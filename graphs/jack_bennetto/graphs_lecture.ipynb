{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Theory (Network Analysis)\n",
    "(credits: Moses Marsh, Matt Drury, Jonathan Torrez, Ivan Corneillet)\n",
    "\n",
    "## Installation Instructions:\n",
    "\n",
    "You may need to install the following modules and utilities to get this notebook to run\n",
    "\n",
    "\n",
    "`pip install nxpd`\n",
    "\n",
    "`brew install graphviz` (macOS) or `sudo apt-get graphviz` (Linux)\n",
    "\n",
    "`git clone https://github.com/taynaud/python-louvain/`\n",
    "\n",
    "`cd python-louvain`\n",
    "\n",
    "`python setup.py install`\n",
    "\n",
    "\n",
    "## Morning Lecture: Graphs\n",
    "\n",
    "### Objectives\n",
    "\n",
    "Morning Objectives\n",
    "- Define a various graph terms, including, degree, neighbors, cycle, components\n",
    "- Define\n",
    "  - Connected vs. disconnected\n",
    "  - Directed vs. undirected\n",
    "  - Weighted vs. unweighted\n",
    "  - Trees\n",
    "- Write code to traverse a graph, both breadth first and depth first\n",
    "\n",
    "Afternoon Objectives\n",
    "\n",
    "- Explain various measures of centrality and how they are used.\n",
    "- Detect a community within a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#from matplotlib import collections as mc\n",
    "from itertools import product\n",
    "\n",
    "# Standard Python Library for working with graphs\n",
    "import networkx as nx\n",
    "\n",
    "# Helper library to visualize graphs\n",
    "import nxpd\n",
    "\n",
    "# Helper library for community related functions\n",
    "import community\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a graph?\n",
    "A graph is a **network**, an abstraction of relationships between data points.\n",
    "![](images/undirected_graph.png)\n",
    "Data points are **nodes** (or **vertices**), and the connections between them are **edges**. \n",
    "\n",
    "Maybe the nodes are people and the edges represent friendship. [Here's](https://github.com/gschool/dsi-welcome/blob/master/readings/Social_Network_Analysis_for_Startups.pdf) a whole book on analyzing **social networks** using graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A social graph from Facebook:\n",
    "\n",
    "![Facebook Social Graph](images/facebook-social-graph.jpg)\n",
    "\n",
    "- **Nodes** are facebook profiles\n",
    "- **Edges** are friend connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game of thrones\n",
    "\n",
    "![](images/game_of_thrones.png)\n",
    "source: https://www.maa.org/sites/default/files/pdf/Mathhorizons/NetworkofThrones%20(1).pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer connectivity across the Internet:\n",
    "\n",
    "![Internet](images/internet.png)\n",
    "\n",
    "- **Nodes** are computers\n",
    "- **Edges** are direct connections from one computer to another\n",
    "\n",
    "source: http://www.opte.org/the-internet/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paris' Metro:\n",
    "\n",
    "![Paris' Metro](images/paris-metro.gif)\n",
    "\n",
    "- **Nodes** are subway stations\n",
    "- **Edges** are subway connections\n",
    "\n",
    "Graphs are mathematical abstractions; the pictures are only there to help our brains comprehend the data.\n",
    "\n",
    "The **actual** Paris subway's geographic structure look like this:\n",
    "\n",
    "![Geographically Accurate Metro Map](images/paris-metro-geo.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food web\n",
    "\n",
    "![](images/food_web.png)\n",
    "[source](https://www.flickr.com/photos/121935927@N06/13578885414)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What kinds of relationships can we represent?\n",
    "\n",
    "![](images/directed-graph_2.png)\n",
    "In a **directed graph** (or digraph), edges represent one-way relationships (e.g. Twitter followers, phone calls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](images/airport_graph.gif)\n",
    "In a **weighted graph**, edges also have a number (usually some kind of **cost**) associated with them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Can you think of something that could be represented by an undirected weighted graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all of this graphs each edge is unique.\n",
    "\n",
    "**Discussion:** Does the directed graph above violate this?\n",
    "\n",
    "**Discussion:** Can you think of an example of a graph with multiple edges between some pairs of nodes? This is called a **multigraph**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of history\n",
    "The original graph is the **Seven Bridges of KÃ¶nigsberg** ([wiki](https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg)):\n",
    "\n",
    "![Bridges of Konigsberg](images/konigsberg.png)\n",
    "![](images/konigsberg_graph.png)\n",
    "\n",
    "**Discussion:** Is it possible to walk around the city, crossing every bridge, but each *exactly* once?\n",
    "\n",
    "Thanks, Euler!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to formalities\n",
    "Formally, a graph $G$ is:\n",
    "\n",
    "- A set $N$ of **nodes**.  Nodes are abstract entities, can represent pretty much anything, and can have data attached\n",
    "- A set $E$ of **edges**, which are directed or undirected pairs of nodes\n",
    "\n",
    "The number of vertices (nodes) $|V|$ is the order of the graph.\n",
    "\n",
    "The number of edges $|E|$ is the size of the graph.\n",
    "\n",
    "So, for example, the following represents an unweighted, undirected graph:\n",
    "\n",
    "$$N = \\{0, 1, 2, 3, 4, 5 \\}$$\n",
    "$$E = \\left\\{ \\{0, 1\\}, \\{0, 4\\}, \\{1, 2 \\}, \\{1, 3\\}, \\{2, 3\\}, \\{2, 5\\}, \\{3, 4\\}, \\{4\\} \\right\\}$$\n",
    "\n",
    "**Question:** What is the $\\{ 4 \\}$ communicating in the edge set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_adj = {\n",
    "    0: [1, 4],\n",
    "    1: [0, 2, 3],\n",
    "    2: [1, 3, 5],\n",
    "    3: [1, 2, 4],\n",
    "    4: [0, 3, 4],\n",
    "    5: [2]}\n",
    "G = nx.from_dict_of_lists(g_adj)\n",
    "# Draw left to right when possible, fits better in notebook\n",
    "G.graph['rankdir'] = 'LR'\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures for Graphs\n",
    "\n",
    "There are three main data structures used for representing a graph.\n",
    "\n",
    "- **Edge list**: a list of the edges (and weights, if applicable)\n",
    "\n",
    "- **Adjacency list**: a dictionary containing each node & its list of neighbors.\n",
    "\n",
    "- **Adjacency matrix**: a square matrix with rows and columns indexed by the nodes.  The entries in the matrix are either $0$ or $1$, depending on whether the nodes are linked with an edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *edge list* representation of the graph above is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_edg = {\n",
    "    (0, 1),\n",
    "    (0, 4),\n",
    "    (1, 0),\n",
    "    (1, 2),\n",
    "    (1, 3),\n",
    "    (2, 1),\n",
    "    (2, 3),\n",
    "    (2, 5),\n",
    "    (3, 1),\n",
    "    (3, 2),\n",
    "    (3, 4),\n",
    "    (4, 0),\n",
    "    (4, 3),\n",
    "    (4, 4),\n",
    "    (5, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *adjacency list* representation of the above graph is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_adj = {\n",
    "    0: [1, 4],\n",
    "    1: [0, 2, 3],\n",
    "    2: [1, 3, 5],\n",
    "    3: [1, 2, 4],\n",
    "    4: [0, 3, 4],\n",
    "    5: [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python library's `networkx` and `nxpd` can be used to manipulate and visualize graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_edgelist(g_edg)\n",
    "\n",
    "# Draw left to right when possible, fits better in notebook\n",
    "G.graph['rankdir'] = 'LR'\n",
    "\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_dict_of_lists(g_adj)\n",
    "\n",
    "# Draw left to right when possible, fits better in notebook\n",
    "G.graph['rankdir'] = 'LR'\n",
    "\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *adjacency matrix* representation of the above graph is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_matrix = np.array([\n",
    "    [0, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 1, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 1],\n",
    "    [0, 1, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures for Graphs\n",
    "\n",
    "- **Adjacency matrix**: a square matrix with rows and columns indexed by the nodes.  The entries in the matrix are either $0$ or $1$, depending on whether the nodes are linked with an edge.  \n",
    "  - PRO: Easy to understand and interpret\n",
    "  - CON: \"No edge\" cells take up same amount of memory as other cells and most networks are low density (online social networks often have density of 0.1%)\n",
    "  \n",
    "- **Edge list**: a list of the edges (and weights, if applicable)\n",
    "  - PRO: Less space in memory for large and sparse networks\n",
    "  - PRO: Maps easily into SQL databases\n",
    "  - PRO: Maps easily into text based formats\n",
    "  - CON: Searching/traversal of graph is slow (iterating over edges)\n",
    "\n",
    "- **Adjacency list**: a dictionary containing each node & its list of neighbors.\n",
    "  - PRO: Less space in memory for large and sparse networks\n",
    "  - PRO: Fast searching and traversal\n",
    "  - PRO: Easy to add/remove nodes and edges\n",
    "  - CON: Harder to parse from text\n",
    "  - CON: Harder to write to databases\n",
    "\n",
    "**Question:** Which data structure is best for persistent storage? Which data structure is best for internal data representation (working with the graph)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: adjacency matrix for a directed graph\n",
    "![](images/directed-graph_2.png)\n",
    "\n",
    "\n",
    "Exercise: adjacency matrix for a weighted graph\n",
    "![](images/weighted_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper function\n",
    "\n",
    "We're going to start with helper functions to make it easier to visualize graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_dict_of_floats(d):\n",
    "    return {key: '{0:2.2f}'.format(val) for key, val in d.items()}\n",
    "\n",
    "def color_nodes(G, node_list, color):\n",
    "    '''Add a filled color attribute to a list of graph nodes.'''\n",
    "    for node in node_list:\n",
    "        G.node[node]['style'] = 'filled'\n",
    "        G.node[node]['fillcolor'] = color\n",
    "\n",
    "def color_edges(G, edge_list, color):\n",
    "    '''Color a list of edges in a graph.'''\n",
    "    for edge in edge_list:\n",
    "        G[edge[0]][edge[1]]['color'] = color\n",
    "\n",
    "def label_nodes(G, labeling_dict):\n",
    "    for node, label in labeling_dict.items():\n",
    "        G.node[node]['label'] = label\n",
    "\n",
    "def label_edges(G, labeling_dict):\n",
    "    for e, label in labeling_dict.items():\n",
    "        G[e[0]][e[1]]['label'] = label\n",
    "\n",
    "def label_edges_with_weights(G):\n",
    "    '''Label each edge in a graph with its associated weight.'''\n",
    "    for e in G.edges():\n",
    "        weight = G[e[0]][e[1]]['weight']\n",
    "        G[e[0]][e[1]]['label'] = weight\n",
    "\n",
    "def reset_graph(G):\n",
    "    color_nodes(G, G.nodes(), 'white')\n",
    "    color_edges(G, G.edges(), 'black')\n",
    "    for node in G.nodes():\n",
    "        G.node[node]['label'] = ' '\n",
    "    for edge in G.edges():\n",
    "        G[edge[0]][edge[1]].pop('label', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Graph Concepts\n",
    "\n",
    "The **neighbors** of a node are all those connected to it by an edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_nodes(G, [1], 'lightblue')\n",
    "color_nodes(G, G.neighbors(1), 'lightgrey')\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **degree** of a node is the number of neighbors it has.\n",
    "\n",
    "$$d(1) = 3$$\n",
    "\n",
    "A **path** is a series of edges that connect two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph(G)\n",
    "color_nodes(G, [0, 4], 'lightgrey')\n",
    "color_nodes(G, [1, 3], 'lightblue')\n",
    "color_edges(G, [(0, 1), (1, 3), (3, 4)], 'blue')\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph is **connected** if every pair of nodes is connected by some path.\n",
    "\n",
    "A graph is **disconnected** if it is not connected.  In this case, each connected piece of the graph is called a **component**.\n",
    "\n",
    "**Exercise:** Fill in the adjacency list for a *disconnected* graph with three components, then plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_disconnected = {\n",
    "    # fill this in\n",
    "}\n",
    "\n",
    "G_disconnected = nx.from_dict_of_lists(g_disconnected)\n",
    "G_disconnected.graph['rankdir'] = 'LR'\n",
    "nxpd.draw(G_disconnected, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **cycle** in a graph is a sequence of edges that returns to the same node from which it began:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph(G)\n",
    "color_nodes(G, [0, 1, 3, 4], 'lightblue')\n",
    "color_edges(G, [(0, 1), (1, 3), (3, 4), (4, 0)], 'blue')\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **tree** is a undirected connected acyclic graph (i.e., has  no cycles). A **rooted tree** has a single node labeled as the root. This effectively makes it directed graph, since the edges can be given a direction away from (or towards) the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_adj_list_to_edge_list(adj_list):\n",
    "    edge_list = set()\n",
    "    for node, child_nodes in adj_list.items():\n",
    "        for child in child_nodes:\n",
    "            edge_list.add((node, child))\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tree = {\n",
    "    0: {1, 2},\n",
    "    1: {3, 4},\n",
    "    2: {5, 6},\n",
    "    3: {},\n",
    "    4: {},\n",
    "    5: {},\n",
    "    6: {7, 8},\n",
    "    7: {},\n",
    "    8: {}\n",
    "}\n",
    "\n",
    "g_tree_edge_list = convert_adj_list_to_edge_list(g_tree)\n",
    "\n",
    "G_tree = nx.DiGraph()\n",
    "G_tree.add_nodes_from(g_tree)\n",
    "G_tree.add_edges_from(g_tree_edge_list)\n",
    "nxpd.draw(G_tree, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are used as fundamental data structures in computer science used in storing and organizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot more terminology around graphs that you can read about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** If $G$ is the *adjacency matrix* of a graph, what graph does $G^2$ represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('G')\n",
    "\n",
    "print(g_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(g_matrix)\n",
    "G.graph['rankdir'] = 'LR'\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "G2_arr = np.dot(g_matrix, g_matrix)\n",
    "# Set all values greater than 0 to 1 since we only care about if there is an edge (1)\n",
    "# or theres isn't an edge (0) in adj. matrices\n",
    "G2_arr[G2_arr > 0] = 1\n",
    "print( \"G^2\")\n",
    "G2_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G2 = nx.Graph(G2_arr)\n",
    "G2.graph['rankdir'] = 'LR'\n",
    "nxpd.draw(G2, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search (Traversal) Algorithms\n",
    "\n",
    "A **traversal algorithm** is a method for visiting every node in a graph.\n",
    "\n",
    "A **search algorithm** is a method for searching for a specified node in a graph.\n",
    "\n",
    "These two types of algorithms are almost interchangable: to turn a traversal algorithm into a search algorithm you simply need to provide a stopping criteria (in this case, the node you are searching for).\n",
    "\n",
    "We will examine traversal algorithms to demonstrate the difference between the methods, but the same ideas apply to the search algorithms.\n",
    "\n",
    "In **breadth first** algorithms we traverse the graph by prioritizing visiting all the *children* of a node before visiting the *children's children*.\n",
    "\n",
    "In **depth first** algorithms we traverse the graph by prioritizing visiting a *child* and the *child's child*, iteratively, before backtracking and visiting the *sibling* nodes.\n",
    "\n",
    "We are using the term child loosely here, as there are no children in an undirected graph, only neighbors.\n",
    "\n",
    "**Intermission:** Review data structures.  **Stack** and **Queue**.\n",
    "\n",
    "- Stack:\n",
    "    - Ordering: Last In, First Out (LIFO)\n",
    "    - Insertion/Removal of items: Same end of chain\n",
    "    - Analogy: stack of dishes\n",
    "- Queue:\n",
    "    - Ordering: First In, First Out (FIFO) ordering\n",
    "    - Insertion/Removal of items: Opposite ends of chain (insert at end, remove at front)\n",
    "    - Analogy: line for movie premiere (if we were British, we'd already use the word queue instead of line)\n",
    "    \n",
    "Note that sometimes the word queue is used generically, and the above are referred to as a LIFO queue and a FIFO queue. We won't do that.\n",
    "\n",
    "**Question:** How can we represent a stack in python? How can we represent a queue?\n",
    "\n",
    "**Discussion:** Which data structure should we use for breadth first algorithms? For depth first?\n",
    "\n",
    "**Further Reading:** Python docs have short discussion of data structures to use for stacks and queues:\n",
    "https://docs.python.org/3/tutorial/datastructures.html#data-structures\n",
    "\n",
    "Breadth First Traversal (BFT) Pseudocode.\n",
    "\n",
    "    Initialize a queue, Q, with starting node.\n",
    "    Initialize an empty set *V* of visited nodes.\n",
    "\n",
    "    While Q is not empty:\n",
    "        Remove (earliest added) node from Q, call it node.\n",
    "        if node is not already visited.\n",
    "            Add node to V (the visited set).\n",
    "            Append every neighbour of node to (the end of) Q.\n",
    "\n",
    "Real code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def breadth_first_traversal(G, initial_node):\n",
    "    Q = [initial_node]\n",
    "    visited = set()\n",
    "\n",
    "    while len(Q) != 0:\n",
    "        node = Q.pop(0) # pop from the left\n",
    "        if node not in visited:\n",
    "            yield node\n",
    "            visited.add(node)\n",
    "            Q.extend(G.neighbors(node)) # extend to the right side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can label nodes by the search order to visualize the algorithm. We'll make a random graph for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.erdos_renyi_graph(12, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_node = 3\n",
    "search_order = {v: i for i, v in\n",
    "                enumerate(breadth_first_traversal(G, starting_node))}\n",
    "\n",
    "reset_graph(G)\n",
    "color_nodes(G, [starting_node], 'lightblue')\n",
    "label_nodes(G, search_order)\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What information does the *order nodes are visited* in the breadth first traversal algorithm contain?\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "- Shortest path in unweighted graph\n",
    "- Crawlers in search engines\n",
    "\n",
    "Today's sprint uses the ideas in this algorithm to compute the shortest path between two nodes.\n",
    "\n",
    "Depth First Traversal (DFT) Pseudocode.\n",
    "\n",
    "    Initiliaze a stack, S, with initial node\n",
    "    Initialize an empty set *V* of visited nodes\n",
    "\n",
    "    While S is not empty:\n",
    "        Pop (last added) node from S, call it node\n",
    "        if node is not already visited\n",
    "            Add node to V (the visited set)\n",
    "            Add every neighbor of node to (the end of) S\n",
    "\n",
    "There are no children in graphs, only neighbors, but the concept of children is important in other graph structures such as trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def depth_first_traversal(G, initial_node):\n",
    "    S = [initial_node]\n",
    "    visited = set() \n",
    "\n",
    "    while len(S) != 0:\n",
    "        node = S.pop() # pop from the right\n",
    "        if node not in visited:\n",
    "            yield node\n",
    "            visited.add(node)\n",
    "            S.extend(G.neighbors(node)) # extend to the right side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_order = {v: i for i, v in\n",
    "                enumerate(depth_first_traversal(G, starting_node))}\n",
    "reset_graph(G)\n",
    "color_nodes(G, [starting_node], 'lightblue')\n",
    "label_nodes(G, search_order)\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications:**\n",
    "\n",
    "- Spanning tree of graph\n",
    "- Solving a maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afternoon Lecture\n",
    "\n",
    "\n",
    "### Where's the machine learning?\n",
    "We can use the shape of a graph to featurize nodes! We want to find how important a single node is in a graph (centrality) and how we can meaningfully group together many nodes (communities).\n",
    "\n",
    "\n",
    "### Centrality Measures\n",
    "\n",
    "Often it is important for us to measure the *importance* of a node in a graph.  There are **many** applications for different versions of this idea.\n",
    "\n",
    "- Fraud rings in insurance claims\n",
    "- Influencers\n",
    "- Bottlenecks for network traffic\n",
    "- Page Rank\n",
    "\n",
    "### Degree Centrality\n",
    "\n",
    "The **standardized degree centrality** measure of a node, $v$, in a graph is defined by:\n",
    "\n",
    "$$\\text{standardized_degree_centrality}(v) = \\frac{\\text{degree}(v)}{\\text{number of nodes in } G - 1}$$\n",
    "\n",
    "**Discussion:** Why subtract 1 from the total number of nodes to standardize? Why standardize at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_star = {\n",
    "    0: {1, 2, 3, 4, 5},\n",
    "    1: {0},\n",
    "    2: {0},\n",
    "    3: {0},\n",
    "    4: {0},\n",
    "    5: {0}\n",
    "}\n",
    "\n",
    "G_star = nx.from_dict_of_lists(g_star)\n",
    "nxpd.draw(G_star, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Compute the degree centrality of the nodes in this graph.\n",
    "\n",
    "### Betweenness Centrality\n",
    "\n",
    "While the *degree centrality* is intuitive and easy to calculate, it often misses important features of a graph we would intuitively recognise as important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_triangle = {\n",
    "    0: {1, 2},\n",
    "    1: {0, 2},\n",
    "    2: {0, 1},\n",
    "    3: {1, 5},\n",
    "    4: {5, 6},\n",
    "    5: {4, 6},\n",
    "    6: {4, 5},\n",
    "}\n",
    "\n",
    "G_triangle = nx.from_dict_of_lists(g_triangle)\n",
    "G_triangle.graph['rankdir'] = 'LR'\n",
    "color_nodes(G_triangle, [3], 'lightblue')\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What is the degree centrality of the highlighted node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centralities = format_dict_of_floats(nx.degree_centrality(G_triangle))\n",
    "label_nodes(G_triangle, degree_centralities)\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breadth first search algorithm can be used to efficiently calculate the number of the number of shortest paths through a given node.\n",
    "\n",
    "$$\\sigma_{uv} = \\text{# of shortest paths between u and v}$$\n",
    "$$\\sigma_{uv}(w) = \\text{# of shortest paths between u and v that pass through w}$$\n",
    "\n",
    "The *betweenness centrality* of a node measures the average fraction of shortest paths pass through that node. Or, loosely, how often we need to pass through the node to move around the graph\n",
    "\n",
    "$$\\text{betweenness_centrality}(w) = \\sum_{u \\neq w, v \\neq w} \\frac{ \\sigma_{uv}(w) }{ \\sigma_{uv} }$$\n",
    "\n",
    "The *normalized betweenness centrality* is:\n",
    "\n",
    "$$\\frac{ \\text{betweenness_centrality}(w) }{ \\frac{(n-1)(n-2)}{2} }$$\n",
    "\n",
    "**Question:** Whats with the denominator?\n",
    "\n",
    "**Activity:** Compute the betweenness centrality of all the nodes in the two triangle graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_centralities = format_dict_of_floats(nx.betweenness_centrality(G_triangle))\n",
    "label_nodes(G_triangle, between_centralities)\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also see later that the concept of betweenness centrality can also be applies to edges in the graph, resulting in cool pictures like this:\n",
    "\n",
    "![Roads Betweeness Centrality](images/edge-betweeness.png)\n",
    "\n",
    "### Eigenvector Centrality\n",
    "\n",
    "Suppose we try to invent a centrality measure that satisfies the following appealing property\n",
    "\n",
    "> The centrality of a node $v$ is proportional to the sum of the centralities of its neighbours.\n",
    "\n",
    "or, a little more generally\n",
    "\n",
    "> A node is important if it is linked to many other important nodes\n",
    "\n",
    "If $A$ is the adjacency matrix of a graph, and $x$ is the vector containing our postulated centrality measures, we can express this idea as system of linear equations\n",
    "\n",
    "$$\\sum_j A_{ij} x_j = \\lambda x_i$$\n",
    "\n",
    "or, as the single matrix equation\n",
    "\n",
    "$$Ax = \\lambda x$$\n",
    "\n",
    "You might recognize that as the equation for eigenvalues.\n",
    "\n",
    "If we take $\\lambda_{max}$, the *largest* eigenvalue of $A$, then the solution vector $x$ *defines* the **eigenvector centrality** of our graph.\n",
    "\n",
    "$$A x_{\\text{eigenvector centrality}} = \\lambda_{\\text{max}} x_{\\text{eigenvector centrality}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_centralities = format_dict_of_floats(nx.eigenvector_centrality(G_triangle))\n",
    "label_nodes(G_triangle, eigen_centralities)\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a picture from wikipedia that shows a the eigenvector centrality for a larger graph ([source](https://en.wikipedia.org/wiki/Centrality)).\n",
    "\n",
    "![Eigenvector Centrality](images/eigenvector-centrality.png)\n",
    "\n",
    "**Note:** Eigenvector centrality was a fundamental component of early versions of *page rank*, Google's web page ranking algorithm.\n",
    "\n",
    "**Discussion:** Recap and contrast the type of information the different centrality measures we learned can give you.\n",
    "\n",
    "Which centrality measure would you use to...\n",
    "* Find a facebook user who is popular?\n",
    "* Find a facebook user who is important in multiple fields?\n",
    "* Find a facebook user who is influential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Simple Communities](images/simple-communities.jpg)\n",
    "\n",
    "Formally a **community** is a subset of the nodes in a graph.  We say a graph is *partitioned into communities* if each node is assigned to exactly one community. \n",
    "\n",
    "We would like to create communities so that the following vague idea is true:\n",
    "\n",
    "> Points in the *same* community are more likely to have an edge between them than points in *different* communities.\n",
    "\n",
    "Just like in clustering, we need a way to *measure* how true this is for a given partition.\n",
    "\n",
    "### Modularity\n",
    "\n",
    "The \"goodness\" of a partition into communities is measured by *modularity*, which is a somewhat tricky concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *idea* of modularity is to compare the graph we have to what we would expect if we erased the actual edges and drew *random* edges in their place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine taking a graph and removing the middle of each edge. You'd end up with a bunch of nodes with edge stubs sticking out. If $m$ is the original number of edges, we now have $2m$ stubs. Each node $i$ has $d(i)$ stubs coming out, where $d(i)$ is the degree of node $i$\n",
    "\n",
    "![](images/edge_stubs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now randomly connect the stubs together. We can calculate the probability that node $i$ gets connected to node $j$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{P}(\\text{single edge stub gets connected to }j) & = \\frac{d(j)}{2m} \\\\\n",
    "\\text{Expected number of edges from }i\\text{ to }j & = \\frac{d(i)d(j)}{2m} \\\\\n",
    "\\text{Expected number of edges between nodes within one community} & = \\sum_{i,j \\in C} \\frac{d(i)d(j)}{2m}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **modularity** of a partitioning of a graph $G$ into a set of communities $\\mathcal{C}$ is defined as the *true* number of edges within communities minus the *expected* number of edges under this random edge assignment (all divided by $2m$)\n",
    "\n",
    "$$\n",
    "\\text{modularity}(G,\\mathcal{C}) = \\frac{1}{2m}\\sum_{C\\in\\mathcal{C}}\\left[\\sum_{i,j\\in C}\\left(A_{ij} - \\frac{d(i)d(j)}{2m}\\right)\\right]\n",
    "$$\n",
    "\n",
    "Where $A_{ij}$ is the entry in the adjacency matrix: $1$ if nodes $i$ and $j$ are connected, $0$ if not.\n",
    "\n",
    "Modularity (also called [Louvain Modularity](https://en.wikipedia.org/wiki/Louvain_Modularity)) can range from -1 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Creating Communities\n",
    "\n",
    "Now that we can measure how good a breakdown into communities is (using modularity) we need an algorithm to create communities for us.\n",
    "\n",
    "**Inspiration:** If our graph breaks up into *disconnected* pieces, these are certainly good communities.\n",
    "\n",
    "**Idea:** Remove the *minimal* number of edges needed to break the graph into disconnected pieces.  The resulting pieces should be good communities.\n",
    "\n",
    "Here we can remove the grey edges, and the resulting communities are all colored.\n",
    "\n",
    "![Simple Communities](images/simple-communities.jpg)\n",
    "\n",
    "How can we identify the grey edges if\n",
    "\n",
    "- The graph was not draws so suggestively\n",
    "- Nothing was colored\n",
    "\n",
    "**Discussion:** Brainstorm.  How should we identify the edges to remove?\n",
    "\n",
    "### Betweenness Centrality Redux\n",
    "\n",
    "Earlier, we defined the **betweenness centrality** measure of a *node* as the number of shorted paths that must pass through that node.\n",
    "\n",
    "This idea could equally well apply to *edges*!\n",
    "\n",
    "![Roads Betweeness Centrality](images/edge-betweeness.png)\n",
    "\n",
    "The **betweenness centrality** of an edge $e$ is:\n",
    "\n",
    "$$\\text{betweenness_centrality}(e) = \\sum_{u \\neq v} \\frac{ \\sigma_{uv}(e) }{ \\sigma_{uv} }$$\n",
    "\n",
    "Where the $\\sigma$s have the same meaning as before:\n",
    "\n",
    "$$\\sigma_{uv} = \\text{# of shortest paths between u and v}$$\n",
    "$$\\sigma_{uv}(w) = \\text{# of shortest paths between u and v that pass through e}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_centralities = format_dict_of_floats(nx.edge_betweenness_centrality(G_triangle))\n",
    "reset_graph(G_triangle)\n",
    "label_edges(G_triangle, between_centralities)\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Girvan-Newman Algorithm\n",
    "\n",
    "The **Girvan-Newman** algorithm is a simple way to break a graph down into communities.\n",
    "\n",
    "    Repeat until satisfied (i.e., you've found a partition that maximizes modularity):\n",
    "        Repeat until a new connected component is created:\n",
    "            Compute the edge betweenness centrality of the current graph.\n",
    "            Remove the edge with highest betweenness centrality.\n",
    "        Return the connected components of resulting graph as community labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-defining so we get some node labels\n",
    "g_triangle = {\n",
    "    0: {1, 2},\n",
    "    1: {0, 2},\n",
    "    2: {0, 1},\n",
    "    3: {1, 5},\n",
    "    4: {5, 6},\n",
    "    5: {4, 6},\n",
    "    6: {4, 5},\n",
    "}\n",
    "\n",
    "G_triangle = nx.from_dict_of_lists(g_triangle)\n",
    "G_triangle.graph['rankdir'] = 'LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_centralities = format_dict_of_floats(nx.edge_betweenness_centrality(G_triangle))\n",
    "label_edges(G_triangle, between_centralities)\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_triangle.remove_edge(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_centralities = format_dict_of_floats(nx.edge_betweenness_centrality(G_triangle))\n",
    "label_edges(G_triangle, between_centralities)\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_triangle.remove_edge(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_centralities = format_dict_of_floats(nx.edge_betweenness_centrality(G_triangle))\n",
    "label_edges(G_triangle, between_centralities)\n",
    "nxpd.draw(G_triangle, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_nbhd_graph(x, y, D):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(zip(x, y))\n",
    "    for ((x_1, y_1), (x_2, y_2)) in product(zip(x, y), zip(x, y)):\n",
    "        if (x_1 - x_2)**2 + (y_1 - y_2)**2 <= D:\n",
    "            G.add_edge((x_1, y_1), (x_2, y_2))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_two_clusters(size, d):\n",
    "    \"\"\"Make two gaussian clusters.  d is the distance between the cluster centers.\"\"\"\n",
    "    x = np.concatenate([np.random.normal(loc=-d/2, size=size), \n",
    "                        np.random.normal(loc=d/2, size=size)])\n",
    "    y = np.concatenate([np.random.normal(loc=0, size=size),\n",
    "                        np.random.normal(loc=0, size=size)])\n",
    "    return x, y\n",
    "\n",
    "def make_segments_in_nbhd_graph(x, y, D):\n",
    "    line_segments = []\n",
    "    for ((x_1, y_1), (x_2, y_2)) in product(zip(x, y), zip(x, y)):\n",
    "        if (x_1 - x_2)**2 + (y_1 - y_2)**2 <= D:\n",
    "             line_segments.append(((x_1, y_1), (x_2, y_2)))\n",
    "    lc = matplotlib.collections.LineCollection(line_segments,\n",
    "                                               color=\"grey\",\n",
    "                                               alpha=0.2, \n",
    "                                               linewidths=2)\n",
    "    return lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [5, 4, 3, 2, 1, 0.5]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(14, 8), sharex=True, sharey=True)\n",
    "\n",
    "for d, ax in zip(ds, axs.flatten()):\n",
    "    x, y = make_two_clusters(30, d)\n",
    "    ax.scatter(x, y, color=([\"red\"]*30 + [\"blue\"]*30))\n",
    "    ax.set_title(\"Distance Between Clusters {}\".format(d))\n",
    "\n",
    "    lc = make_segments_in_nbhd_graph(x, y, 1.5)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    G = make_nbhd_graph(x, y, d)\n",
    "    communities = {(x[i], y[i]): i < 30 for i in range(30*2)}\n",
    "    modularity = community.modularity(communities, G)\n",
    "    ax.text(-5, 3, \"Modularity {0:2.2f}\".format(modularity), fontsize=20, alpha=0.5)\n",
    "    ax.set_ylim(-6, 6)\n",
    "    ax.set_ylim(-4, 4)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
