{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$\\textit{pandas}$$\n",
    "$$\\text{Schwartz}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $$\\textbf{They're not on the endangered species list any more}$$\n",
    "# $$\\textbf{China saved the Giant Panda}$$\n",
    "\n",
    "As of September 2016 the International Union for the Conservation of Nature (IUCN) has taken the global icon off the endangered species list. The giant panda is now listed as \"vulnerable\" as opposed to \"endangered\". Thanks to Chinese conservation efforts the Giant Panda population has increased to approximately 2,000 individuals up from a low of about 1,000 in the 1970's when the species was at the most risk.  This population increase has been the result of bamboo forest restoration projects and the incorporation of improved captive breeding and husbandry methods -- initiatives driven by a better understanding of Giant Panda physiology and behaviour. Challenges remain, however. Climate change is predicted to wipe out more than one-third of the panda's bamboo habitat in the next 80 years, and reintroduction of captive-bred pandas into the wild remains challenging. \n",
    "\n",
    "<table align=\"center\">\n",
    "<tr><td>\n",
    "<img src=\"stuff/pandas.png\" width=\"600px\" align=\"center\"> \n",
    "</tr></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Before we do pandas...\n",
    "* Connect to a Postgres server \n",
    "    * in python \n",
    "        * using psycopg2\n",
    "* Understand psycopg2's \"cursors\"\n",
    "    * executes\n",
    "    * commits\n",
    "* Generate dynamic queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# psycopg2\n",
    "* A python SQL postgres server interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install homebrew: http://brew.sh\n",
    "\n",
    "# brew cask install postgres -> double click -> applications\n",
    "# brew cask install pgadmin3 -> double click -> applications, click plug\n",
    "# brew tap homebrew/services\n",
    "# brew services start postgresql\n",
    "\n",
    "# https://github.com/zipfian/welcome/blob/master/notes/postgres_setup.md\n",
    "\n",
    "# conda install psycopg2\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1: open a connection\n",
    "conn = psycopg2.connect(dbname='my_postgresql_db',port=5432,password=\"\",\n",
    "                        user='schwarls37',host='localhost')\n",
    "\n",
    "# host could be a remote database as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td><img src=\"stuff/whywouldyoudothat1.jpg\" width=\"300px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/whywouldyoudothat2.jpg\" width=\"415px\" align=\"center\"></td> \n",
    "</tr>\n",
    "</table>\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td><img src=\"stuff/whywouldyoudothat3.jpg\" width=\"400px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/whywouldyoudothat4.jpg\" width=\"305px\" align=\"center\"></td> \n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Allows us to combine data sources in one place\n",
    "* Can use python to simultaneously pull data from other databases as well \n",
    "    * mysql-connector-python (MySql)\n",
    "    * sqlite (SQLite)\n",
    "    * pymongo (MongoDB)\n",
    "    * sqlalchemy (all the things)\n",
    "    * [psychopg2 (postgreSQL), obviously]\n",
    "\n",
    "## Allows us to bring other python tools to bear\n",
    "* DataFrames and associated functionality, Machine Learning tools, etc.\n",
    "\n",
    "## Allows for easy dynamic query generation\n",
    "* And hence, automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: create a cursor object\n",
    "#cur.close()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# The cursor interfaces and traverses the database \n",
    "# We don't have to worry about how it does it\n",
    "# Queries are returned as (single iteration) generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 3: execute some SQL queries\n",
    "query = '''SELECT \"Facility Name\", \"Available Residential Beds\" \n",
    "           FROM Beds \n",
    "           WHERE \"City\" = 'Cuba' \n",
    "           LIMIT 10;'''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InternalError: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "# If you see this error \n",
    "\n",
    "print \"InternalError: current transaction is aborted, commands ignored until end of transaction block\"\n",
    "\n",
    "# Then the cursor is chocking on a current command \n",
    "# and it needs to be aborted with: conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 4)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 3)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 4)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 3)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 5)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 4)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 6)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 5)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 5)\n",
      "('Cuba Memorial Hospital Inc SNF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ', 5)\n"
     ]
    }
   ],
   "source": [
    "for row in cur:\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in cur:\n",
    "    print row\n",
    "    \n",
    "# See, I told you: cur saves results as a (one pass) generator    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other options for iterating through the generator\n",
    "\n",
    "# cur.fetchone(), or cur.next()\n",
    "# cur.fetchmany(n)\n",
    "# cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''ALTER TABLE Beds \n",
    "           RENAME COLUMN \"Available Residential Beds\" \n",
    "           TO \"Available_Residential_Beds\"'''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4: commit SQL actions \n",
    "# (to actually make the changes to the DB permanent)\n",
    "\n",
    "conn.commit()\n",
    "# conn.autocommit = True\n",
    "\n",
    "# database level operations are also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''ALTER TABLE Beds \n",
    "           RENAME COLUMN \"Available_Residential_Beds\" \n",
    "           TO \"Available Residential Beds\"'''\n",
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_name = \"Scott\"\n",
    "unsafe_query = '''SELECT * FROM Users \n",
    "                  WHERE Name = ''' + my_name\n",
    "\n",
    "# what if...\n",
    "my_name = \"Scott; DROP TABLE Users\"\n",
    "\n",
    "# This is called SQL Injection and it's obviously risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instead \n",
    "my_name = \"Scott; DROP TABLE Users\"\n",
    "\n",
    "cur.execute('''SELECT * FROM Users WHERE Name = %s''', my_name)\n",
    "\n",
    "# will search for rows in Name *exactly* equal to 'Scott; DROP TABLE Users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5: close the connection\n",
    "\n",
    "cur.close() # optional, automatically close with conn.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Pandas are cute cuddly animals\n",
    "* They are also the Flying Circus' answer to Excel and R Data Frames\n",
    "* They are built on top of NumPy NdArrays\n",
    "\n",
    "# Objectives\n",
    "* Proficiency with Pandas Series\n",
    "    * Familiarity with Pandas Time Series\n",
    "* Proficiency with Pandas DataFrames\n",
    "    * Using the DataFrame Index\n",
    "    * Creating and destroying columns\n",
    "* Proficiency applying functions to rows and columns\n",
    "    * DataFrame grouping and aggregation\n",
    "    * DataFrames sorting\n",
    "* Proficiency in linking DataFrames\n",
    "    * Concatenating/Appening DataFrames\n",
    "    * Merging/Joining DataFrames\n",
    "* Familiarity with matplotlib and Pandas Exploratory Data Analysis (EDA) functionality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas is very functional\n",
    "\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td><img src=\"stuff/panda7.jpg\" width=\"300px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda2.jpg\" width=\"180px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda6.jpg\" width=\"475px\" align=\"center\"></td> \n",
    "<tr><td>Killer Panda</td><td>Red Handed Panda</td><td>Sexy Panda</td></tr>\n",
    "\n",
    "\n",
    "</tr>\n",
    "</table>\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "\n",
    "<td><img src=\"stuff/panda4.jpg\" width=\"230px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda3.jpg\" width=\"300px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda1.jpg\" width=\"205x\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda8.jpg\" width=\"210px\" align=\"center\"></td> \n",
    "<tr><td>Sherrif Panda</td><td>Assisted Pushup Panda</td><td>Acrobat Panda (Advanced)</td><td>Acrobat Panda (Beginner)</td></tr>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# (Standard Library) Lists\n",
    "* concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3] + [4,5,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numpy NdArrays\n",
    "* operate elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.,  14.,  17.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]) + np.arange(3) + np.linspace(10,12,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numpy NdArrays\n",
    "\n",
    "* have types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 |S1 |S3\n"
     ]
    }
   ],
   "source": [
    "ints = np.array(range(3))\n",
    "chars = np.array(list('ABC'))\n",
    "strings = np.array(['A','BC',\"DEF\"])\n",
    "\n",
    "print ints.dtype, chars.dtype, strings.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Speed\n",
    "\n",
    "https://ipython.org/ipython-doc/3/interactive/magics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python list\n",
      "100 loops, best of 1: 10.8 ms per loop\n",
      "0.0108169817924\n",
      "\n",
      "numpy array\n",
      "1000 loops, best of 1: 844 µs per loop\n",
      "0.000843533992767\n",
      "\n",
      "numpy array -- standard library sum\n",
      "10 loops, best of 1: 103 ms per loop\n",
      "0.103136014938\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.arange(0, 1000000)\n",
    "python_list = range(1000000)\n",
    "\n",
    "print \"python list\"\n",
    "time = %timeit -r 1 -o sum(python_list)\n",
    "print time.all_runs[0]/time.loops \n",
    "\n",
    "print \"\\n\" + \"numpy array\"\n",
    "time = %timeit -r 1 -o np.sum(numpy_array)\n",
    "print time.all_runs[0]/time.loops\n",
    "\n",
    "print \"\\n\" + \"numpy array -- standard library sum\"\n",
    "time = %timeit -r 1 -o sum(numpy_array)\n",
    "print time.all_runs[0]/time.loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Broadcasting\n",
    "\n",
    "http://docs.scipy.org/doc/numpy-1.10.1/user/basics.broadcasting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (2, 2)\n",
      "\n",
      "\n",
      "[[ 11  12]\n",
      " [-11 -12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[10], [-10]]) \n",
    "b = np.array([[1, 2], [-1, -2]]) \n",
    "\n",
    "print a.shape, b.shape \n",
    "print \"\\n\"\n",
    "print a + b\n",
    "\n",
    "# elements will \"duplicate, expand, and fill up\" \n",
    "# to make the dimensions compatible for element-wise operations\n",
    "# cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (2, 2)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6bae2e24bfd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# it's not clear how it should fill up in this case... so it can't/doesn't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,2) "
     ]
    }
   ],
   "source": [
    "a = np.array([[10, 0, -10, 0],[-10, 0, -10, 0]]) \n",
    "b = np.array([[2,2],[-1,-1]]) \n",
    "print a.shape, b.shape \n",
    "print \"\"\n",
    "print a + b\n",
    "\n",
    "# it's not clear how it should fill up in this case... so it can't/doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# dimension dimentia -- don't be caught holding the bag!\n",
    "\n",
    "a = 10\n",
    "a = np.array(10)\n",
    "a = np.array([10])\n",
    "a = np.array([[[10]]])\n",
    "a = np.array([[10],[10]])\n",
    "b = np.array([[1,2],[-1,-2]])\n",
    "\n",
    "print a.shape, b.shape\n",
    "#print \"\\n\"\n",
    "#print a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas Series\n",
    "* are (one dimensional) np.ndarray vectors **with an index**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series = pd.Series([5775,373,7,42,np.nan,33])\n",
    "print series\n",
    "print \"\\n\"\n",
    "print series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_series = pd.Series([\"cubs\",\"royals\",\"giants\",\"sox\",\"giants\",\"cards\",\"giants\",\"...\",None])\n",
    "world_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas Date Series\n",
    "* are fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdays = pd.date_range(start='19821107', periods=34+1, freq=pd.DateOffset(years=1))\n",
    "bdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### After you learn Pandas you might care about using Date Series Types and the following could be useful:\n",
    "* df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n",
    "* df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas DataFrames\n",
    "* are a set of Pandas Series **that share the same index** \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$\\huge \\text{Pandas DataFrame} \\supset \\text{Pandas Series} \\supset \\text{NumPy Array}$$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df = pd.DataFrame({ 'A' : 1.,\n",
    "                     'B' : pd.Timestamp('20130102'),\n",
    "                     'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "                     'D' : np.array([3] * 4,dtype='int32'),\n",
    "                     'E' : pd.Categorical([\"test\",\"train\",\"test\",\"try\"]),\n",
    "                     'F' : 'foo' })\n",
    "\n",
    "# mixedTypes_df.to_dict() \n",
    "\n",
    "print mixedTypes_df\n",
    "print \"\"\n",
    "print mixedTypes_df.shape\n",
    "print \"\"\n",
    "mixedTypes_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Additional Numpy NdArray\n",
    "* stuff that will likely be useful at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_ndarray = np.random.randn(35,6)\n",
    "\n",
    "print noise_ndarray\n",
    "print noise_ndarray.shape\n",
    "\n",
    "#print noise_ndarray.flatten().shape\n",
    "#print noise_ndarray.flatten() # copy\n",
    "\n",
    "#print noise_ndarray.ravel().shape\n",
    "#print noise_ndarray.ravel() # view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeros_ndarray = np.zeros((3,4))        # Create a matrix of zeros with 3 rows and 4 columns. \n",
    "ones_ndarray = np.ones((10,20))        # Create a matrix of ones with 10 rows and 20 columns.\n",
    "identity_ndarray = np.identity(10)     # Create an identity matrix with 50 rows and 50 columns. \n",
    "random_ndarray = np.random.rand(2, 2)  # Create a 2x2 array of random floats ranging from 0 to 1. \n",
    "range_ndarray = np.arange(0, 20, 0.5)  # Create a numpy array with arguments (start, end, step_size).\n",
    "zeros_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np bonus (+ pandas foreshadowing):\n",
    "# applying functions by rows or columns\n",
    "\n",
    "print noise_ndarray\n",
    "print noise_ndarray.shape\n",
    "print \"\\n\" + \"sum, axis=0\"\n",
    "print noise_ndarray.sum(axis=0)\n",
    "print \"\\n\" + \"sum, axis=1\"\n",
    "print noise_ndarray.sum(axis=1)\n",
    "print \"\\n\" + \"mean, axis=0\"\n",
    "print noise_ndarray.mean(axis=0)\n",
    "print \"\\n\" + \"std, axis=0\"\n",
    "print noise_ndarray.std(axis=0)\n",
    "print \"\\n\" + \"max, axis=0\"\n",
    "print noise_ndarray.max(axis=0)\n",
    "print \"\\n\" + \"min, axis=0\"\n",
    "print noise_ndarray.min(axis=0)\n",
    "print \"\\n\" + \"argmax, axis=0\"\n",
    "print noise_ndarray.argmax(axis=0)\n",
    "print \"\\n\" + \"argmin, axis=0\"\n",
    "print noise_ndarray.argmin(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Manipulating Pandas Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_df = pd.DataFrame(noise_ndarray, index=bdays, columns=list('ABC123'))\n",
    "#noise_df\n",
    "#noise_df.values # as_matrix()\n",
    "#noise_df.index\n",
    "#noise_df.index.values #.dtype\n",
    "\n",
    "#noise_df.index.tolist()\n",
    "#noise_df.columns\n",
    "\n",
    "#noise_df.reset_index(inplace=True)\n",
    "#noise_df.rename(columns={'index': 'mybdayz'}, inplace=True)\n",
    "\n",
    "#noise_df.set_index(\"A\", inplace=True)\n",
    "#noise_df.reset_index().set_index(\"A\")\n",
    "\n",
    "#noise_df.rename(columns={'A': 'a'}, inplace=True)\n",
    "\n",
    "#noise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noise_df\n",
    "#noise_df.sort_index(axis=1, ascending=False)\n",
    "#noise_df.sort_index(axis=0, ascending=False)\n",
    "#noise_df.sort_values(by='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Accessing Data in Pandas\n",
    "* is kind of special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_ndarray[:4,:4]\n",
    "#is this a matrix?\n",
    "\n",
    "print noise_df.head()\n",
    "#noise_df.columns\n",
    "#noise_df[:4,:4]\n",
    "\n",
    "# ANSWER THESE\n",
    "#how to get rows?\n",
    "#noise_df[1]\n",
    "###bdays[7]\n",
    "#how to get columns?\n",
    "#noise_df['B']\n",
    "#.values\n",
    "#.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "watchOut_df = pd.DataFrame(np.random.randn(3,3), index=list('ABC'), columns=range(3))\n",
    "print watchOut_df\n",
    "print \"\"\n",
    "print watchOut_df.columns\n",
    "print \"\"\n",
    "\n",
    "#watchOut_df[:1]\n",
    "#watchOut_df[[0,1]]\n",
    "#watchOut_df[\"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.loc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_df[:3]\n",
    "print \"\"\n",
    "print bdays[:3]\n",
    "print \"\"\n",
    "print noise_df.columns, noise_df.columns.values, noise_df.columns.tolist()\n",
    "\n",
    "#noise_df.loc[bdays[7],[\"B\",\"C\"]]\n",
    "#noise_df.loc[[\"B\",\"C\"]] # hint: ,\n",
    "\n",
    "#noise_df.loc[:,[1,2]] # hint: \"\n",
    "#noise_df.loc[:3,[\"B\",\"C\"]] # hint: bdays[7]\n",
    "\n",
    "#noise_df.loc[bdays[:3],[\"B\",\"C\"]]\n",
    "#noise_df.loc[bdays[1]:bdays[3],[\"B\",\"C\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.iloc*\n",
    "* as opposed to the *.loc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_df.iloc[bdays[0]:bdays[3],[\"B\",\"C\"]]\n",
    "#print noise_df.iloc[2:5,2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.ix*\n",
    "* as opposed(?) to the *.loc* and the *.iloc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_df.ix[:4,1:3]\n",
    "print \"\"\n",
    "print noise_df.ix[:bdays[3],1:3]\n",
    "print \"\"\n",
    "print noise_df.ix[:4,['B','C']]\n",
    "print \"\"\n",
    "print noise_df.ix[:bdays[3],['B','C']]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.at/.iat*?\n",
    "* gets you a single scalar. fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Boolean Indexing (i.e., row selecting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OH, BTW, LOOK! READING IN CSV'S... \n",
    "# Just like with RDBMS's you can basically read in any file flavor you want...\n",
    "\n",
    "Schools_df = pd.read_csv(\"stuff/Schools.csv\")\n",
    "Players_df = pd.read_csv(\"stuff/SchoolsPlayers.csv\")\n",
    "\n",
    "# & | ~ == != VERSUS and or not equals\n",
    "\n",
    "pd.DataFrame(Schools_df[Schools_df.schoolState.isin([\"TX\"])])\n",
    "#reshape(3,13)\n",
    "# schoolNick.unique()\n",
    "# len()\n",
    "# .reshape(13,3)\n",
    "# pd.DataFrame()    \n",
    "# [['schoolNick', 'schoolCity',' schoolName']]\n",
    "# sort_values(by=['schoolNick','schoolCity'])\n",
    "\n",
    "#Schools_df[(Schools_df.schoolState.isin([\"TX\"]) & Schools_df.schoolNick.str.contains(\"Tigers\")) \n",
    "#           | ((Schools_df.schoolCity.astype(str) == \"Austin\") & \n",
    "#              (Schools_df[\"schoolName\"].astype(str) != \"University of Texas at Austin\")) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kp = (Schools_df.schoolState.isin([\"TX\"]) & Schools_df.schoolNick.str.contains(\"Tigers\")) | \\\n",
    "    ((Schools_df.schoolCity.astype(str) == \"Austin\") & ~(Schools_df.schoolName.astype(str) == \"University of Texas at Austin\"))\n",
    "print Schools_df.ix[kp, [\"schoolName\",\"schoolNick\"]]\n",
    "print \"\"\n",
    "print Schools_df.loc[kp, \"schoolName\":\"schoolNick\"]\n",
    "print \"\"\n",
    "print Schools_df.iloc[kp ,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_ndarray = np.random.randn(35,6)\n",
    "noise_df = pd.DataFrame(noise_ndarray, index=bdays, columns=list('ABC123'))\n",
    "print noise_df[:3]\n",
    "print \"\"\n",
    "noise_df[noise_df > 0]\n",
    "#noise_df[noise_df > 0] = 0\n",
    "#noise_df\n",
    "\n",
    "#.as_matrix()\n",
    "#mat[~np.isnan(mat)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# *Copy* versus *View* \n",
    "* and not accidentally editing another variables memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_ndarray = np.random.randn(35,6)\n",
    "noise_df = pd.DataFrame(noise_ndarray, index=bdays, columns=list('ABC123'))\n",
    "abs_noise_df = noise_df\n",
    "\n",
    "print \"noise_df[:3]\" \n",
    "print noise_df[:3] \n",
    "\n",
    "abs_noise_df[abs_noise_df < 0] = -abs_noise_df[abs_noise_df < 0] \n",
    "\n",
    "print \"\\n\"+\"abs_noise_df[:3]\"\n",
    "print abs_noise_df[:3] \n",
    "\n",
    "print \"\\n\"+\"noise_df[:3]\" \n",
    "print noise_df[:3] \n",
    "print \"\\n\"+\"noise_ndarray[:3]\" \n",
    "print noise_ndarray[:3] \n",
    "\n",
    "# Do you have a problem with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_ndarray = np.random.randn(35,6)\n",
    "noise_df = pd.DataFrame(noise_ndarray, index=bdays, columns=list('ABC123'))\n",
    "abs_noise_df = noise_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abs_noise_df[abs_noise_df < 0] = -abs_noise_df[abs_noise_df < 0] \n",
    "\n",
    "print \"abs_noise_df[:3]\"\n",
    "print abs_noise_df[:3] \n",
    "print \"\\n\"+\"noise_df[:3]\" \n",
    "print noise_df[:3] \n",
    "print \"\\n\"+\"noise_nparray[:3]\" \n",
    "print noise_nparray[:3] \n",
    "\n",
    "# much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df = pd.DataFrame({ 'A' : 1.,\n",
    "                     'B' : pd.Timestamp('20130102'),\n",
    "                     'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "                     'D' : np.array([3] * 4,dtype='int32'),\n",
    "                     'E' : pd.Categorical([\"test\",\"train\",\"test\",\"try\"]),\n",
    "                     'F' : 'foo' })\n",
    "\n",
    "mixedTypes_augmented_df = mixedTypes_df.copy()\n",
    "\n",
    "mixedTypes_augmented_df['F'] = mixedTypes_augmented_df['F'] + \" fighter\"\n",
    "mixedTypes_augmented_df['G'] = 'hommies'\n",
    "\n",
    "print \"mixedTypes_df\"\n",
    "print mixedTypes_df\n",
    "print \"\\n\"+\"mixedTypes_augmented_df\"\n",
    "print mixedTypes_augmented_df\n",
    "\n",
    "# columns can be removed with the del keyword (demonstrated later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df[mixedTypes_df.E==\"test\"]=np.nan\n",
    "print mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mixedTypes_df\n",
    "print \"\"\n",
    "print mixedTypes_df.dropna(how='any') #df.dropna(subset=['a']) # there's probably an \"inplace\"...\n",
    "print \"\"\n",
    "print mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df.F = mixedTypes_df['F'].fillna(value=\"I pity the\")\n",
    "\n",
    "print mixedTypes_df#.isnull()\n",
    "print \"\\n\"\n",
    "print pd.isnull(mixedTypes_df)\n",
    "print \"\\n\"\n",
    "print pd.notnull(mixedTypes_df)\n",
    "\n",
    "\n",
    "mixedTypes_df.loc[pd.isnull(mixedTypes_df.C),'D'] = 20\n",
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applying functions to Data\n",
    "## A.k.a., transforming data, doing stuff to data, etc.\n",
    "<br>\n",
    "$$\\huge \\text{NumPy Array} \\subset \\text{Pandas Series} \\subset \\text{Pandas DataFrame}$$\n",
    "\n",
    "* http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    noise_df.iloc[i,i] = np.nan\n",
    "\n",
    "print noise_df[:8]\n",
    "print \"\\n\" + \"mean, axis=0\"\n",
    "print noise_df.mean(axis=0) \n",
    "print \"\\n\" + \"mean, axis=1\"\n",
    "print noise_df.mean(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Schools_df.head()\n",
    "Schools_df.schoolState.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popular_names = Schools_df.schoolNick.value_counts()\n",
    "pd.set_option('display.max_rows',len(popular_names))\n",
    "print popular_names\n",
    "pd.set_option('display.max_rows',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_df.A[1:].quantile([0, .25, .5, .75, 1])\n",
    "print \"\"\n",
    "print pd.qcut(noise_df.A,[0, .25, .5, .75, 1])[:5]\n",
    "print \"\"\n",
    "print pd.cut(noise_df.A,3)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_df.apply(lambda x: x.max() - x.min()) #np.log(np.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* [Guru God Level Extra Credit] Transform versus Apply -- what's the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_df[:3]\n",
    "print \"\"\n",
    "print noise_df.describe()\n",
    "print \"\"\n",
    "print mixedTypes_df\n",
    "print \"\"\n",
    "print mixedTypes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Plotting\n",
    "* for good, not evil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "pylab.rcParams['figure.figsize']=(6,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.style.use('classic')\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "print plt.style.available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_nparray = np.random.randn(35,6)\n",
    "noise_df = pd.DataFrame(noise_nparray, index=bdays, columns=list('ABC123'))\n",
    "for i in range(6):\n",
    "    noise_df.iloc[i,i] = np.nan\n",
    "    \n",
    "random_walk_df = noise_df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print random_walk_df\n",
    "random_walk_df = random_walk_df.reset_index()\n",
    "print \"\"\n",
    "print random_walk_df.columns\n",
    "print \"\"\n",
    "print random_walk_df\n",
    "del random_walk_df['index'] # or df.drop('index', inplace=True, axis=1)\n",
    "print \"\"\n",
    "print random_walk_df.columns\n",
    "\n",
    "random_walk_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "random_walk_df.hist()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_walk_df.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize']=(17,5)\n",
    "random_walk_df.plot(kind='bar')\n",
    "pylab.rcParams['figure.figsize']=(7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(random_walk_df, alpha=0.9, figsize=(10, 10), diagonal='kde')\n",
    "pylab.rcParams['figure.figsize']=(6,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* http://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "* http://matplotlib.org\n",
    "* http://matplotlib.org/users/style_sheets.html\n",
    "* https://stanford.edu/~mwaskom/software/seaborn/ \n",
    "* http://bokeh.pydata.org/en/latest/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Elementwise Operations\n",
    "* with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize']=(7,5)\n",
    "standarized_walk_df = (random_walk_df - random_walk_df.mean()) / random_walk_df.std()\n",
    "\n",
    "plt.figure()\n",
    "standarized_walk_df.plot()\n",
    "pylab.rcParams['figure.figsize']=(6,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = noise_df[[\"1\",\"2\",\"3\"]] #.copy()? # tmp.iloc[1,1] = 1.0 # print noise_df.iloc[1,1]\n",
    "\n",
    "print noise_df[:6]\n",
    "print \"\"\n",
    "print tmp[:6]\n",
    "\n",
    "#tmp.columns = list('ABC')\n",
    "noise_df[[\"A\",\"B\",\"C\"]] + tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Concatenating\n",
    "* adding *rows*\n",
    "* see also: df.append()\n",
    "* http://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print noise_df[:3]\n",
    "print \"\"\n",
    "print noise_df[30:]\n",
    "print \"\"\n",
    "print pd.concat([noise_df[:3],noise_df[30:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([noise_df[[\"1\",\"2\",\"3\"]],noise_df[[\"A\",\"B\",\"C\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = noise_df[[\"1\",\"2\",\"3\"]]\n",
    "A = A.reset_index()\n",
    "del A['index']\n",
    "A.columns = list('ABC')\n",
    "\n",
    "B = noise_df[[\"A\",\"B\",\"C\"]]\n",
    "B = B.reset_index()\n",
    "del B['index']\n",
    "\n",
    "C = pd.concat([A,B])\n",
    "print C\n",
    "print \"\"\n",
    "print C.loc[1,:] # what's going on here with multiple results?\n",
    "print \"\"\n",
    "C = pd.concat([A,B],ignore_index=True)\n",
    "print C\n",
    "print \"\"\n",
    "print C.loc[1,:] # did that fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merging\n",
    "* adding *columns*\n",
    "* see also: df.join\n",
    "* http://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schools_df = pd.read_csv('stuff/Schools.csv')\n",
    "print schools_df[:3] \n",
    "print schools_df.shape\n",
    "players_df = pd.read_csv('stuff/SchoolsPlayers.csv')\n",
    "print \"\"\n",
    "print players_df[:3]\n",
    "print players_df.shape\n",
    "\n",
    "pd.merge(schools_df, players_df, on='schoolID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# SQL Style Joining\n",
    "* Left, right, inner, outer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo', 'bar'], 'lval': [1, 2, 3]})\n",
    "right = pd.DataFrame({'key': ['foo', 'foo','post'], 'rval': [\"A\", \"B\", \"C\"]})\n",
    "\n",
    "print \"X\"\n",
    "print left\n",
    "print \"\\n\" + \"Y\"\n",
    "print right\n",
    "print \"\\n\" + \"X outer join Y\"\n",
    "print pd.merge(left, right, on='key', how='outer')\n",
    "print \"\\n\" + \"X inner join Y\"\n",
    "print pd.merge(left, right, on='key', how='inner')\n",
    "print \"\\n\" + \"X left join Y\"\n",
    "print pd.merge(left, right, on='key', how='left')\n",
    "print \"\\n\" + \"X right join Y\"\n",
    "print pd.merge(left, right, on='key', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Group By\n",
    "* Aggregate, Apply\n",
    "* http://pandas.pydata.org/pandas-docs/stable/groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                   'B' : ['one', 'one', 'two', 'three',\n",
    "                          'two', 'two', 'one', 'three'],\n",
    "                   'C' : np.random.randn(8),\n",
    "                   'D' : np.random.randn(8)})\n",
    "\n",
    "print df\n",
    "print \"\"\n",
    "df.groupby('A').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.groupby(['A','B']).sum()\n",
    "print \"\"\n",
    "print df.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Remember, Sorting is just done as a sort -- *not* a Group By\n",
    "* You just sort by mulptiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.sort_values(by = ['A','C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Indexing\n",
    "* group by structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(names=['first', 'second'],\n",
    "            tuples = list(zip(['bar', 'bar', 'baz', 'baz','foo', 'foo', 'qux', 'qux'],\n",
    "                              ['one', 'two', 'one', 'two','one', 'two', 'one', 'two'])))\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Stacking\n",
    "* and unstacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked = df.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked.unstack() #.unstack() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print stacked\n",
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas supports all sorts of data types\n",
    "So we noted all the RDBMS support\n",
    "* http://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html\n",
    "* http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_query.html\n",
    "* http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html\n",
    "\n",
    "\n",
    "And we've seen CSV import capability \n",
    "\n",
    "Even .xlsx is supported\n",
    "* http://pandas.pydata.org/pandas-docs/stable/io.html\n",
    "\n",
    "\n",
    "So is Pickle\n",
    "\n",
    "So is pretty much everything else\n",
    "\n",
    "# And of course we can write out in all of these formats, as well\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jes = pd.read_excel(\"stuff/Robert Distribution Environmental Data 2016.08.04.xlsx\",\n",
    "                    skiprows=1).iloc[:38,:]\n",
    "\n",
    "jes.rename(columns = {'Evaluation Criteria':'Category', 'Unnamed: 1':'Evaluation Criteria'}, inplace = True)\n",
    "jes['Route 2'] = pd.to_numeric(jes['Route 2'])\n",
    "jes['Route 6'] = pd.to_numeric(jes['Route 6'])\n",
    "\n",
    "jes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pivot Tables\n",
    "* http://pandas.pydata.org/pandas-docs/version/0.15.2/reshaping.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(jes, index = ['Category', 'Priority'],\n",
    "               aggfunc = [len, max], values = ['Route 1', 'Route 7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_pd = pd.merge(Schools_df, Players_df, on='schoolID')\n",
    "pd.crosstab(m_pd.schoolState, m_pd.schoolNick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "# When will I _ever_ EVEN have to use Pandas? \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "E.g., \"When you need a team of animals to pull a sled across the expansive frozen tundra?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "# Actual Answer: all the time.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "So you might as well get good at it sooner rather than later... so...\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Some other \"Intro To Pandas\" notebooks that I like a lot\n",
    "* https://github.com/zipfian/DSI_Lectures/blob/master/pandas/sallamander/numpy_notes.ipynb\n",
    "* https://github.com/zipfian/DSI_Lectures/blob/master/pandas/numpy_pandas.ipynb  \n",
    "* http://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "\n",
    "# The Official Documentation\n",
    "* http://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "\n",
    "# An In-House Cheat Sheet\n",
    "* https://github.com/zipfian/precourse/tree/master/Chapter_4_Pandas#functions-i-use-all-the-time"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
