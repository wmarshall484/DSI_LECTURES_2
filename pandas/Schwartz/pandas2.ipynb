{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"hlmsjstN6Aw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# We're not saying \"no\" to Pandas, but first...\n",
    "* Connect to a Postgres server \n",
    "    * in python \n",
    "        * using psycopg2\n",
    "* Understand psycopg2's \"cursors\"\n",
    "    * executes\n",
    "    * commits\n",
    "* Generate dynamic queries\n",
    "\n",
    "# psycopg2 is a python/postgreSQL server interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install homebrew: http://brew.sh\n",
    "\n",
    "# brew cask install postgres -> double click -> applications\n",
    "### not needed ### brew cask install pgadmin4 -> double click -> applications, click plug\n",
    "# brew tap homebrew/services\n",
    "# brew services start postgresql\n",
    "\n",
    "# https://github.com/zipfian/welcome/blob/master/notes/postgres_setup.md\n",
    "\n",
    "# pip install psycopg2\n",
    "# conda install psycopg2\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/zipfian/precourse/tree/master/Chapter_3_SQL/data\n",
    "# psql -f stuff/beds.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: open a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ALTER USER schwarls37 ENCRYPTED PASSWORD 'need a password';\n",
    "\n",
    "conn = psycopg2.connect(dbname='schwarls37',port=5432,password=\"\",\n",
    "                        user='schwarls37',host='localhost')\n",
    "\n",
    "# host could be a remote database as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td><img src=\"stuff/whywouldyoudothat1.jpg\" width=\"300px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/whywouldyoudothat2.jpg\" width=\"415px\" align=\"center\"></td> \n",
    "</tr>\n",
    "</table>\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td><img src=\"stuff/whywouldyoudothat3.jpg\" width=\"400px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/whywouldyoudothat4.jpg\" width=\"305px\" align=\"center\"></td> \n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Allows us to combine data sources in one place\n",
    "* Can use python to simultaneously pull data from other databases as well \n",
    "    * mysql-connector-python (MySql)\n",
    "    * sqlite (SQLite)\n",
    "    * pymongo (MongoDB)\n",
    "    * sqlalchemy (all the things)\n",
    "    * [psychopg2 (postgreSQL), obviously]\n",
    "\n",
    "## Allows us to bring other python tools to bear\n",
    "* DataFrames and associated functionality, Machine Learning tools, etc.\n",
    "\n",
    "## Allows for easy dynamic query generation\n",
    "* And hence, automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: create a cursor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "#cur.close()\n",
    "\n",
    "# The cursor interfaces and traverses the database \n",
    "# We don't have to worry about how it does it\n",
    "# Queries are returned as (single iteration) generators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: execute some SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''SELECT \"facility_name\", \"available_residential_beds\" \n",
    "           FROM Beds \n",
    "           WHERE \"city\" = 'Cuba' \n",
    "           LIMIT 10;'''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you see this error \n",
    "\n",
    "print \"InternalError: current transaction is aborted, commands ignored until end of transaction block\"\n",
    "\n",
    "# Then the cursor is chocking on a current command \n",
    "# and it needs to be aborted with: conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in cur:\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in cur:\n",
    "    print row\n",
    "    \n",
    "# See, I told you: cur saves results as a (one pass) generator    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other options for iterating through the generator\n",
    "\n",
    "# cur.fetchone(), or cur.next()\n",
    "# cur.fetchmany(n)\n",
    "# cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''ALTER TABLE Beds \n",
    "           RENAME COLUMN \"available_residential_beds\" \n",
    "           TO \"Available Residential Beds\"'''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: commit SQL actions \n",
    "### (to actually make the changes to the DB permanent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "# conn.autocommit = True\n",
    "\n",
    "# database level operations are also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''ALTER TABLE Beds \n",
    "           RENAME COLUMN \"Available Residential Beds\" \n",
    "           TO \"available_residential_beds\"'''\n",
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# $$\\textbf{Sanitize your queries}$$\n",
    "\n",
    "<table align=\"center\">\n",
    "<tr><td>\n",
    "<img src=\"stuff/exploits_of_a_mom.png\" width=\"600px\" align=\"center\"> \n",
    "</tr></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_name = \"Scott\"\n",
    "unsafe_query = '''SELECT * FROM Users \n",
    "                  WHERE Name = ''' + my_name\n",
    "\n",
    "# what if...\n",
    "my_name = \"Scott; DROP TABLE Users\"\n",
    "\n",
    "# This is called SQL Injection and it's obviously risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instead \n",
    "my_name = \"Scott; DROP TABLE Users\"\n",
    "\n",
    "cur.execute('''SELECT * FROM Users WHERE Name = %s''', my_name)\n",
    "\n",
    "# will search for rows in Name *exactly* equal to 'Scott; DROP TABLE Users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close() # optional, automatically close with conn.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or... \n",
    "\n",
    "# just read directly into a pandas data frame... which we shall begin learning about: now.\n",
    "\n",
    "conn = psycopg2.connect(dbname='schwarls37',port=5432,password=\"\",\n",
    "                        user='schwarls37',host='localhost')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "query = '''SELECT \"facility_name\", \"available_residential_beds\" \n",
    "           FROM Beds \n",
    "           WHERE \"city\" = 'Cuba' \n",
    "           LIMIT 10;'''\n",
    "rows = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$\\textit{pandas}$$\n",
    "$$\\text{Schwartz}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $$\\textbf{They're not on the endangered species list any more}$$\n",
    "# $$\\textbf{How China saved the Giant Panda}$$\n",
    "\n",
    "As of September 2016 the International Union for the Conservation of Nature (IUCN) has taken the global icon off the endangered species list. The giant panda is now listed as \"vulnerable\" as opposed to \"endangered\". Thanks to Chinese conservation efforts the Giant Panda population has increased to approximately 2,000 individuals up from a low of about 1,000 in the 1970's when the species was at the most risk.  This population increase has been the result of bamboo forest restoration projects and the incorporation of improved captive breeding and husbandry methods -- initiatives driven by a better understanding of Giant Panda physiology and behaviour. Challenges remain, however. Climate change is predicted to wipe out more than one-third of the panda's bamboo habitat in the next 80 years, and reintroduction of captive-bred pandas into the wild remains challenging. \n",
    "\n",
    "<table align=\"center\">\n",
    "<tr><td>\n",
    "<img src=\"stuff/pandas.png\" width=\"600px\" align=\"center\"> \n",
    "</tr></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"RDrfE9I8_hs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# QUIZ\n",
    "\n",
    "* 1:\n",
    "* 2:\n",
    "* 3:\n",
    "* 4:\n",
    "* 5:\n",
    "* Bonus #1:\n",
    "* Bonus #2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Pandas are cute cuddly animals\n",
    "* They are also the Flying Circus' answer to Excel and R Data Frames\n",
    "* They are built on top of NumPy NdArrays\n",
    "* http://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html\n",
    "\n",
    "# Objectives\n",
    "* psycopg2\n",
    "    * obviously the quizze stuff above\n",
    "* numpy\n",
    "    * Speed\n",
    "    * Broadcasting\n",
    "* Pandas Series\n",
    "    * Pandas Time Series Type\n",
    "* Pandas DataFrames\n",
    "    * Creating and destroying columns\n",
    "    * Merging/Joining DataFrames\n",
    "    * Concatenating/Appening DataFrames\n",
    "    * Sorting\n",
    "    * Accessing data\n",
    "    * Manipulating the DataFrame Index    \n",
    "* Exploratory Data Analysis (EDA) with Matplotlib and Pandas \n",
    "    * Grouping/Aggregation\n",
    "    * Creating pivot tables\n",
    "    * Applying functions/plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas is very functional\n",
    "\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td><img src=\"stuff/panda7.jpg\" width=\"300px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda2.jpg\" width=\"180px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda6.jpg\" width=\"475px\" align=\"center\"></td> \n",
    "<tr><td>Killer Panda</td><td>Red Handed Panda</td><td>Sexy Panda</td></tr>\n",
    "\n",
    "\n",
    "</tr>\n",
    "</table>\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "\n",
    "<td><img src=\"stuff/panda4.jpg\" width=\"230px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda3.jpg\" width=\"300px\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda1.jpg\" width=\"205x\" align=\"center\"></td> \n",
    "<td><img src=\"stuff/panda8.jpg\" width=\"210px\" align=\"center\"></td> \n",
    "<tr><td>Lone Ranger Panda</td><td>Assisted Pushup Panda</td><td>Acrobat Panda (Beginner)</td><td>Acrobat Panda (Advanced)</td></tr>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# (Standard Library) Lists\n",
    "* concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1,2,3] + [4,5,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numpy NdArrays\n",
    "* operate elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([1,2,3]) + np.arange(3) + np.linspace(10,12,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numpy NdArrays\n",
    "\n",
    "* have types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ints = np.array(range(3))\n",
    "chars = np.array(list('ABC'))\n",
    "strings = np.array(['A','BC',\"DEF\"])\n",
    "\n",
    "print ints.dtype, chars.dtype, strings.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Speed\n",
    "\n",
    "https://ipython.org/ipython-doc/3/interactive/magics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy_array = np.arange(0, 1000000)\n",
    "python_list = range(1000000)\n",
    "\n",
    "print \"python list\"\n",
    "time = %timeit -r 1 -o sum(python_list)\n",
    "print time.all_runs[0]/time.loops \n",
    "\n",
    "print \"\\n\" + \"numpy array\"\n",
    "time = %timeit -r 1 -o np.sum(numpy_array)\n",
    "print time.all_runs[0]/time.loops\n",
    "\n",
    "print \"\\n\" + \"numpy array -- standard library sum\"\n",
    "time = %timeit -r 1 -o sum(numpy_array)\n",
    "print time.all_runs[0]/time.loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Broadcasting\n",
    "\n",
    "http://docs.scipy.org/doc/numpy-1.10.1/user/basics.broadcasting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[10], [-10]]) \n",
    "b = np.array([[1, 2], [-1, -2]]) \n",
    "\n",
    "print a.shape, b.shape \n",
    "print \"\\n\"\n",
    "print a + b\n",
    "\n",
    "# elements will \"duplicate, expand, and fill up\" \n",
    "# to make the dimensions compatible for element-wise operations\n",
    "# cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[10, 0, -10, 0],[-10, 0, -10, 0]]) \n",
    "b = np.array([[2,2],[-1,0]]) \n",
    "print a.shape, b.shape \n",
    "print \"\"\n",
    "print a + b\n",
    "\n",
    "# it's not clear how it should fill up in this case... so it can't/doesn't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Dimentia..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 10\n",
    "#a = np.array(10)\n",
    "#a = np.array([10])\n",
    "#a = np.array([[[10]]])\n",
    "#a = np.array([[10],[10]])\n",
    "b = np.array([[1,2],[-1,-2]])\n",
    "\n",
    "print a.shape, b.shape\n",
    "print \"\\n\"\n",
    "print a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notes:\n",
    "\n",
    "# a.shape can be assigned into to change the shape with compatible shapes\n",
    "# a.reshape() can be used to change shape as well to compatible shapes \n",
    "\n",
    "# see also a.flatten() and a.ravel(), which leads us to the following... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aliasing Amnesia... \n",
    "* *Copy* versus *View* (and not accidentally editing another variables memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = [1, 2]\n",
    "zz = z#[:]\n",
    "zz[0]=11\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.array([[1,2],[-1,-2]])\n",
    "print b\n",
    "print \"\"\n",
    "\n",
    "c = b#[:]#.copy()#\n",
    "# also see \"deepcopy()\"\n",
    "c[0,0]=666\n",
    "\n",
    "print c\n",
    "print \"\"\n",
    "print b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas Series\n",
    "* are (one dimensional) np.ndarray vectors **with an index**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series = pd.Series([5775,373,7,42,np.nan,33])\n",
    "print series\n",
    "print \"\\n\"\n",
    "print series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_series = pd.Series([\"cubs\",\"royals\",\"giants\",\"sox\",\"giants\",\"cards\",\"giants\",\"...\",None])\n",
    "world_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas Date Series\n",
    "* are fancy: http://pandas.pydata.org/pandas-docs/stable/timeseries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdays = pd.date_range(start='19821107', periods=34+1, freq=pd.DateOffset(years=1))\n",
    "bdays#.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### After you learn Pandas you might care about using Date Series Types and the following could be useful:\n",
    "* df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n",
    "* df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas DataFrames\n",
    "* are a set of Pandas Series **that share the same index** \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$\\large \\text{Python List} \\subset \\text{NumPy Array} \\subset \\text{Pandas Series} \\subset \\text{Pandas DataFrame}$$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df = pd.DataFrame({ '0' : [np.nan] + 3 * [1.],\n",
    "                               'b' : pd.Timestamp('20130102'),\n",
    "                               'C' : pd.Series(3, index=list(range(4)), dtype='float32'),\n",
    "                               '1' : np.array(4 * [1], dtype='int32'),\n",
    "                                2  : pd.Categorical([\"train\", \"test\", \"validate\", \"win\"]),\n",
    "                                3 : 2*[np.nan, 'foo'] }) #, index=bdays[:4]\n",
    "print mixedTypes_df\n",
    "print \"\"\n",
    "print mixedTypes_df.shape\n",
    "print \"\"\n",
    "mixedTypes_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Managing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df.rename(columns={'b': 'B'}, inplace=True)\n",
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(mixedTypes_df['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(mixedTypes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del mixedTypes_df['1']\n",
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_augmented_df = mixedTypes_df.copy() # de-referencing\n",
    "\n",
    "mixedTypes_df.index = bdays[:4]\n",
    "\n",
    "mixedTypes_augmented_df[2] = mixedTypes_augmented_df[2] + np.array([\", I\"]*4) # element-wise\n",
    "mixedTypes_augmented_df[2] = mixedTypes_augmented_df[2] + \" must\" # broadcasting\n",
    "mixedTypes_augmented_df['G'] = 'hommies' # broadcasting\n",
    "\n",
    "print \"mixedTypes_df\"\n",
    "print mixedTypes_df\n",
    "print \"\\n\"+\"mixedTypes_augmented_df\"\n",
    "print mixedTypes_augmented_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Accessing Data part I: skeletons\n",
    "* is kind of special in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting columns\n",
    "mixedTypes_augmented_df[\"G\"]\n",
    "mixedTypes_augmented_df.G#.values#.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mixedTypes_df.index\n",
    "print \"\"\n",
    "print mixedTypes_df.index.values# .dtype # type()\n",
    "print \"\"\n",
    "print mixedTypes_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mixedTypes_df.columns\n",
    "print \"\"\n",
    "print mixedTypes_df.columns.values #.dtype\n",
    "print \"\"\n",
    "print mixedTypes_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Accessing Data part II: innards\n",
    "* is kind of special in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones((10,10))[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeros_ndarray = np.zeros((3,4))        # Create a matrix of zeros with 3 rows and 4 columns. \n",
    "ones_ndarray = np.ones((10,20))        # Create a matrix of ones with 10 rows and 20 columns.\n",
    "identity_ndarray = np.identity(50)     # Create an identity matrix with 50 rows and 50 columns. \n",
    "random_ndarray = np.random.rand(2, 2)  # Create a 2x2 array of random floats ranging from 0 to 1. \n",
    "range_ndarray = np.arange(0, 20, 0.5)  # Create a numpy array with arguments (start, end, step_size). \n",
    "noise_nparray = np.random.randn(35, 6) # Create a 35x6 array of normally distributed random normal variables\n",
    "\n",
    "identity_ndarray[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df.head()\n",
    "mixedTypes_df[:3,:3]\n",
    "# is mixedTypes_df a matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mixedTypes_df.values#[:3,:3] \n",
    "mixedTypes_df.as_matrix() # type(\n",
    "\n",
    "# are these the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting columns\n",
    "mixedTypes_df[[2,3,\"0\",\"B\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting rows\n",
    "print bdays[1]\n",
    "mixedTypes_df[:bdays[1]] # hint: \"slice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz 1\n",
    "#-------\n",
    "mixedTypes_df[:1]\n",
    "#mixedTypes_df[2:3]\n",
    "#mixedTypes_df[[2,3]]\n",
    "#mixedTypes_df[2]\n",
    "#mixedTypes_df[1]\n",
    "#mixedTypes_df[0]\n",
    "#mixedTypes_df['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df = mixedTypes_df.reset_index()\n",
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz 2\n",
    "#-------\n",
    "\n",
    "mixedTypes_df[:1]\n",
    "#mixedTypes_df[2:3]\n",
    "#mixedTypes_df[[2,3]]\n",
    "#mixedTypes_df[2]\n",
    "#mixedTypes_df[1]\n",
    "#mixedTypes_df[0]\n",
    "#mixedTypes_df['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df = mixedTypes_df.set_index('index')\n",
    "del mixedTypes_df.index.name\n",
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Accessing Data part III: open sesame and abracadabra\n",
    "* is kind of special in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.loc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df.loc[[\"B\",\"C\"]] # hint: :,\n",
    "#mixedTypes_df.loc[1:3,[\"B\",\"C\"]] # hint: bdays[1]:bdays[3]\n",
    "#mixedTypes_df.loc[3,[\"B\",\"C\"]] # hint: bdays[3]\n",
    "#mixedTypes_df.loc[:,[\"2\",\"3\"]] # hint: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.iloc*\n",
    "* as opposed to the *.loc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mixedTypes_df.iloc[2:4,2:4]\n",
    "print mixedTypes_df.iloc[:bdays[3],[\"B\",\"C\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.ix*\n",
    "* as opposed(?) to the *.loc* and the *.iloc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mixedTypes_df.ix[:3,1:3]\n",
    "print \"\"\n",
    "print mixedTypes_df.ix[:bdays[3],1:3]\n",
    "print \"\"\n",
    "print mixedTypes_df.ix[:3,['B','C']]\n",
    "print \"\"\n",
    "print mixedTypes_df.ix[:bdays[3],[2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The *.at/.iat*?\n",
    "* gets you a single scalar. fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pandas talks to all sorts of data types\n",
    "## SQL, csv, .xlsx, pickle, etc.\n",
    "* http://pandas.pydata.org/pandas-docs/stable/io.html\n",
    "* https://docs.python.org/2/library/pickle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Schools_df = pd.read_csv(\"stuff/Schools.csv\")\n",
    "Schools_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applying functions to Data\n",
    "## A.K.A., transforming data, doing stuff to data, etc.\n",
    "<br>\n",
    "$$\\LARGE \\text{NumPy Array} \\subset \\text{Pandas Series} \\subset \\text{Pandas DataFrame}$$\n",
    "\n",
    "* http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Filtering (i.e., row selecting or boolean indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# & | ~ == != VERSUS and or not equals\n",
    "\n",
    "Schools_df[(Schools_df.schoolState.isin([\"TX\"]) & Schools_df.schoolNick.str.contains(\"Tigers\")) \n",
    "           | ((Schools_df.schoolCity.astype(str) == \"Austin\") & \n",
    "              (Schools_df[\"schoolName\"].astype(str) != \"University of Texas at Austin\")) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kp = (Schools_df.schoolState.isin([\"TX\"]) & Schools_df.schoolNick.str.contains(\"Tigers\")) | \\\n",
    "    ((Schools_df.schoolCity.astype(str) == \"Austin\") & ~(Schools_df.schoolName.astype(str) == \"University of Texas at Austin\"))\n",
    "\n",
    "print Schools_df.ix[kp, [\"schoolName\",\"schoolNick\"]]\n",
    "print \"\"\n",
    "print Schools_df.loc[kp, \"schoolName\":\"schoolNick\"]\n",
    "print \"\"\n",
    "print Schools_df.iloc[kp ,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Schools_df[Schools_df.schoolNick.notnull() & Schools_df.schoolState.isin([\"TX\"])].schoolNick.reshape(5,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Managing Missing Values\n",
    "* http://pandas.pydata.org/pandas-docs/stable/missing_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mixedTypes_df\n",
    "print \"\"\n",
    "print mixedTypes_df.dropna(how='any') # subset=['0'], inplace=True\n",
    "print \"\"\n",
    "print mixedTypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixedTypes_df[3]= mixedTypes_df[3].fillna(value=\"I pity the\")\n",
    "print mixedTypes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Group By\n",
    "* Aggregate, Apply\n",
    "* http://pandas.pydata.org/pandas-docs/stable/groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Schools_df.groupby(['schoolState'])[['schoolID']].count().head()\n",
    "#Schools_df.schoolState.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pivot Tables\n",
    "* http://pandas.pydata.org/pandas-docs/version/0.15.2/reshaping.html#pivot-tables-and-cross-tabulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nicknames_states = pd.crosstab(Schools_df.schoolNick, Schools_df.schoolState) \n",
    "nicknames_states.ix[\"Tigers\":\"Vandals\",\"IN\":\"VA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nicknames_states['total'] = nicknames_states.T.sum() # axis=1\n",
    "nicknames_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nicknames_states.loc['total'] = (nicknames_states.sum(axis=0).values)\n",
    "nicknames_states.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nicknames_states.sort_values(axis=0, by=['total'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('stuff/PostsForAnalysis.txt')\n",
    "users_df = pd.read_csv('stuff/UsersForAnalysis.txt')\n",
    "posts_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print posts_df.comments_count.quantile([0, .25, .5, .75, 1])\n",
    "print \"\"\n",
    "print pd.qcut(posts_df.comments_count, [0, .25, .5, .75, 1])[:5]\n",
    "print \"\"\n",
    "print pd.cut(posts_df.comments_count, 5)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .apply - more Aggregations and Transformations\n",
    "* [Guru God Level Extra Credit] Transform versus Apply -- what's the difference?\n",
    "* see also: df.isnull, df.notnull, pd.isnull, pd.notnull\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show combining columns \n",
    "((posts_df.comments_count/posts_df.votes_count)*np.log(posts_df.votes_count))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_df.twitter_username.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_df.headline.apply(lambda x: \"Boss\" if \"founder\" in str(x).lower() or \"ceo\" in str(x).lower() else \"Nots\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_df[:10].created_at.apply(pd.to_datetime).apply(lambda x: (x - pd.to_datetime('2013-11-21T23:06:54.070-08:00')) / np.timedelta64(1, 'D')).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "posts_df.ix[:, \"date\":\"time_of_day\"].apply(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merge \n",
    "* http://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "* adding *columns*\n",
    "* see also: df.join\n",
    "* Inner, Left, Right, Outer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo', 'bar'], 'lval': [1, 2, 3]})\n",
    "right = pd.DataFrame({'key': ['foo', 'foo','post'], 'rval': [\"A\", \"B\", \"C\"]})\n",
    "\n",
    "print \"X\"\n",
    "print left\n",
    "print \"\\n\" + \"Y\"\n",
    "print right\n",
    "print \"\\n\" + \"X outer join Y\"\n",
    "print pd.merge(left, right, on='key', how='outer')\n",
    "print \"\\n\" + \"X inner join Y\"\n",
    "print pd.merge(left, right, on='key', how='inner')\n",
    "print \"\\n\" + \"X left join Y\"\n",
    "print pd.merge(left, right, on='key', how='left')\n",
    "print \"\\n\" + \"X right join Y\"\n",
    "print pd.merge(left, right, on='key', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_users_df = pd.merge(posts_df, users_df, on='user_id')\n",
    "posts_users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Concatenating\n",
    "* adding *rows*\n",
    "* see also: df.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([posts_users_df[:3],posts_users_df[-3:]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([posts_users_df[[\"id\",\"date\",\"day\"]],posts_users_df[[\"headline\",\"twitter_username\",\"website_url\"]]], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Indexing\n",
    "* group by structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(names=['first', 'second'],\n",
    "            tuples = list(zip(['bar', 'bar', 'baz', 'baz','foo', 'foo', 'qux', 'qux'],\n",
    "                              ['one', 'two', 'one', 'two','one', 'two', 'one', 'two'])))\n",
    "df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked = df.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked.unstack() #.unstack() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked.unstack(0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Plotting\n",
    "* for good, not evil\n",
    "* http://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "* http://matplotlib.org\n",
    "* http://matplotlib.org/users/style_sheets.html\n",
    "* https://stanford.edu/~mwaskom/software/seaborn/ \n",
    "* http://bokeh.pydata.org/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "pylab.rcParams['figure.figsize']=(6,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.style.use('classic')\n",
    "#matplotlib.style.use('ggplot')\n",
    "#print plt.style.available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeros_ndarray = np.zeros((3,4))        # Create a matrix of zeros with 3 rows and 4 columns. \n",
    "ones_ndarray = np.ones((10,20))        # Create a matrix of ones with 10 rows and 20 columns.\n",
    "identity_ndarray = np.identity(50)     # Create an identity matrix with 50 rows and 50 columns. \n",
    "random_ndarray = np.random.rand(2, 2)  # Create a 2x2 array of random floats ranging from 0 to 1. \n",
    "range_ndarray = np.arange(0, 20, 0.5)  # Create a numpy array with arguments (start, end, step_size). \n",
    "noise_nparray = np.random.randn(35,6)  # Create a 35x6 array of normally distributed random normal variables\n",
    "\n",
    "noise_df = pd.DataFrame(noise_nparray, index=bdays, columns=list('ABC123'))\n",
    "for i in range(6):\n",
    "    noise_df.iloc[i,i] = np.nan\n",
    "    \n",
    "random_walk_df = noise_df.apply(np.cumsum)\n",
    "standarized_walk_df = (random_walk_df - random_walk_df.mean()) / random_walk_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "standarized_walk_df = standarized_walk_df.reset_index()\n",
    "print standarized_walk_df\n",
    "del standarized_walk_df['index'] # or df.drop('index', inplace=True, axis=1)\n",
    "\n",
    "standarized_walk_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "random_walk_df.hist()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_walk_df.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize']=(17,5)\n",
    "random_walk_df.plot(kind='bar')\n",
    "pylab.rcParams['figure.figsize']=(7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(random_walk_df, alpha=0.9, figsize=(10, 10), diagonal='kde')\n",
    "pylab.rcParams['figure.figsize']=(6,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "# When will I ever even have to use Pandas? \n",
    "\n",
    "\"Is it when I need a team of hardy animals to pull me across the expansive frozen tundra in a sled?\"\n",
    "\n",
    "<br>\n",
    "# Answer: all the time.\n",
    "So you might as well get good at it sooner rather than later... \n",
    "\n",
    "### Some other \"Intro To Pandas\" notebooks that I like a lot\n",
    "* https://github.com/zipfian/DSI_Lectures/blob/master/pandas/sallamander/numpy_notes.ipynb\n",
    "* https://github.com/zipfian/DSI_Lectures/blob/master/pandas/numpy_pandas.ipynb  \n",
    "* http://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "\n",
    "### The Official Documentation\n",
    "* http://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "\n",
    "### An In-House Cheat Sheet\n",
    "* https://github.com/zipfian/precourse/tree/master/Chapter_4_Pandas#functions-i-use-all-the-time"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
