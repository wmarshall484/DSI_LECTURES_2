{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "## What is Pandas?\n",
    "A Python library providing data structures and data analysis tools.\n",
    "\n",
    "## Huh?\n",
    "Think of it like Excel for Python that doesn't suck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#By convention import pandas like:\n",
    "import pandas as pd\n",
    "#For fake data.\n",
    "from numpy.random import randn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series\n",
    "Think of a Pandas Series as a _labeled_ one-dimensional vector. In fact, it need not be a numeric vector, it can contain arbitrary python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_series = pd.Series([i + 10 for i in xrange(10)])\n",
    "int_series.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_series = pd.Series(randn(10)) #randn(10) samples 10 values at random from a normal distribution of mean 0 and std 1\n",
    "num_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_series = pd.Series([x for x in 'abcde'*2])\n",
    "str_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_series = pd.Series([lambda x: x*i for i in range(10)])\n",
    "fun_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes.\n",
    "Notice how each series has an index (in this case a relatively meaningless default index).\n",
    "\n",
    "Pandas can make great use of informative indexes. **Indexes work similarly to a dictionary key**, allowing fast lookups of the data associated with the index.\n",
    "\n",
    "Indexes can also be exploited for fast group-bys, merges, time-series operations and lots more.\n",
    "\n",
    "When you're really in the zone with pandas, you'll be thinking a lot about indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_series = pd.Series(randn(5), \n",
    "                           index = ['California', 'Alabama', \n",
    "                                    'Indiana', 'Montana', \n",
    "                                    'Kentucky']) #order of indices maintained\n",
    "alt_indexed_series = pd.Series(randn(5),\n",
    "                               index = ['Washington', 'Alabama', \n",
    "                                        'Montana', 'Indiana', \n",
    "                                        'New York']) #order of indices maintained\n",
    "\n",
    "series_from_dict = pd.Series({'key1':1,'key0':0,'key5':5,'key3':6,'key2':7}) #dictionaries have no order, indices will be sorted\n",
    "\n",
    "print indexed_series\n",
    "print '\\n'\n",
    "print alt_indexed_series\n",
    "print '\\n'\n",
    "print series_from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas uses the index by default to align series for arithmetic!\n",
    "indexed_series + alt_indexed_series #matching indices will be added!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_series = pd.Series(randn(5*100), \n",
    "                           index = ['California', 'Alabama', \n",
    "                                    'Indiana', 'Montana', \n",
    "                                    'Kentucky']*100)\n",
    "\n",
    "#If you have non-unique indexes, you can use them \n",
    "#to do groupby operations.\n",
    "\n",
    "# indexed_series\n",
    "indexed_series.groupby(level=0).mean() #will be grouped by state and the mean calculated for each gruop (state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_series['Alabama'] \n",
    "#there are 100 values for each state now, this is different from a dictionary and more like a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datetime index\n",
    "dt_index = pd.date_range('2015-1-1', \n",
    "                        '2015-11-1', \n",
    "                        freq='M')\n",
    "dt_series = pd.Series(randn(10), \n",
    "                      index = dt_index)\n",
    "dt_series #will use last of each month by default, beginning of month by donig 'MS' (Capital! otherwise millisecond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datetime indexes make it easy to transform frequencies etc! Behaves similarly to group_by\n",
    "dt_series.resample('q').mean()\n",
    "#note for last quarter the mean is just the same as the October value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_series #still the same, no transformation in place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "Data frames extend the concept of Series to table-like data.\n",
    "\n",
    "Many Series with shared indices. Looks very much like a database table!\n",
    "\n",
    "Can also defign column names/indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(randn(10, 5), index=dt_index, columns=[x for x in 'abcde'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A dataframes columns are series:\n",
    "col = df.a\n",
    "print col\n",
    "type(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'] #same as df.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So are the rows.\n",
    "row = df.loc['2015-01-31'] #ix needs to be used for rows instead of direct indexing like for columns\n",
    "type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select row by row label\n",
    "df.loc['2015-01-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select row by index\n",
    "df.iloc[0] #this means first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select row by either label OR index, tries by label and falls back to index if label not found\n",
    "print df.ix['2015-01-31']\n",
    "print df.ix[0]\n",
    "#note: planned for deprecation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The columns all have the same index:\n",
    "col.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What's the index for the rows?\n",
    "row.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#New column\n",
    "df['new'] = df['a'] + df['b']\n",
    "df['new2'] = 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'] + df['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Delete a column\n",
    "df = df.drop('new', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axis?\n",
    "Because pandas thinks of rows and columns as both being series, anything we can do to rows we can do to columns too. \n",
    "\n",
    "Axis describes which one we want to do it to. 0=rows, 1=columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lbl = pd.Timestamp('2015-04-30 00:00:00', freq='M')\n",
    "print lbl\n",
    "df.drop(lbl, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df #april still there! not done in place!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting subsets.\n",
    "There a couple of ways to select a subset of a python data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To subset the rows, you can use the convenient:\n",
    "df[df['a'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df['a'] > 0 #boolean filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or combine multiple conditions:\n",
    "df[(df.a > 0) & (df.c < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting a column\n",
    "df.a\n",
    "#Works sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'] #works always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['a', 'b']]\n",
    "#Or a subset of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced selection.\n",
    "The above methods work for simple types of selections, but what if you need something more complex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2015-05-31':'2015-08-31', 'c':'e'] #Ranges by label. List arrays + dictionaries together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df #still the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:-3,2:5] #Ranges by index number. Like arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL-like queries for row selection.\n",
    "#Experimental\n",
    "df.query('a > 1 and c <1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi Index:\n",
    "dt_index = pd.date_range('2015-1-1', \n",
    "                        '2017-7-1', \n",
    "                        freq='m')\n",
    "df = pd.DataFrame(randn(30,5), index=dt_index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'] = ['Alabama', 'Alaska' , 'Arizona'] * 10\n",
    "df.head() #creates new column with old indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.set_index(['state', 'index']) #makes state a new index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can now select by state\n",
    "df.loc['Alabama'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc['2015-01-31'] #Doesn't work. Date is not priary index anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('Alabama', '2015-01-31')] #Can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can also have multi-index in columns.\n",
    "df.reset_index().set_index(['index', 'state']).unstack().head() #unstack() pivots the table\n",
    "#Pivot a level of the (necessarily hierarchical) index labels, \n",
    "#returning a DataFrame having a new level of column labels \n",
    "#whose inner-most level consists of the pivoted index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(15) #same old, not in place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split-apply-combine\n",
    "* **Splitting** the data into groups based on some criteria\n",
    "* **Applying** a function to each group independently\n",
    "* **Combining** the results into a data structure\n",
    "\n",
    "Similar to SQL aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level=0).mean() #level=1 is state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same thing:\n",
    "df.groupby(level=0).apply(np.mean) #level=1 is state\n",
    "#groupby_object.apply(function to apply to each group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level=1).mean().head() #Groupby index #level=1 is date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby doesn't have to be on index. Can be on any regular column!\n",
    "df.reset_index().head().groupby('state').mean().head()\n",
    "#'state' could be replaced with a list of columns to group on, say ['state','city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split \n",
    "g = df.groupby(level=0)\n",
    "#create groupby object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply\n",
    "#If one row for each index.\n",
    "#g.aggregate(np.mean)\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.apply(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more fancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.apply(lambda x: (x - x.mean())/x.std()).head()\n",
    "#standardize each cell using group mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.apply(lambda x: x.describe())\n",
    "#describe each group as if it was its own dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip the following three cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#.transform() returns an object of the same shape as original df being grouped\n",
    "# a transform should be a reducing function and needs to return a scalar; \n",
    "#i.e. it returns a value for each value in the frame\n",
    "# apply can handle a transform or an arbitrary return for each group\n",
    "#print df.head()\n",
    "#print g.apply(lambda x: (x - x.mean())/x.std()).head()\n",
    "#print g.transform(lambda x: (x - x.mean())/x.std()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Different index than I started with.\n",
    "#g.apply(lambda x: x.describe()) #cannot use transform here because result different shape and index than original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('saved_data.csv', sep='\\t') #saves DF as tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read = pd.read_csv('saved_data.csv', sep='\\t')\n",
    "#TONS OF options for reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Other methods:\n",
    "pd.read_excel\n",
    "pd.read_sql\n",
    "pd.read_stata\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other very useful things.\n",
    "\n",
    "join, concat and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df = pd.DataFrame({'governor':['Robert Bentley',\n",
    "                                    'Bill Walker',\n",
    "                                    'Doug Ducey',\n",
    "                                    'Asa Hutchinson']}, \n",
    "                        index=['Alaska', 'Alabama', 'Arizona', 'Arkansas'])\n",
    "state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note merge is most useful when you want to merge on something other than the index.\n",
    "#Default is to merge on common column names.\n",
    "pd.merge(df.reset_index(), state_df, \n",
    "          left_on='state', right_index=True, how='left').tail() \n",
    "#left: use only keys from left frame, similar to a SQL left outer join; preserve key order\n",
    "#it tries to match the \"state\" field from the left DF (left_on) with the right index (right_index=True)\n",
    "#if we want to merge on two columns we would use left_on and right_on. \n",
    "#If we want to merge on two indices we would set left_index and right_index to True. \n",
    "# Latter is the same as .join() (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_avg = df.groupby(level=0).mean()\n",
    "state_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat allows joining along the axes.\n",
    "pd.concat([state_avg, state_df], axis=1)\n",
    "#there are no values for Arkansas in the original df or the state_avg df, \n",
    "#but there is a value for the governor in state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join also works. Just like merge, but \n",
    "#default is to join on indexes.\n",
    "state_avg.join(state_df, how='left') #ignores Akransas because left join, and left df has no Arkansas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with Pandas\n",
    "## More on this next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/playgolf.csv', delimiter='|' )\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Windy'] = df[\"Windy\"].astype('bool')\n",
    "df.describe().T\n",
    "#describes numerical fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see the general pattern of Temperature and Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can make use of df.plot() to produce simple graphs that calls on the more adjustable Matplotlib library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df.hist(['Temperature','Humidity'],bins=[60,66,72,80,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Temperature','Humidity']].plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots for examining bivariate relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(plt)\n",
    "df.plot('Temperature', 'Humidity', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we want to color the scatterplots according to a category, it requires a bit of matplotlib...ugh!\n",
    "### more on matplotlib later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=df.groupby('Outlook')\n",
    "for name, group in groups:\n",
    "    print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.Temperature, group.Humidity, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend(numpoints=1, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about the categorical variables? Frequency tables and relative frequency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simply df.value_counts() gets you the frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlook'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using apply will get you the value counts for multiple columns at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Outlook','Result']].apply(lambda x: x.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contingency Tables for looking at bivariate relationships between two categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Outlook'],df['Result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Often we want the row percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Outlook'], df['Result']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or the column percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Outlook'], df['Result']).apply(lambda c: c/c.sum(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enough...lets get to the pair sprint\n",
    "\n",
    "https://www.youtube.com/watch?v=yGf6LNWY9AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
