{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "## What is Pandas?\n",
    "A Python library providing data structures and data analysis tools.\n",
    "\n",
    "\n",
    "## Benefits\n",
    "\n",
    "* Efficient storage and processing of data.\n",
    "* Includes many built in functions for data transformation, aggregations, and plotting.\n",
    "* Great for exploratory work.\n",
    "\n",
    "## Not so greats\n",
    "\n",
    "* Does not scale terribly well to large datasets.\n",
    "\n",
    "## Documentation:\n",
    "\n",
    "* http://pandas.pydata.org/pandas-docs/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By convention import pandas like:\n",
    "import pandas as pd\n",
    "\n",
    "#By convention import numpy like:\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Make sure you have both lines when using matplotlib in Jupyter notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#For fake data.\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas \n",
    "* They are built on top of NumPy NdArrays\n",
    "* http://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* Create `Series` and `DataFrame`s from Python data types. \n",
    "* Create `DataFrame`s from on disk data.\n",
    "* Index and Slice `pandas` objects.\n",
    "* Aggregate data in `DataFrame`s.\n",
    "* Join multiple `DataFrame`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas is built on Numpy\n",
    "* Numpy is one of the fundamental packages for scientific computing in Python.\n",
    "\n",
    "\n",
    "## Numpy Arrays\n",
    "* Or NdArrays (n-dimensional array)\n",
    "* They are like lists in Python however they allow faster computation\n",
    "    1. They are stored as one contiguous block of memory, rather than being spread out across multiple locations like a list. \n",
    "    2. Each item in a numpy array is of the same data type (i.e. all integers, all floats, etc.), rather than a conglomerate of any number of data types (as a list is). We call this idea homogeneity, as opposed to the possible heterogeneity of Python lists.\n",
    "\n",
    "\n",
    "Just how much faster are they? Let's take the numbers from 0 to 1 million, and sum those numbers, timing it with both a list and a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python list\n",
      "19.4 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n",
      "0.019449680800005354\n",
      "\n",
      "numpy array\n",
      "683 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1000 loops each)\n",
      "0.0006832007929999691\n",
      "\n",
      "numpy array -- standard library sum\n",
      "103 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n",
      "0.10284348160000718\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.arange(0, 1000000)\n",
    "python_list = range(1000000)\n",
    "\n",
    "print (\"python list\")\n",
    "time = %timeit -r 1 -o sum(python_list)\n",
    "print (time.all_runs[0]/time.loops )\n",
    "\n",
    "print (\"\\n\" + \"numpy array\")\n",
    "time = %timeit -r 1 -o np.sum(numpy_array)\n",
    "print (time.all_runs[0]/time.loops)\n",
    "\n",
    "print (\"\\n\" + \"numpy array -- standard library sum\")\n",
    "time = %timeit -r 1 -o sum(numpy_array)\n",
    "print (time.all_runs[0]/time.loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy NdArrays\n",
    "\n",
    "* have types\n",
    "* Each array is of one type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = np.array(range(3))\n",
    "chars = np.array(list('ABC'))\n",
    "strings = np.array(['A','BC',\"DEF\"])\n",
    "\n",
    "print (ints.dtype, chars.dtype, strings.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and using NdArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_lst_ndarray = np.array([1, 2, 3, 4, 5])\n",
    "my_tuple_ndarray = np.array((1, 2, 3, 4, 5), np.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_lst_ndarray.dtype)\n",
    "print(my_tuple_ndarray.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_lst_ndarray.shape)\n",
    "print(my_tuple_ndarray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_arr = np.array([[1, 2, 3, 4, 5],[6, 7, 8, 9, 10],[11, 12, 13, 14, 15]])\n",
    "nd_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access info in the array\n",
    "* Individual data\n",
    "* Slices of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_arr[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_arr[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_arr.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_arr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[10], [-10]]) \n",
    "b = np.array([[1, 2], [-1, -2]]) \n",
    "\n",
    "print (a.shape, b.shape )\n",
    "print (\"\\n\")\n",
    "print (a + b)\n",
    "\n",
    "# elements will \"duplicate, expand, and fill up\" \n",
    "# to make the dimensions compatible for element-wise operations\n",
    "# cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[10, 0, -10, 0],[-10, 0, -10, 0]]) \n",
    "b = np.array([[2,2],[-1,0]]) \n",
    "print (a.shape, b.shape )\n",
    "print (\"\")\n",
    "print (a + b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it's not clear how it should fill up in this case... so it can't/doesn't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "\n",
    "# Pandas \n",
    "\n",
    "\n",
    "## Pandas Series\n",
    "* are (one dimensional) np.ndarray vectors **with an index**\n",
    "* They are built upon NdArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([5775,373,7,42,np.nan,33])\n",
    "print (series)\n",
    "print (\"\\n\")\n",
    "print (series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_series = pd.Series([\"cubs\",\"royals\",\"giants\",\"sox\",\"giants\",\"cards\",\"giants\",\"...\",None])\n",
    "world_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series are very powerful when dealing with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datetime index\n",
    "dt_index = pd.date_range('2015-1-1', \n",
    "                        '2015-11-1', \n",
    "                        freq='m')\n",
    "dt_series = pd.Series(randn(10), \n",
    "                      index = dt_index)\n",
    "dt_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Indexes.\n",
    "Notice how each series has an index (in this case a relatively meaningless default index).\n",
    "\n",
    "Pandas can make great use of informative indexes. Indexes work similarly to a dictionary key, allowing fast lookups of the data associated with the index.\n",
    "\n",
    "Indexes can also be exploited for fast group-bys, merges, time-series operations and lots more.\n",
    "\n",
    "When you're really in the zone with pandas, you'll be thinking a lot about indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_series = pd.Series(randn(5), \n",
    "                           index = ['California', 'Alabama', \n",
    "                                    'Indiana', 'Montana', \n",
    "                                    'Kentucky'])\n",
    "alt_indexed_series = pd.Series(randn(5),\n",
    "                               index = ['Washington', 'Alabama', \n",
    "                                        'Montana', 'Indiana', \n",
    "                                        'New York'])\n",
    "print (indexed_series)\n",
    "print ('\\n')\n",
    "print (alt_indexed_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas uses the index by default to align series for arithmetic!\n",
    "indexed_series + alt_indexed_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrames\n",
    "* are a set of Pandas Series **that share the same index** \n",
    "\n",
    "Think Excel spreadsheets!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [[1, 2, 3], [4, 5, 6]], \n",
    "    columns=['a', 'b', 'c'], \n",
    "    index=['foo', 'bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(randn(10, 5), index=dt_index, columns=[x for x in 'abcde'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A dataframes columns are series:\n",
    "col = df.a\n",
    "type(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So are the rows.\n",
    "row = df.loc['2015-01-31']\n",
    "type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The columns all have the same index:\n",
    "col.index   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What's the index for the rows?\n",
    "row.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrame basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing/ access of data\n",
    "\n",
    "# When one row is returned it is a Series (note a dataframe) \n",
    "print (type(df.a))\n",
    "df.a  # sometimes works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'] #works always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return subset / multipul columns \n",
    "df[['a','b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced sleection\n",
    "## .loc / .iloc / .xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2015-05-31':'2015-08-31', 'c':'e'] #Ranges by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:-3,2:5] #Ranges by number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix[2:-3,2:5] #Tries to estimate your request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix['2015-05-31':'2015-08-31', 'c':'e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT USE .ix \n",
    "It is here as you may see it in other code and should know what it is\n",
    "  \n",
    "  \n",
    "--------------------------------------------------------------------------------------------     \n",
    "        \n",
    "      \n",
    "      \n",
    "# DataFrame Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi Index:\n",
    "dt_index = pd.date_range('2015-1-1', \n",
    "                        '2017-7-1', \n",
    "                        freq='m')\n",
    "df = pd.DataFrame(randn(30,5), index=dt_index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new column\n",
    "df['state'] = ['Alabama', 'Alaska' , 'Arizona'] * 10\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.set_index(['state', 'index'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Alabama'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2015-01-31'] #Doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('Alabama', '2015-01-31')] #Can do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from file for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winequality-red.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  #Display the first x rows (default is 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering (i.e., row selecting or boolean indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueFalse= df['chlorides'] <= 0.08 \n",
    "trueFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[trueFalse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use a mask, we actually have to use it to index into the DataFrame (using square brackets). \n",
    "df[df['chlorides'] <= 0.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, this is cool. What if I wanted a slightly more complicated query...\n",
    "df[(df['chlorides'] >= 0.04) & (df['chlorides'] < 0.08)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('quality') # Note that this returns back to us a groupby object. It doesn't actually \n",
    "                      # return to us anything useful until we perform some aggregation on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we can also group by multilple columns by passing them in in a list. It will group by \n",
    "# the first column passed in first, and then the second after that (i.e. it will group by \n",
    "# the second within the group by of the first). \n",
    "df2 = df.groupby(['pH', 'quality']).count()['chlorides']\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding / Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a computed column\n",
    "\n",
    "df['pct_free_sulf'] = df['free sulfur dioxide'] / df['total sulfur dioxide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Droping a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('pct_free_sulf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('pct_free_sulf', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Missing Values\n",
    "* http://pandas.pydata.org/pandas-docs/stable/missing_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val_df = pd.DataFrame(\n",
    "    [[1, 2, 3], [4, np.nan, 6]], \n",
    "    columns=['a', 'b', 'c'], \n",
    "    index=['foo', 'bar'])\n",
    "miss_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU WANT THE CHANGE TO HAPPEN INPLACE YOU MUST add that\n",
    "miss_val_df.fillna(0,inplace=True)\n",
    "miss_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DROP ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val_df['b']['foo'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge \n",
    "* http://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "\n",
    "We can join DataFrames in a similar way that we join tables to SQL.  In fact, left, right, outer, and inner joins work the same way here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.DataFrame(\n",
    "    [[1, 2, 3], [4, 3, 6]], \n",
    "    columns=['a', 'b', 'c'])\n",
    "\n",
    "merge2 = pd.DataFrame(\n",
    "    [[1, 2, 3], [4, 3, 6]], \n",
    "    columns=['z', 'b', 'y'])\n",
    "\n",
    "merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merge1.merge(merge2, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating\n",
    "* adding *rows*\n",
    "* see also: df.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {'Col1': range(5), 'Col2': range(5), 'Col3': range(5)})\n",
    "df2 = pd.DataFrame(\n",
    "    {'Col1': range(5), 'Col2': range(5), 'Col4': range(5)},\n",
    "    index=range(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertically\n",
    "pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], join='outer', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/playgolf.csv', delimiter=',' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(['Temperature','Humidity'],bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Temperature','Humidity']].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot('Temperature', 'Humidity', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=df.groupby('Outlook')\n",
    "for name, group in groups:\n",
    "    print( name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.Temperature, group.Humidity, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend(numpoints=1, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlook'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
