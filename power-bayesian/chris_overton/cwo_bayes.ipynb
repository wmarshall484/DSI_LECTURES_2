{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Power & Bayes\n",
    "\n",
    "Chris Overton  \n",
    "2016-09-22  \n",
    "\n",
    "Adapted from versions by several other lecturers\n",
    "\n",
    "Morning: winding up our frequentist statistics\n",
    "* Recap: significance vs. causality\n",
    "* Statistical Power\n",
    "\n",
    "Afternoon:\n",
    "* Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Afternoon: Bayesian Inference\n",
    "* Frequentist vs. Bayesian approaches\n",
    "* Work with Bayes rule to compute posterior probability\n",
    "* Prior, likelihood and posterior distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Three coins problem - a second look\n",
    "\n",
    "Three coins are in an Urn.  \n",
    "\n",
    "Coin $B_1$ has sides HH (i.e. heads on each side)  \n",
    "Coin $B_2$ has sides HT (like a normal fair coin)  \n",
    "Coin $B_3$ has sides TT (tails on each side.)\n",
    "\n",
    "Pull out a coin and flip it. It comes up H.\n",
    "\n",
    "What is the probability the same coin comes out H if you flip it a second time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         second\n",
       "first          \n",
       "False  0.173913\n",
       "True   0.851852"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As tested by simulation:\n",
    "import random\n",
    "import pandas as pd\n",
    "coins = ['HH', 'HT', 'TT']\n",
    "results = []\n",
    "for i in range(100):\n",
    "    coin = random.choice(coins)\n",
    "    results.append([random.choice(coin) for i in [1,2]])\n",
    "df = pd.DataFrame(results, columns=['first', 'second']) == 'H'\n",
    "df.groupby('first').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Our old solution\n",
    "\n",
    "$ P(X_2 = H) = 1/2 $\n",
    "\n",
    "$ P(X_2 = H | X_1 = H) = \\frac{5}{6} \\ne \\frac{1}{2} = P(X_2=H) $\n",
    "\n",
    "Originally, each coin had a probability 1/3 of being picked. Now it is impossible for the coin picked to have been the third, and it is now twice as likely that the coin picked is the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Old solution uses conditional probability\n",
    "\n",
    "$ P(B|A) = P(A \\cap B) / P(A) $\n",
    "\n",
    "in other words\n",
    "\n",
    "$ P(X_2=H | X_1=H) = P(X_2 = H \\cap X_1 = H) / P(X_1=H) = \\frac{\\frac{1}{3} + \\frac{1}{3}\\frac{1}{4}}{\\frac{1}{2}}$\n",
    "\n",
    "Now let's look at this using Bayes formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Rule\n",
    "Allows us to compute $P(B|A)$ using information about $P(A|B)$\n",
    "\n",
    "$$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$$\n",
    "\n",
    "### Proof (remember this if nothing else):  \n",
    "\n",
    "The probability for the intersection can be obtained from either end of the equation below:\n",
    "\n",
    "$$P(B|A) * P(A) = P(A \\cap B) = P(A|B)* P(B)$$\n",
    "\n",
    "### The reson this is helpful: often, it is easier to compute conditional probabilities going in one direction, but you really want conditional probabilities going in the other \"hard\" direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Rule\n",
    "Bayes' Rule helps when all you know about $P(B)$ is an initial guess - the **prior**, and you are trying to figure out how additional evidence (A) alters this guess. \n",
    "\n",
    "However, it is easier to make conclusions $P(A|B)$ about A from B (the **likelihood**) than what you want - the **posterior probability** $P(B|A)$:\n",
    "\n",
    "$$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$$\n",
    "\n",
    "Here, the denominator $P(A)$ might seem hard to compute, but can be obtained using the **Law of Total Probability**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Law of Total Probability (LOTP)\n",
    "\n",
    "If $\\{B_n\\}$ is a partition of a sample space $ X $, meaning $ \\cup_i B_i = X$ and $B_i \\cap B_j=\\emptyset$  $ \\forall i, j$\n",
    "\n",
    "Then for any event $A \\subset X$  \n",
    "\n",
    "$ P(A) = \\sum P(A\\cap B_i) $\n",
    "\n",
    "or\n",
    "\n",
    "$ P(A) = \\sum P(A|B_i) P(B_i)$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back to Bayes Rule\n",
    "Assuming a partition $\\{B_n\\}$, you can thus re-write the denominator as follows (for any i):\n",
    "\n",
    "$$P(B_i|A) = \\frac{P(A|B_i)P(B_i)}{P(A)}$$\n",
    "\n",
    "$$ = \\frac{P(A|B_i)P(B_i)}{\\sum P(A|B_i) P(B_i)}$$\n",
    "\n",
    "Now, all of the conditional probabilities go in the 'easy' direction from $B_i$'s to $A$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back to the coin problem\n",
    "\n",
    "Our question asks which of three disjoint events has occurred: whether the coin chosen is $B_1$ (HH), $B_2$ (HT) or $B_3$ (TT).\n",
    "\n",
    "We want to know about the outcome A = 'the coin comes up heads'\n",
    "\n",
    "This might seem tricky, but it is easier to reason from $B_i$ to $A$:  \n",
    "$P(A|B_1) = 1$, $P(A|B_2) = 1/2$, and $P(A|B_3) = 0$\n",
    "\n",
    "Our prior probability for each $B_i = \\frac{1}{3}$\n",
    "\n",
    "Plugging this into Bayes formula gives:\n",
    "\n",
    "$$P(B_i|A) = \\frac{P(A|B_i)P(B_i)}{\\sum P(A|B_i) P(B_i)} = \\frac{P(A|B_i)P(B_i)}{1 * 1/3 + 1/2 * 1/3 + 0 * 1/3} = P(A|B_i)P(B_i) * 2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back to the coin problem \n",
    "Note that we had already evaluated each possibility for the numerator when computing the denominator.  \n",
    "\n",
    "It follows that $P(B_1|A) = 2/3$, $P(B_2|A) = 1/3$, and $P(B_3|0) = 0$\n",
    "\n",
    "We can now use our *posterior* probabilities of the $B_i$ to calculate the probability of a second H coin flip:\n",
    "\n",
    "$$P(A|{posterior P(B_i)}) = 2/3 * 1 + 1/3 * 1/2 = 5/6$$\n",
    "\n",
    "This might seem like a long path to a result that took us fewer lines earlier, but now we have the additional estimates of probabilities for each the coins.\n",
    "\n",
    "Further coin flip results would continue to alter these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 'Reliable' test for rare disease - a famously counterintuitive example\n",
    "\n",
    "A fairly reliable diagnostic test T exists for a rare disease D. The result of the test is either positive ($T_+$) or negative ($T_-$)\n",
    "\n",
    "|Conditional Events | Probability |\n",
    "| --------- | ----------- |\n",
    "| $ P(T_+|D)$ | .99 |\n",
    "| $ P(T_+|\\neg D)$ | .05 |\n",
    "| $P(D)$ | .005 |\n",
    "\n",
    "So for someone who tests positive, what is their probability of having the disease ($ P(D | T_+) $)?\n",
    "\n",
    "First, give a quick rough answer!  \n",
    "In particular, are they more likely to have the disease or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ## 'Reliable' test for rare disease: Rough answer $P(D|T_+) \\approx 1/11$\n",
    "There are two ways to test positive: $P(T_+D)$ and $P(T_+ \\neg D)$.  \n",
    "\n",
    "The rare events gating these are respectively $P(D) = .005$ and $ P(T_+ \\neg D) = .05$\n",
    "\n",
    "Because $D$ and $\\neg D$ partition the space, Bayes theorem says:\n",
    "\n",
    "$$P(D|T_+) = \\frac{P(T_+|D)P(D)}{(T_+|D)P(D) + (T_+| \\neg D)P( \\neg D)} \\approx \\frac{.005}{.005 + .05} = \\frac{1}{11}$$\n",
    "\n",
    "From this, we obtain a quick estimate by ignoring terms close to 1.\n",
    "\n",
    "If the test were less reliable ($P(T_+|D) << 1$), we would need that in an estimate as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 'Reliable' test for rare disease\n",
    "This probability update of D goes in the right direction, from $0.005$ to $.091$.\n",
    "\n",
    "Even so, it may seem surprisingly slow to update as we'd wish!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Updating: Accumulation of evidence\n",
    "\n",
    "In today's pairs sprint, you'll implement a discrete approximation to the following:\n",
    "\n",
    "![Bayesian updating](images/bayesianUpdate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian Updating: Accumulation of evidence (II)\n",
    "\n",
    "Observe how situations impossible from the data are updated to 0 (e.g. p=1 when any tails have been seen.)\n",
    "\n",
    "After many updates, the posterior distribution starts resembling a normal distribution calculated via MOM or MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frequentist vs. Bayesian\n",
    "\n",
    "Frequentist probability: **long-run** probability of an outcome\n",
    "\n",
    "Subjective probability: a degree of measure of **belief**\n",
    "\n",
    "Bayesians consider both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Frequentist vs. Bayesian\n",
    "\n",
    "** Experiment 1: **  ![Musician](images/musicMan.png) \n",
    "\n",
    "A fine classical musician says he’s able to distinguish Haydn from Mozart.  \n",
    "Small excerpts are selected at random and played for the musician.\n",
    "Musician makes 10 correct guesses in exactly 10 trials.\n",
    "\n",
    "** Experiment 2: **  ![Drunk](images/drunk.png)\n",
    "\n",
    "Drunken man says he can correctly guess what face of the coin will fall down, mid air.\n",
    "Coins are tossed and the drunken man shouts out guesses while the coins are mid air.\n",
    "Drunken man correctly guesses the outcomes of the 10 throws.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Frequentist vs. Bayesian\n",
    "\n",
    "Frequentist:  “They’re both so skilled!  I have as much confidence in musician’s ability to distinguish Haydn and Mozart as I do the drunk’s to predict coin tosses”\n",
    "\n",
    "Bayesian:  “I’m not convinced by the drunken man…”\n",
    "\n",
    "The Bayesian approach is to incorporate prior knowledge into the experimental results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Frequentist vs. Bayesian\n",
    "\n",
    "Frequentist:  “They’re both so skilled!  I have as much confidence in musician’s ability to distinguish Haydn and Mozart as I do the drunk’s to predict coin tosses”\n",
    "\n",
    "Bayesian:  “I’m not convinced by the drunken man…”\n",
    "\n",
    "The Bayesian approach is to incorporate prior knowledge (perhaps very subjective) into the experimental results:\n",
    "\n",
    "$$P(psychic | correct) = \\frac{P(correct | psychic) P(psychic)}{P(correct)} = \\frac{1 * 10^{-5}}{.5^{10}} \\approx 10^{-2}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The fierce ideological war between Bayesians and 'Frequentists': XKCD#1132\n",
    "    \n",
    "![xkcd Bayes vc Freq](images/xkcd1132.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The fierce ideological war between Bayesians and 'Frequentists': XKCD#1132\n",
    "    \n",
    "![xkcd Bayes vc Freq](images/xkcd1132b.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Monty Hall problem: an interesting use for Bayesian logic\n",
    "\n",
    "Setup: three doors. Behind two, there's a goat. Behind one, there's a car.  \n",
    "\n",
    "After you pick one, the game show host will open another door with a goat.  \n",
    "\n",
    "You are then allowed to change your choice of door.  \n",
    "\n",
    "** Question **: should you?\n",
    "\n",
    "![Monty Hall game](images/montyHall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frequentist vs. Bayesian: Closing thoughts  \n",
    "\n",
    "* Frequentist tools certainly can be and are misused\n",
    "* Probabilities may change faster than long-run models can be assembled\n",
    "\n",
    "*** However ***\n",
    "\n",
    "* Bayesians use frequentist tools too.\n",
    "* Frequentist reasoning is nearly as entrenched as phone lines, so it's useful to master\n",
    "* The supposed 'war' is more sort of a tounge-in-cheek means to promoting discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Summary\n",
    "\n",
    "\n",
    "##  Summary\n",
    "\n",
    "* Frequentist vs. Bayesian approaches\n",
    "* Work with Bayes rule to compute posterior probability\n",
    "* Prior, likelihood and posterior distributions\n",
    "\n",
    "![Losing Monty Hall game](images/wonAGoat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
