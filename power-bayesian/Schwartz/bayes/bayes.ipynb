{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slide_type": "markdown"
   },
   "source": [
    "# $$\\textit{Bayes} \\text{ (pronounced BAE$\\cdot$z)}$$\n",
    "\n",
    "$$\\text{Schwartz}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"stuff/bayes.tiff\" width=\"1000px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"stuff/bayes_regs.tiff\" width=\"1000px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' Rule for Events\n",
    "\n",
    "# $$p(B|A) = \\frac{p(A|B)p(B)}{p(A)} = \\frac{p(A,B)}{p(A)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' Formula for Random Variables\n",
    "# $$p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)} = \\frac{p(X,Y)}{p(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' Theorem for Random Variables & Parameters (_as Random Variables_)\n",
    "# $$p(\\theta|X) = \\frac{p(X|\\theta)p(\\theta)}{p(X)} = \\frac{p(X,\\theta)}{p(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' for Data Analysis\n",
    "\n",
    "# $\\begin{align}\n",
    "p(\\theta|X_1,X_2,\\cdots,X_n) &= \\frac{p(X_1,X_2,\\cdots,X_n|\\theta)p(\\theta)}{p(X_1,X_2,\\cdots,X_n)}\\\\{}\\\\ \n",
    "\\text{Posterior} &= \\frac{\\text{Likelihood}\\times\\text{prior}}{\\text{Marginal Likelihood}} \n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _\"The posterior is proportional to the likelihood times the prior\"_\n",
    "#### _(the marginal likelihood is just a normalizing constant)_\n",
    "\n",
    "## $\\begin{align}\n",
    "\\text{Posterior} &= \\\\\n",
    "p(\\theta|X_1,X_2,\\cdots,X_n) &= \\frac{p(X_1,X_2,\\cdots,X_n|\\theta)p(\\theta)}{p(X_1,X_2,\\cdots,X_n)}\\\\ \n",
    "&= \\frac{p(X_1,X_2,\\cdots,X_n|\\theta)p(\\theta)}{c} \\propto  p(X_1,X_2,\\cdots,X_n|\\theta)p(\\theta)\\\\\n",
    "& \\hspace{11.5em} \\text{Likelihood } \\times \\text{prior}\n",
    "\\end{align}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"stuff/bayes.png\" width=\"750px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrasting Frequentist and Bayesian Analysis\n",
    "\n",
    "\n",
    "## $\\begin{align}\n",
    "\\underset{\\theta}{argmax}\\; p(X_1,X_2,\\cdots,X_n|\\theta) &= \\underset{\\theta}{argmax}\\; \\; p(X_1|\\theta)p(X_2|\\theta)\\cdots p(X_n|\\theta) \\quad\\;\\;\\;\\;\\;\\;\\textbf{(1)}\\\\{}\\\\\n",
    "\\quad\\quad p(\\theta|X_1,X_2,\\cdots,X_n) &\\propto \\quad\\quad\\quad\\; p(X_1|\\theta)p(X_2|\\theta)\\cdots p(X_n|\\theta)p(\\theta) \\quad\\textbf{ (2)}\\\\{}\\\\\n",
    "\\underset{\\theta}{argmax}\\; p(\\theta|X_1,X_2,\\cdots,X_n) &= \\underset{\\theta}{argmax}\\;\\; p(X_1|\\theta)p(X_2|\\theta)\\cdots p(X_n|\\theta)p(\\theta) \\quad\\textbf{ (3)}\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Classical Frequentist Maximum Likelihood Estimation (MLE)\n",
    "### (2) Full Bayesian Posterior Analysis \n",
    "### (3) Maximum $a\\;posteriori$ (MAP) Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_1 = 4\n",
    "x_2 = 14\n",
    "\n",
    "# prior\n",
    "p_theta_1 = .2\n",
    "p_theta_11 = .3\n",
    "p_theta_21 = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$p(X_i|\\theta) = \\frac{\\theta^{x_i} e^{-\\theta}}{x_i!}$$\n",
    "\n",
    "# $$\n",
    "\\begin{align}\n",
    "p(\\theta=1|x_1=4,x_2=14) &\\propto ?\\\\ % \\frac{1^{4} e^{-1}}{4!}\\frac{1^{14} e^{-1}}{14!} \\times .2 \\\\\n",
    "p(\\theta=11|x_1=4,x_2=14) &\\propto ?\\\\ % \\frac{11^{4} e^{-11}}{4!}\\frac{11^{14} e^{-11}}{14!} \\times .3 \\\\\n",
    "p(\\theta=21|x_1=4,x_2=14) &\\propto ?\\\\ % \\frac{21^{4} e^{-21}}{4!}\\frac{21^{14} e^{-21}}{14!} \\times .5 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "21**4*np.exp(-21)/math.factorial(4) * 21**14*np.exp(-21)/math.factorial(14) * .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loglikelihood(sample, model, pars):\n",
    "    log_likelihood = 0\n",
    "    for x in sample:\n",
    "        log_likelihood = log_likelihood + np.log(getattr(stats,model).pmf(x,**pars))\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = [11,2,14,5,16]\n",
    "model = \"poisson\"\n",
    "pars = {'mu': np.linspace(0, 20, 1000)[1:]}          \n",
    "\n",
    "prior_model = \"expon\"\n",
    "prior_pars = {\"scale\": 10}        \n",
    "\n",
    "prior = getattr(stats,prior_model).pdf(pars['mu'], **prior_pars)\n",
    "scaling = max(prior)\n",
    "\n",
    "plt.plot(pars['mu'], prior)\n",
    "\n",
    "likelihood = np.exp(loglikelihood(sample, model, pars))\n",
    "likelihood = likelihood/max(likelihood) * scaling\n",
    "\n",
    "plt.plot(pars['mu'], likelihood)\n",
    "\n",
    "posterior = np.exp(loglikelihood(sample, model, pars)) * getattr(stats, prior_model).pdf(pars['mu'], **prior_pars)\n",
    "posterior = posterior / max(posterior) * scaling\n",
    "\n",
    "plt.plot(pars['mu'], posterior)\n",
    "\n",
    "plt.legend([\"pior\", \"Likelihood\", \"Posterior\"], loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson-Exponential posterior is Gamma\n",
    "#### (This is becuase the exponential (gamma) distribution is \"conjugate\" to the poisson distribution)\n",
    "\n",
    "$\\begin{array}\n",
    "Pp(\\theta|X_1,X_2,\\cdots,X_n) &\\propto \\lambda e^{-\\lambda \\theta} \\prod_{i=1}^{n}\\frac{\\theta^{x_i} e^{-\\theta}}{x_i!}\\\\\n",
    "&\\propto \\theta^{^{\\sum_{i=1}^{n}x_i}} e^{-(n+\\lambda)\\theta}\\\\\n",
    "&\\propto Gamma\\left(1+\\sum_{i=1}^{n}x_i, n+\\lambda\\right)\n",
    "\\end{array}$\n",
    "\n",
    "##### And you can do whatever you want with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# probabilistic programming\n",
    "* http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/\n",
    "* https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "\n",
    "parameter = pm.Exponential(\"poisson_param\", 1./10)\n",
    "data = np.array([11,2,14,5,16])\n",
    "#data_generator = pm.Poisson(\"data_generator_observed\", parameter)\n",
    "data_generator = pm.Poisson(\"data_generator_observed\", parameter, value=data, observed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_generator.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = [parameter.random() for i in range(20000)]\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(samples, bins=100, normed=True)\n",
    "plt.xlim([0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc = pm.MCMC([data, parameter])\n",
    "mcmc.sample(100000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(mcmc.trace(\"poisson_param\")[:], bins=100, histtype=\"stepfilled\", normed=True)\n",
    "plt.xlim([0,20])\n",
    "\n",
    "plt.plot(pars['mu'], 2.9*posterior, color='r', lw=2)\n",
    "plt.legend([\"Theoretical Posterior\"], loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesians have posterior distributions\n",
    "- a probability distribution $p(\\theta|X_1,X_2,\\cdots,X_n)$ over parameter $\\theta$ conditional on observable data (_\"theta given data\"_)\n",
    "- and can therefore make probabilistic statements about $\\theta$\n",
    "- e.g., the **probability** that $\\theta$ is greater than some null hypothesis $H_0: \\theta = \\theta_0$\n",
    "\n",
    "### **Bayesian's don't use *statistics***\n",
    "\n",
    "# What else do Bayesians have?\n",
    "- A prior where they can put subjective _\"prior belief\"_ into an analysis\n",
    "- An easily intreptable and consistent system for \"_updating belief\"_ after seeing data\n",
    "- Fully integrated uncertainty propegation in complex hierarchical models \n",
    "- Immediate formalization and integration of regularization within a fully coherent framework \n",
    "\n",
    "\n",
    "# What do Frequentists have?\n",
    "- Asymptotic distributional approximations that sometimes work\n",
    "- $H_0$'s that don't have probabistic interpretations -- they're either right or wrong only\n",
    "- test statistics and critical values for rejecting null hypothesis $H_0$\n",
    "   - p-values to measure evidence against the null hypothesis $H_0$\n",
    "   - p-values aren't the probability that the null is true\n",
    "- confidence intervals to give plausible ranges for parameters \n",
    "- a lot of envy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is Bayesian analysis similar to bootstrapping?\n",
    "\n",
    "### Suppose you have posterior distributions for $\\theta_1$ and $\\theta_2$: how can you say which is larger?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even more context\n",
    "\n",
    "* Bayesian care _completely_ about uncertainty assessment for the parameters in their model\n",
    "* Frequentists _do_ characterize uncertainty -- but not at the parameter level \n",
    "    * Frequentists characterize the uncertainty (long run \"frequency\" behavior) of their _estimation procedures_\n",
    "* Machine Learning procrastenates on examining uncertainty until they examine model predictive performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a prior?\n",
    "\n",
    "# What is a posterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments for Bayesian Analysis\n",
    "* Ease of interpretability\n",
    "\n",
    "     probability statements about parameters are more easily interpreted than confidence intervals, hypothesis testing and p-values  \n",
    "\n",
    "\n",
    "* Utilizes _prior_ information\n",
    "\n",
    "    the Bayesian framework is a natural mechanism to incorporate, build upon and grow information, i.e., learn in an sequential and iterative manner\n",
    "\n",
    "\n",
    "\n",
    "* No \"large n\" asymptotic distribution requirements\n",
    "\n",
    "    Bayesian analysis is a fully coherent probabilistic framework regardless of sample size, whereas many Frequentist methodologies (vaguely) rely upon \"large n\" results\n",
    "    \n",
    "    \n",
    "* Complex hierarchical data models\n",
    "\n",
    "    many complicated modeling specifications are _only_ available within the Bayesian computational framework\n",
    "    \n",
    "    \n",
    "* Uncertainty propegation \n",
    "\n",
    "     Bayesian analysis provides a hierarchical modeling framework that definitionally incorporates all modeled uncertainty into parameter estimation\n",
    "\n",
    "\n",
    "\n",
    "* Performs regularization\n",
    "\n",
    "    the prior specification can stabilize model fitting procedures so they are less prone to overfitting data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments agaist Bayesian Analysis\n",
    "## (and these are substantial; I personally heavily subscribe to the last two subpoints)\n",
    "## (i.e., _Occam's Razor_ and _Murphy's Law_, yo...)\n",
    "\n",
    "* _Requires_ specification of the _prior_ \n",
    "\n",
    "    allows objectivity to be sacrificed for subjectivity -- arbitrary information can be  incorporated into Bayesian analysis\n",
    "    \n",
    "    \n",
    "* Bayesian computation has more overhead/is more expensive than Frequentist computation on a number of levels:\n",
    "\n",
    "    * Bayesian analysis requires practitioners with more advanced skill sets\n",
    "\n",
    "    * Bayesian analysis is more difficult to implement correctly\n",
    "    \n",
    "    * simple Frequentist solutions often outperform complex Bayesian solutions at a fraction of total development and computational costs\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
