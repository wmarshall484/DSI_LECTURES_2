{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "Content taken from Skylar Versage and rearranged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Describe the difference between frequentist and bayesian approaches of experiments\n",
    "- Define bayes rule, use in two examples\n",
    "- Define posterior, prior, likelihood, evidence\n",
    "- Solve a discrete bayes problem by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Example 1**: A highly trained conductor says she can tell the difference between Mozart and Beethoven. We randomly sample excerpts and play them. She guesses 10/10 correctly. \n",
    "\n",
    "**Example 2**: A drunk observer then claims he can guess the outcome of a coin flip mid air, we proceed to test him and he guesses 10/10 correctly.\n",
    "\n",
    "A **Frequentist** might say “They are both so skilled, I have as much confidence in the conductor’s ability as the drunk man’s ability to predict the coin toss”\n",
    "\n",
    "A **bayesian** would say “I’m not so convinced by the drunk guy”.\n",
    "\n",
    "The bayes approach incorporates **prior knowledge** into the experiment’s results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conditional Probabilities [Review]\n",
    "\n",
    "The probability of an event B given \n",
    "\n",
    "> The conditional probability of an event B is the probability that the event will occur given the knowledge that an event A has already occurred. This probability is written\n",
    "\n",
    ">$$ P(B \\mid A) $$\n",
    "\n",
    "> notation for the probability of B given A. [\\[link\\]](http://www.stat.yale.edu/Courses/1997-98/101/condprob.htm) [also see All of Statistics p 28].\n",
    "\n",
    "$$ P(B \\mid A) = \\frac {P(A \\cap B)} {P(A)} $$\n",
    "\n",
    "That you can relate, by analogy, to a set of possible outcomes:\n",
    "\n",
    "<img src=\"images/set_intersection.svg\" alt=\"set intersection\" style=\"width: 300px;\"/>\n",
    "\n",
    "**Exercise**: what's the probability of rolling a dice with a value less than 4 knowing that the value is odd.\n",
    "- identify that is A and B in the problem, to inject into the formula above,\n",
    "- identify the possible outcomes for each component of that formula,\n",
    "- compute the answer to the problem.\n",
    "\n",
    "<br/>\n",
    "<details>\n",
    "<summary>Click here to see the solution below</summary>\n",
    "- B is \"rolling a dice with a value less than 4\", as a set of possible outcomes it is $ \\{ 1, 2, 3 \\} $<br/>\n",
    "- A is \"rolling a dice with a value that is odd\", as a set of possible outcomes it is $ \\{ 1, 3, 5 \\} $<br/>\n",
    "- $ A \\cap B $, as the intersection of those sets is $ \\{ 1, 3 \\} $ <br/>\n",
    "- $ P(B \\mid A) = \\frac {P(A \\cap B)} {P(A)} = \\frac {|A \\cap B|} {|A|} = \\frac {2} {3} $\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayes Rule\n",
    "\n",
    "### 2.1. Law of total probability\n",
    "\n",
    "Given a partition $ A_1, ..., A_n $ of $ \\Omega $, the probability of an event B\n",
    "\n",
    "$$ P(B) $$\n",
    "\n",
    "Can be written as:\n",
    "\n",
    "$$ P(B) = \\Sigma i P( B \\mid A_i ) P (A_i) $$\n",
    "\n",
    "Special case for this, if two situations are exclusive (A and non A):\n",
    "\n",
    "$$ P(B) = P( B \\mid A ) \\: P (A) + P( B \\mid non A ) \\: P (non A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Bayes Rule\n",
    "\n",
    "\n",
    "$$ P(A \\mid B) = \\frac { P(B \\mid A) \\: P(A) } {P(B)} $$\n",
    "\n",
    "- $ P(A \\mid B) $ is called the posterior probability\n",
    "- $ P(B \\mid A) $ is called the likelihood\n",
    "- $ P(A) $ is called the prior probability\n",
    "- $ P(B) $ is a probability, often refered to a normalizing constant (we'll talk about that later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Let's apply it right away..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: planning a picnic\n",
    "\n",
    "You are planning a picnic today in summer in Seattle, but the morning is cloudy. What is the chance that it will rain during the day, knowing that:\n",
    "\n",
    "- 50% of all rainy days start off cloudy\n",
    "- cloudy mornings are common in Seattle (40% of days start cloudy)\n",
    "- this month of summer is usually dry (only 3 days out of 30 tend to be rainy).\n",
    "\n",
    "What is the chance that it will rain during the day?\n",
    "- identify the terms in the Bayes Rule: what is A, what is B?\n",
    "- identify which probability you know, write them as A and B, and inject them into the formula\n",
    "- compute the result\n",
    "\n",
    "<br/>\n",
    "<details>\n",
    "<summary>Click here to see the solution below</summary>\n",
    "What we want to know is\n",
    "$$P(A \\mid B)$$\n",
    "$$P(rainy \\: day \\mid cloudy \\: morning)$$<br/>\n",
    "\n",
    "- B is \"today is a rainy day\"<br/>\n",
    "- A is \"today is a cloudy morning\"<br/>\n",
    "<br/>\n",
    "What we know is:<br/>\n",
    "<br/>\n",
    "_\"50% of all rainy days start off cloudy\"_ translates as $ P(cloudy \\: morning \\mid rainy \\: day) = 0.5 $<br/>\n",
    "<br/>\n",
    "_\"40% of days start cloudy\"_ translates as $ P(cloudy \\: morning) = 0.4 $<br/>\n",
    "<br/>\n",
    "_\"only 3 days out of 30 tend to be rainy\"_ translates as $ P(rainy \\: day)= 3/30 $<br/>\n",
    "<br/>\n",
    "\n",
    "$$ P(rainy \\: day \\mid cloudy \\: morning) = \\frac { P(cloudy \\: morning \\mid rainy \\: day) \\: P(rainy \\: day) } {P(cloudy \\: morning)} $$\n",
    "\n",
    "<br/>\n",
    "\n",
    "$$ P(rainy \\: day \\mid cloudy \\: morning) = \\frac { 0.5 \\times 3/30 } { 0.4 } = 0.125 $$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: cancer screening\n",
    "\n",
    "- $ P(cancer) = .01 $\n",
    "- $ P(tested \\: positive \\mid cancer) = .9 $\n",
    "- $ P(tested \\: negative \\mid no \\: cancer) = .9 $\n",
    "\n",
    "What’s the probability we have cancer given we’ve been tested positive?\n",
    "- identify the terms in the Bayes Rule: what is A, what is B?\n",
    "- identify which probability you know, write them as A and B, and inject them into the formula\n",
    "- compute the result\n",
    "\n",
    "<br/>\n",
    "<details>\n",
    "<summary>Click here</summary>\n",
    "What we want to know is\n",
    "$$P(A \\mid B)$$\n",
    "$$P(cancer \\mid tested \\: positive)$$<br/>\n",
    "\n",
    "- B is \"tested positive\"<br/>\n",
    "- A is \"cancer\"<br/>\n",
    "<br/>\n",
    "What we know is:<br/>\n",
    "<br/>\n",
    "- $ P(cancer) = .01 $<br/>\n",
    "- $ P(tested \\: positive \\mid cancer) = .9 $<br/>\n",
    "- $ P(tested \\: negative \\mid no \\: cancer) = .9 $<br/>\n",
    "<br/>\n",
    "\n",
    "$$ P(cancer \\mid tested \\: positive) = \\frac { P(tested \\: positive \\mid cancer) \\: P(cancer) } {P(tested \\: positive)} $$\n",
    "\n",
    "<br/>\n",
    "\n",
    "$$ P(cancer \\mid tested \\: positive) = \\frac { 0.9 \\times 0.01 } {P(tested \\: positive)} $$\n",
    "\n",
    "</details>\n",
    "\n",
    "How do you obtain:\n",
    "\n",
    "$$ P(tested \\: positive) $$\n",
    "\n",
    "<details>\n",
    "<summary>Click here</summary>\n",
    "<br/>\n",
    "$ P(tested \\: positive) = $<br\\>\n",
    "$ P(tested \\: positive \\mid cancer) \\: P (cancer) + P(tested \\: positive \\mid no \\: cancer) \\: P (no \\: cancer) $\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. How to obtain it (or recover it from your long term memory)\n",
    "\n",
    "<img src=\"images/set_intersection.svg\" alt=\"set intersection\" style=\"width: 300px;\"/>\n",
    "\n",
    "Remember conditional probability?\n",
    "\n",
    "$$ P(B \\mid A) = \\frac {P(A \\cap B)} {P(A)} $$\n",
    "\n",
    "Can also be rewritten as:\n",
    "\n",
    "$$ P(B \\mid A) \\: P(A) = P(A \\cap B) $$\n",
    "\n",
    "Now, $ A \\cap B = B \\cap A $, right? so...\n",
    "\n",
    "$$ P(B \\mid A) \\: P(A) = P(A \\cap B) = P(B \\cap A) = P(A \\mid B) \\: P(B) $$\n",
    "\n",
    "Let's put them together:\n",
    "\n",
    "$$ P(B \\mid A) \\: P(A) = P(A \\mid B) \\: P(B) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Components revisited\n",
    "\n",
    "**Prior Probability**:\n",
    "- A PMF / PDF representing your initial beliefs about the parameter(s)\n",
    "- The initial belief is less represented in the posterior as more data is incorporated\n",
    "- How do we obtain it? Previous Studies... Researcher’s Intuition... Expert Opinion... If all else fails use an uninformed prior\n",
    "\n",
    "**Likelihood**:\n",
    "- The probability of observing the data given the parameter(s)\n",
    "- i.e. What is the likelihood of 3 Heads in a row given the probability of heads is 0.7?\n",
    "\n",
    "**Posterior Probability**:\n",
    "- The product of prior and likelihood (Bayesian-update)\n",
    "- The posterior probability becomes the prior of the next Bayesian-update\n",
    "\n",
    "**Normalizing Constant**:\n",
    "- The probability of observing the data. \n",
    "- In Bayesian analysis, this term ensures the sum of all probabilities is 1\n",
    "\n",
    "\n",
    "### 2.4. The \"diachronic\" interpretation\n",
    "\n",
    "In [Think Bayes, p. 5](http://www.greenteapress.com/thinkbayes/thinkbayes.pdf) we find:\n",
    "\n",
    "> There is another way to think of Bayes’s theorem: it gives us a way to update the probability of a hypothesis, H, in light of some body of data, D.\n",
    "This way of thinking about Bayes’s theorem is called the diachronic interpretation. “Diachronic” means that something is happening over time; in this case the probability of the hypotheses changes, over time, as we see new data.\n",
    "\n",
    ">Rewriting Bayes’s theorem with H and D yields:\n",
    "\n",
    "> $$ P(H \\mid D) = \\frac {P(H) \\: P(D \\mid H)} {P(D)}$$\n",
    "\n",
    "> In this interpretation, each term has a name:\n",
    "\n",
    ">- $P(H)$ is the probability of the hypothesis before we see the data, called the prior probability, or just prior.\n",
    ">- $P(H \\mid D)$ is what we want to compute, the probability of the hypothesis after we see the data, called the posterior.\n",
    ">- $P(D \\mid H)$ is the probability of the data under the hypothesis, called the likelihood.\n",
    ">- $P(D)$ is the probability of the data under any hypothesis, called the normalizing constant.\n",
    "\n",
    "\n",
    "\n",
    "If we overlook that normalizing constant, what comes up is a relation between prior, likelihood and posterior.\n",
    "\n",
    "$$ posterior \\sim likelihood \\times prior $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prior in Action [example]\n",
    "\n",
    "Let's take an example.\n",
    "\n",
    "You have a drawer of 100 coins, 10 of which are biased.\n",
    "\n",
    "- $ P ( head \\mid fair ) = 0.5 $\n",
    "- $ P ( head \\mid biased ) = 0.25 $\n",
    "\n",
    "You randomly choose a coin and flip it once. It comes up heads.\n",
    "1. What is $ P(fair \\mid head) $ ?\n",
    "2. What if you flip it a second time and it comes up heads again?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. First loop: no prior\n",
    "\n",
    "After the first flip, $D = [head]$\n",
    "\n",
    "H = \"fair coin\"\n",
    "\n",
    "$ P (fair \\mid head) = ... $\n",
    "\n",
    "<br/>\n",
    "<details>\n",
    "<summary>Click here to see the solution below</summary>\n",
    "<br/>\n",
    "$ P (fair \\mid head) = \\frac { P (head \\mid fair) \\: P (fair) } { P (head \\mid fair) \\: P (fair) + P (head \\mid biased) \\: P (biased) } $<br/>\n",
    "<br/>\n",
    "$ P (fair \\mid head) = \\frac { 0.5 \\: 0.9 } { 0.5 \\times 0.9 + 0.25 \\times 0.1 } $<br/>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n"
     ]
    }
   ],
   "source": [
    "P_fair_head = (0.5 * 0.9) / (0.5 * 0.9 + 0.25 * 0.1)\n",
    "print(P_fair_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = \"biased coin\"\n",
    "\n",
    "$ P (biased \\mid head) = ... $\n",
    "\n",
    "<br/>\n",
    "<details>\n",
    "<summary>Click here to see the solution below</summary>\n",
    "<br/>\n",
    "$ P (biased \\mid head) = \\frac { P (head \\mid biased) \\: P (biased) } { P (head \\mid fair) \\: P (fair) + P (head \\mid biased) \\: P (biased) } $<br/>\n",
    "<br/>\n",
    "$ P (biased \\mid head) = \\frac { 0.25 \\: 0.1 } { 0.5 \\times 0.9 + 0.25 \\times 0.1 } $<br/>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0526315789474\n"
     ]
    }
   ],
   "source": [
    "P_biased_head = (0.25 * 0.1) / (0.5 * 0.9 + 0.25 * 0.1)\n",
    "print(P_biased_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. New evidence! (Second loop)\n",
    "\n",
    "After a second flip, $D = [head, head]$\n",
    "\n",
    "We'll use our previous results as priors:\n",
    "\n",
    "$$ P (fair) = 0.947 $$\n",
    "$$ P (biased) = 0.052 $$\n",
    "\n",
    "And consider we've just observed one new evidence $ D=[head] $\n",
    "\n",
    "H = \"fair coin\"\n",
    "\n",
    "$ P (fair \\mid head) = ... $\n",
    "\n",
    "<br/>\n",
    "<details>\n",
    "<summary>Click here to see the solution below</summary>\n",
    "<br/>\n",
    "$ P (fair \\mid head) = \\frac { P (head \\mid fair) \\: P (fair) } { P (head \\mid fair) \\: P (fair) + P (head \\mid biased) \\: P (biased) } $<br/>\n",
    "<br/>\n",
    "$ P (fair \\mid head) = \\frac { 0.5 \\: 0.947 } { 0.5 \\times 0.947 + 0.25 \\times 0.053 } $<br/>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972778633796\n"
     ]
    }
   ],
   "source": [
    "P_fair_head = (0.5 * 0.947) / (0.5 * 0.947 + 0.25 * 0.053)\n",
    "print(P_fair_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = \"biased coin\"\n",
    "\n",
    "$ P (biased \\mid head) = ... $\n",
    "\n",
    "<br/>\n",
    "<details>\n",
    "<summary>Click here to see the solution below</summary>\n",
    "<br/>\n",
    "$ P (biased \\mid head) = \\frac { P (head \\mid biased) \\: P (biased) } { P (head \\mid fair) \\: P (fair) + P (head \\mid biased) \\: P (biased) } $<br/>\n",
    "<br/>\n",
    "$ P (biased \\mid head) = \\frac { 0.25 \\: 0.053 } { 0.5 \\times 0.947 + 0.25 \\times 0.053 } $<br/>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0272213662044\n"
     ]
    }
   ],
   "source": [
    "P_biased_head = (0.25 * 0.053) / (0.5 * 0.947 + 0.25 * 0.053)\n",
    "print(P_biased_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Loop N times for head\n",
    "\n",
    "If I go on drawing heads for a long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_head_fair = 0.5\n",
    "p_head_biased = 0.25\n",
    "\n",
    "p_fair_prior = 0.9\n",
    "p_biased_prior = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function we're building here, is using the likelihood of observations to update the posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(fair|D) = 0.947368421053\n",
      "p(biased|D) = 0.0526315789474\n"
     ]
    }
   ],
   "source": [
    "# we draw head\n",
    "p_fair_posterior = ((p_head_fair * p_fair_prior)\n",
    "                    / (p_head_fair * p_fair_prior\n",
    "                        + p_head_biased * p_biased_prior) )\n",
    "\n",
    "print(\"p(fair|D) = {}\".format(p_fair_posterior))\n",
    "\n",
    "p_biased_posterior = ((p_head_biased * p_biased_prior)\n",
    "                    / (p_head_fair * p_fair_prior\n",
    "                        + p_head_biased * p_biased_prior) )\n",
    "\n",
    "print(\"p(biased|D) = {}\".format(p_biased_posterior))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_fair_prior = p_fair_posterior\n",
    "p_biased_prior = p_biased_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Can we design a generic bayesian update loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_head_fair = 0.5\n",
    "p_head_biased = 0.25\n",
    "\n",
    "p_tail_fair = 1 - p_head_fair\n",
    "p_tail_biased = 1 - p_head_biased\n",
    "\n",
    "p_fair_prior = 0.9\n",
    "p_biased_prior = 0.1\n",
    "\n",
    "# evidence of previous example\n",
    "E = ['h','h']\n",
    "\n",
    "# Fake evidence for fair\n",
    "#E = ['h','t','h','t','h','t','h','t','h','t','h','t','h','t']\n",
    "\n",
    "# Fake evidence for biased\n",
    "#E = ['t','t','t','h','t','t','t','h','t','t','t','h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drew h\n",
      "   p(fair|D) = 0.947368421053\n",
      "   p(biased|D) = 0.0526315789474\n",
      "Drew h\n",
      "   p(fair|D) = 0.972972972973\n",
      "   p(biased|D) = 0.027027027027\n"
     ]
    }
   ],
   "source": [
    "for el in E:\n",
    "    print(\"Drew {}\".format(el))\n",
    "    \n",
    "    if el == 'h':\n",
    "        # we draw head\n",
    "        p_fair_posterior = ((p_head_fair * p_fair_prior)\n",
    "                            / (p_head_fair * p_fair_prior\n",
    "                                + p_head_biased * p_biased_prior) )\n",
    "        p_biased_posterior = ((p_head_biased * p_biased_prior)\n",
    "                            / (p_head_fair * p_fair_prior\n",
    "                                + p_head_biased * p_biased_prior) )\n",
    "    elif el == 't':\n",
    "        # we draw tail\n",
    "        p_fair_posterior = ((p_tail_fair * p_fair_prior)\n",
    "                            / (p_tail_fair * p_fair_prior\n",
    "                                + p_tail_biased * p_biased_prior) )\n",
    "        p_biased_posterior = ((p_tail_biased * p_biased_prior)\n",
    "                            / (p_tail_fair * p_fair_prior\n",
    "                                + p_head_biased * p_biased_prior) )\n",
    "\n",
    "    print(\"   p(fair|D) = {}\".format(p_fair_posterior))\n",
    "    print(\"   p(biased|D) = {}\".format(p_biased_posterior))\n",
    "\n",
    "    p_fair_prior = p_fair_posterior\n",
    "    p_biased_prior = p_biased_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "\n",
    "Imagine we have hypothesis about all the possible probabilities of that coin we're flipping. And we want to estimate how unfair it is, what is its probability for heads/tails.\n",
    "\n",
    "Let's imagine all possible hypothesis and assign priors on them.\n",
    "\n",
    "Let's \"feed\" evidence into a loop using:\n",
    "\n",
    "$$ posterior \\sim likelihood \\times prior $$\n",
    "\n",
    "![](images/bayes-update.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
