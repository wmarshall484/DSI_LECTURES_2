{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Web Services (AWS)\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Describe core AWS services & concepts\n",
    "- Configure your laptop to use AWS\n",
    "- Use SSH key to access EC2 instances\n",
    "- Launch & access EC2\n",
    "- Access S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Storage + Execution\n",
    "\n",
    "What are the primary services that Amazon AWS offers?\n",
    "\n",
    "Name | Full Name | Service\n",
    "---|---|---\n",
    "S3 | Simple Storage Service | Storage\n",
    "EC2 | Elastic Compute Cloud | Execution\n",
    "EBS | Elastic Block Store | Storage attached to EC2 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: I want to store some video files on the web. Which Amazon service should I use?</summary>\n",
    "A: S3\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: I just created an iPhone app which needs to store user profiles on the web somewhere. Which Amazon service should I use?</summary>\n",
    "A: S3\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: I want to create a web application that uses Javascript in the backend along with a MongoDB database. Which Amazon service should I use?</summary>\n",
    "A: S3 + EC2 + EBS\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 vs. EBS\n",
    "\n",
    "What is the difference between S3 and EBS? Why would I use one versus the other?\n",
    "\n",
    "Feature | S3 | EBS\n",
    "---|---|---\n",
    "Can be accessed from | Anywhere on the web;<br/>any EC2 instance | Specific availability zone;<br/>EC2 instance attached to it\n",
    "Pricing | Less expensive;<br/>Storage (3¢/GB);<br/>Use (1¢/10,000 requests) | More expensive;<br/>Storage (3¢/GB) [+ IOPS]\n",
    "Latency | Higher | Lower\n",
    "Throughput | Usually more | Usually ess\n",
    "Performance | Slightly worse |Slightly better\n",
    "Max volume size | Unlimited | 16 TB\n",
    "Max file size | 5 TB | 16 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: What is latency?</summary>\n",
    "A: Latency is the time it takes between making a request and the start of a response.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: Which is better?  Higher latency or lower?</summary>\n",
    "A: Lower is better.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: Why is S3 latency higher than EBS?</summary>\n",
    "A: One reason is that EBS is in the same availability zone.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buckets and Files\n",
    "\n",
    "What is a bucket?\n",
    "- A bucket is a container for files.\n",
    "- Think of a bucket as a logical grouping of files like a sub-domain.\n",
    "- A bucket can contain an arbitrary number of files.\n",
    "\n",
    "How large can a file in a bucket be?\n",
    "- A file in a bucket can be 5 TB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket Names\n",
    "\n",
    "What are best practices on naming buckets?\n",
    "- Bucket names must be unique across all of s3.\n",
    "- Bucket names must be at least 3 and no more than 63 characters long.\n",
    "- Bucket names must be a series of one or more labels, separated by a single period. \n",
    "- Bucket names can contain lowercase letters, numbers, and hyphens. \n",
    "- Each label must start and end with a lowercase letter or a number.\n",
    "- Bucket names must _not_ be formatted as an IP address (e.g., 192.168.5.4).\n",
    "\n",
    "What are some examples of valid bucket names?\n",
    "- `myawsbucket`\n",
    "- `my.aws.bucket`\n",
    "- `myawsbucket.1`\n",
    "\n",
    "What are some examples of invalid bucket names? \n",
    "- `.myawsbucket`\n",
    "- `myawsbucket.`\n",
    "- `my..examplebucket`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: Why are these bucket names invalid?</summary>\n",
    "A: Bucket names cannot start or end with a period. And they cannot have a multiple periods next to each other.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python - AWS Integration with boto & boto3\n",
    "http://boto3.readthedocs.io/en/latest/guide/quickstart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Boto is the Amazon Web Services (AWS) SDK for Python, which allows Python developers to write software that makes use of Amazon services like S3 and EC2. Boto provides an easy to use, object-oriented API as well as low-level direct service access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Credentials\n",
    "\n",
    "\n",
    "Get your access key and secret key from the `credentials.csv` that you downloaded from AWS. (https://console.aws.amazon.com/iam/home?region=us-east-1#/users)\n",
    "\n",
    "Create a file called `~/.aws/credentials` (on Linux/Mac) or `%USERPROFILE%\\.aws\\credentials` (on Windows), and insert the following code into it. Replace `ACCESS_KEY` and `SECRET_KEY` with the S3 keys you got from Amazon.\n",
    "  \n",
    "```\n",
    "[default]\n",
    "aws_access_key_id = ACCESS_KEY\n",
    "aws_secret_access_key = SECRET_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a Connection to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boto 2.x\n",
    "import boto\n",
    "boto_connection = boto.connect_s3()\n",
    "\n",
    "# Boto 3\n",
    "import boto3\n",
    "boto3_connection = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check contents of existing buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boto 2.x\n",
    "def print_s3_contents_boto(connection):\n",
    "    for bucket in connection:\n",
    "        for key in bucket:\n",
    "            print(key.name)\n",
    "\n",
    "# Boto 3\n",
    "def print_s3_contents_boto3(connection):\n",
    "    for bucket in connection.buckets.all():\n",
    "        for key in bucket.objects.all():\n",
    "            print(key.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_s3_contents_boto(boto_connection)\n",
    "print_s3_contents_boto3(boto3_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing there yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Bucket(name='elliotcohen-new-bucket')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "username = os.environ['USER']\n",
    "bucket_name = username + \"-new-bucket\"\n",
    "\n",
    "# Boto 2.x\n",
    "boto_connection.create_bucket(bucket_name)\n",
    "boto_connection.create_bucket(bucket_name)\n",
    "\n",
    "# Boto 3\n",
    "boto3_connection.create_bucket(Bucket=bucket_name)\n",
    "boto3_connection.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Access a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello-boto.txt\n"
     ]
    }
   ],
   "source": [
    "# Boto 2.x\n",
    "bucket = boto_connection.get_bucket(bucket_name, validate=False)\n",
    "exists = boto_connection.lookup(bucket_name)\n",
    "if exists:\n",
    "    file = bucket.new_key('hello-boto.txt')\n",
    "    file.set_contents_from_string('Hello world from boto!')\n",
    "    \n",
    "print_s3_contents_boto(boto_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello-boto.txt\n",
      "hello-boto3.txt\n"
     ]
    }
   ],
   "source": [
    "# Boto 3\n",
    "import botocore\n",
    "bucket = boto3_connection.Bucket(bucket_name)\n",
    "exists = True\n",
    "try:\n",
    "    boto3_connection.meta.client.head_bucket(Bucket=bucket_name)\n",
    "    boto3_connection.Object(bucket_name, 'hello-boto3.txt').put(Body=open('tmp/hello.txt', 'rb'))\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    # If a client error is thrown, then check that it was a 404 error.\n",
    "    # If it was a 404 error, then the bucket does not exist.\n",
    "    error_code = int(e.response['Error']['Code'])\n",
    "    if error_code == 404:\n",
    "        exists = False\n",
    "        \n",
    "print_s3_contents_boto3(boto3_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Control Access to a Bucket and its Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, can we access our newly-created file on s3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://s3.amazonaws.com/elliotcohen-new-bucket/hello-boto.txt\n"
     ]
    }
   ],
   "source": [
    "# let's find out...\n",
    "def s3_url(bucket, key):\n",
    "    return 'http://s3.amazonaws.com/{}/{}'.format(bucket, key)\n",
    "\n",
    "print(s3_url(bucket_name, 'hello-boto.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'HTTPHeaders': {'content-length': '0',\n",
       "   'date': 'Mon, 30 Oct 2017 04:28:16 GMT',\n",
       "   'server': 'AmazonS3',\n",
       "   'x-amz-id-2': 'EVfTc1lY+aZj41q2lnkY2+xZWTq/uLLUZZ6wCtykhf1oduJ+wGsbJNc/lLPTasHksUIj0TD01/M=',\n",
       "   'x-amz-request-id': '0D79BEA5BEDAB844'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HostId': 'EVfTc1lY+aZj41q2lnkY2+xZWTq/uLLUZZ6wCtykhf1oduJ+wGsbJNc/lLPTasHksUIj0TD01/M=',\n",
       "  'RequestId': '0D79BEA5BEDAB844',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boto 2.x\n",
    "bucket = boto_connection.get_bucket(bucket_name, validate=False)\n",
    "key = bucket.get_key('hello-boto.txt')\n",
    "bucket.set_acl('public-read')\n",
    "key.set_acl('public-read')\n",
    "\n",
    "# Boto 3\n",
    "bucket = boto3_connection.Bucket(bucket_name)\n",
    "obj = boto3_connection.Object(bucket_name,'hello-boto3.txt')\n",
    "bucket.Acl().put(ACL='public-read')\n",
    "obj.Acl().put(ACL='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://s3.amazonaws.com/elliotcohen-new-bucket/hello-boto.txt\n"
     ]
    }
   ],
   "source": [
    "# Now let's try again\n",
    "print(s3_url(bucket_name, 'hello-boto.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Delete a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto 2.x\n",
    "bucket = boto_connection.get_bucket(bucket_name, validate=False)\n",
    "for key in bucket:\n",
    "    key.delete()\n",
    "bucket.delete()\n",
    "\n",
    "# # Boto 3\n",
    "# bucket = s3.Bucket(bucket_name)\n",
    "# for key in bucket.objects.all():\n",
    "#     key.delete()\n",
    "# bucket.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have deleted our bucket and its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_s3_contents_boto(boto_connection)\n",
    "print_s3_contents_boto3(boto3_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success! \n",
    "We have successfully connected to s3, created a new bucket, added content, deleted that content and deleted the bucket itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Issues and What To Do About Them\n",
    "First, let's review keys steps from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Connect to s3\n",
    "import boto\n",
    "conn = boto.connect_s3()\n",
    "conn\n",
    "\n",
    "# Step 2: List all existing buckets\n",
    "conn.get_all_buckets()\n",
    "\n",
    "# Step 3: Create a new bucket\n",
    "import os\n",
    "username = os.environ['USER']\n",
    "bucket_name = username + \"-new-bucket\"\n",
    "bucket = conn.create_bucket(bucket_name)\n",
    "\n",
    "# Step 4: Connect to bucket\n",
    "bucket = conn.get_bucket(bucket_name, validate=False)\n",
    "\n",
    "# Step 5: View contents\n",
    "for key in bucket:\n",
    "    print(key.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 1:  Boto is not able to find my credentials\n",
    "\n",
    "**Q**: Boto is not able to find my credentials.  \n",
    "**A**: Upgrade Boto. Older versions of Boto were not able to read the credentials file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.48.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2: How do I read/write numeric data to s3?\n",
    "**Q**: Previously we saw how to read/write a plain-text file to s3, but what about quantitative data?  \n",
    "**A**: We will encode the data as a string along the way, but we can retrieve with fidelity and ease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall how we read/write a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello World!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's how we read/write a plain text file\n",
    "file = bucket.new_key('hello-world.txt')\n",
    "file.set_contents_from_string('Hello World!')\n",
    "\n",
    "# List files again; new file should appear\n",
    "bucket.get_all_keys()\n",
    "\n",
    "# Retrieve file from a bucket\n",
    "retrieved_file = bucket.get_key('hello-world.txt')\n",
    "retrieved_file.get_contents_as_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try with numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 351, -340, -163, -354],\n",
       "       [-143,  280,  221, -358],\n",
       "       [ 111, -349, -261,  -76],\n",
       "       [ -17, -239, -310,  -77],\n",
       "       [ 310,  264, -109,  154],\n",
       "       [-261,  198, -259, -187],\n",
       "       [  51, -158,  -60,   56],\n",
       "       [ 137,  -72,  241,  332],\n",
       "       [-187,   37,  192,  179],\n",
       "       [ 189,  -11,  -84,  196]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, create some data locally\n",
    "import numpy as np\n",
    "\n",
    "n = 1000\n",
    "mat = np.random.randint(-360,360, n*4).reshape(n,4)\n",
    "mat[np.where(mat==0)] = 1\n",
    "\n",
    "# and write it to csv\n",
    "np.savetxt(\"random_coordinates.csv\", mat, delimiter=\",\")\n",
    "\n",
    "# here's the first ten rows\n",
    "mat[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101991"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write data from local file to s3\n",
    "file = bucket.new_key('random_coordinates.csv')\n",
    "file.set_contents_from_filename('random_coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve data from s3\n",
    "retrieved_file = bucket.get_key('random_coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do we get the data out?\n",
    "c = retrieved_file.get_contents_as_string()\n",
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 351., -340., -163., -354.],\n",
       "       [-143.,  280.,  221., -358.],\n",
       "       [ 111., -349., -261.,  -76.],\n",
       "       [ -17., -239., -310.,  -77.],\n",
       "       [ 310.,  264., -109.,  154.],\n",
       "       [-261.,  198., -259., -187.],\n",
       "       [  51., -158.,  -60.,   56.],\n",
       "       [ 137.,  -72.,  241.,  332.],\n",
       "       [-187.,   37.,  192.,  179.],\n",
       "       [ 189.,  -11.,  -84.,  196.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "df = pd.read_csv(io.BytesIO(c), header=None)\n",
    "arr = df.values\n",
    "arr[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm nothing was scrambled in transmission\n",
    "(arr == mat).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 3: Creating Buckets With Periods\n",
    "\n",
    "**Q**: How can I create a bucket in Boto with a period in the name?\n",
    "- There is a bug in Boto that causes `create_bucket` to fail if the bucket name has a period in it. \n",
    "- Try creating the bucket with a period in its name. This should fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: hostname 'elliotcohen-new-bucket.1.2.3.s3.amazonaws.com' doesn't match either of '*.s3.amazonaws.com', 's3.amazonaws.com'\n"
     ]
    }
   ],
   "source": [
    "bucket_name_with_period = bucket_name + \".1.2.3\"\n",
    "\n",
    "try:\n",
    "    bucket_with_period = conn.create_bucket(bucket_name_with_period)\n",
    "    bucket_with_period\n",
    "except Exception as e:\n",
    "    print(\"ERROR: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: Run this code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "if hasattr(ssl, '_create_unverified_context'):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now try creating th- e bucket with a period in its name and it should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Bucket: elliotcohen-new-bucket.1.2.3>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name_with_period = bucket_name + \".1.2.3\"\n",
    "\n",
    "bucket_with_period = conn.create_bucket(bucket_name_with_period)\n",
    "\n",
    "bucket_with_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to delete buckets when you're done with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucket_with_period.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For more details see <https://github.com/boto/boto/issues/2836>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 4: Access Control\n",
    "\n",
    "Q: I want to access my S3 file from a web browser without giving my access and secret keys. How can I open up access to the file to anyone?\n",
    "- You can set up Access Control Lists (ACLs) at the level of the bucket or at the level of the individual objects in the bucket (folders, files).\n",
    "\n",
    "Q: What are the different ACL policies?\n",
    "\n",
    "ACL Policy | Meaning\n",
    "---|---\n",
    "`private` | No one else besides owner has any access rights.\n",
    "`public-read` | Everyone has read access.\n",
    "`public-read-write` | Everyone has read/write access.\n",
    "`authenticated-read` | Registered Amazon S3 users have read access.\n",
    "\n",
    "Q: What does `read` and `write` mean for buckets and files?\n",
    "- Read access to a file lets you read the file.\n",
    "- Read access to a bucket or folder lets you see the names of the files inside it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: If a bucket is `private` and a file inside it is `public-read` can I view it through a web browser?</summary>\n",
    "A: Yes. Access to the file is only determined by its ACL policy.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: If a bucket is `public-read` and a file inside it is `private` can I view the file through a web browser?</summary>\n",
    "A: No, you cannot. However, if you access the URL for the bucket you will see the file listed.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Access Control Into Action\n",
    "**Q**: How can I make a file available on the web so anyone can read it?  \n",
    "**A**: Create a file with a specific ACL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = bucket.new_key('yet-another-hello-world.txt')\n",
    "file.set_contents_from_string('Hello World!', policy = 'private')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try reading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n",
      "<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>9B06D59CE0972453</RequestId><HostId>SlxFASurSZ2UNVzlsBC489zWTiMwWfWQ/gEh0gc1MYtqpAb3X++0pecMnppyn67AFsiiiQRCynk=</HostId></Error>"
     ]
    }
   ],
   "source": [
    "file_url = 'http://s3.amazonaws.com/' + bucket_name + '/yet-another-hello-world.txt'\n",
    "\n",
    "!curl $file_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now change its ACL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!"
     ]
    }
   ],
   "source": [
    "file.set_acl('public-read')\n",
    "\n",
    "!curl $file_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Also you can try accessing the file through the browser.\n",
    "- If you do not specify the ACL for a file when you set its contents, the file is `private` by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 5: URL for S3 Files\n",
    "\n",
    "**Q**: How can I figure out the URL of my S3 file?  \n",
    "**A**: You can compose the URL using the region, bucket, and filename. \n",
    "- For 'N. Virginia' the general template for the URL is `http://s3.amazonaws.com/BUCKET/FILE`.\n",
    "    - Region-specific endpoint is http://s3-AWSREGION.amazonaws.com/BUCKET/FILE.\n",
    "- You can also find the URL by looking at the file on the AWS web console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 6: Deleting Buckets\n",
    "\n",
    "**Q**: How can I delete a bucket?\n",
    "- Try deleting a bucket containing files. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: S3ResponseError: 409 Conflict\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<Error><Code>BucketNotEmpty</Code><Message>The bucket you tried to delete is not empty</Message><BucketName>elliotcohen-new-bucket</BucketName><RequestId>F10856313CDE00F0</RequestId><HostId>rRbpeg1xIMJ88+VXgX5ivZ3TScUCSqOGhLmO4MrOy3VQEJo8YGDEM902sZfoRvQ24BDEaHUbEbU=</HostId></Error>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bucket.delete()\n",
    "except Exception as e:\n",
    "    print(\"Error: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To delete the bucket first delete all the files in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in bucket.get_all_keys(): \n",
    "    key.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then delete the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before bucket deletion\n",
      "[<Bucket: elliotcohen-new-bucket>]\n",
      "After bucket deletion\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print ('Before bucket deletion')\n",
    "print (conn.get_all_buckets())\n",
    "\n",
    "bucket.delete()\n",
    "\n",
    "print ('After bucket deletion')\n",
    "print (conn.get_all_buckets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Go Forth and Conquer the Individual Excercise\n",
    "We have covered EC2 in a previous lecture, so the note below are for reference only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions\n",
    "\n",
    "Q: What are *AWS Regions*?\n",
    "- AWS is hosted in different geographic locations worldwide. \n",
    "- For example, there are 4 regions in the US.\n",
    "\n",
    "Q: What are the regions in the US\n",
    "\n",
    "Region | Name | Location \n",
    "---|---|--- \n",
    "us-east-1 | US East | N. Virginia\n",
    "us-east-2 | US East 2 | Ohio\n",
    "us-west-1 | US West | N. California\n",
    "us-west-2 | US West 2 | Oregon\n",
    "\n",
    "Q: How should I choose a region?\n",
    "- N. Virginia or `us-east-1` is the default region for EC2.\n",
    "- Using a region other than N. Virginia requires additional configuration.\n",
    "- If you are not sure choose N. Virginia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability Zones\n",
    "\n",
    "Q: What are *AWS Availability Zones*?\n",
    "\n",
    "- Regions are divided into isolated availability zones for fault tolerance.\n",
    "- Availability zones run on physically separate hardware and infrastructure.\n",
    "- They do not share hardware, generators, or cooling equipment. \n",
    "- Availability zones are assigned automatically to your EC2 instances based on your user ID.\n",
    "\n",
    "<img src='assets/aws_regions.png'>\n",
    "\n",
    "<details>\n",
    "<summary>Q: Is it possible for two separate users to coordinate and land on the same availability zone?</summary>\n",
    "1. Availability zones are assigned automatically by the system.\n",
    "2. It is not possible for two AWS users to coordinate and be hosted on the same availability zone.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to EC2\n",
    "\n",
    "Q: How can I connect to an EC2 instance?\n",
    "- Login to the AWS console.\n",
    "- Navigate: EC2 > Launch Instance > Community AMIs > Search community AMIs > `ami-a4c7edb2` (An Amazon AMI)\n",
    "- View the instance and get its Public DNS.\n",
    "    - This should look something like `ec2-34-229-96-155.compute-1.amazonaws.com`.\n",
    "- Use this command to connect to it.\n",
    "    - `ssh -X -i ~/.ssh/keypair.pem user@domain`\n",
    "    - Here is an example:\n",
    "        - `ssh -X -i ~/.ssh/keypair.pem ec2-user@ec2-34-229-96-155.compute-1.amazonaws.com`\n",
    "- Make sure you replace the Public DNS value below with the value you have for your instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying Files to EC2\n",
    "\n",
    "Q: How can I copy files to the EC2 instance?\n",
    "- To copy a file `myfile.txt` to EC2, use a command like this.\n",
    "    - `scp -i ~/.ssh/keypair.pem myfile.txt user@domain:`\n",
    "- To copy a directory `mydir` recursively to EC2, use a command like this. \n",
    "    - `scp -i ~/.ssh/keypair.pem -r mydir user@domain:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: When you copy a file to EC2 with `scp` will this show up in S3?</summary>\n",
    "A: No. The file will be stored on the disk on the EC2 instance. It will not be in S3.\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
