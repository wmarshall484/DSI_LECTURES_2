{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough : indexing Bag-of-Words into a vector table\n",
    "\n",
    "This Walkthrough will lead us from bag-of-words representations of documents to **vector signatures** (indexes) using the **TF-IDF** formula.\n",
    "\n",
    "The ultimate goal of **indexing** is to create a **vector representation** (signature) for each document. This vector representation will be used for:\n",
    "\n",
    "- mine the features that can caracterize classes of documents (supervised learning using **labels**)\n",
    "- mine the documents that have similar features to establish trends (unsupervised learning).\n",
    "\n",
    "To do that, we need:\n",
    "- a fixed number of features\n",
    "- a quantitative value for each feature.\n",
    "\n",
    "The number of features is given by the vocabulary over the corpus: the set of all possible words (tokens) found in all documents.\n",
    "\n",
    "The quantitative value is given, for each doc, by counting the occurences of each of these words in the doc and by using a TF-IDF formula.\n",
    "\n",
    "<img src=\"img/pipeline-walkthrough2.png\" width=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading some input data from the Amazon Reviews\n",
    "\n",
    "To try this indexing walkthrough, we will get 5 reviews from the Amazon Reviews dataset. We will apply a function for extracting bag-of-words representations from these 5 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- review: Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\n",
      "--- bow: [u'much', u'filter', u'pop', u'record', u'more', u'crisp', u'lowest', u'price', u'filter', u'amazon', u'same', u'price']\n",
      "\n",
      "--- review: The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\n",
      "--- bow: [u'product', u'doubl', u'better', u'ad', u'bonus', u'screen', u'small', u'hint', u'smell', u'old', u'grape', u'candi', u'reminisc', u'sake', u'pop', u'filter', u'nose', u'dif', u'pop', u'filter', u'expens', u'one', u'aroma', u'mine', u'product', ']']\n",
      "\n",
      "--- review: The primary job of this device is to block the breath that would otherwise produce a popping sound, while allowing your voice to pass through with no noticeable reduction of volume or high frequencies. The double cloth filter blocks the pops and lets the voice through with no coloration. The metal clamp mount attaches to the mike stand secure enough to keep it attached. The goose neck needs a little coaxing to stay where you put it.\n",
      "--- bow: [u'primari', u'job', u'devic', u'breath', u'pop', u'sound', u'voic', u'notic', u'reduct', u'volum', u'high', u'frequenc', u'doubl', u'cloth', u'filter', u'pop', u'voic', u'color', u'metal', u'clamp', u'mount', u'attach', u'mike', u'secur', u'enough', u'attach', u'goos', u'neck', u'littl', u'coax']\n",
      "\n",
      "--- review: Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only marginally able to hold the screen in position and requires careful positioning of the clamp to avoid sagging.\n",
      "--- bow: [u'nice', u'windscreen', u'protect', u'mxl', u'mic', u'prevent', u'pop', u'thing', u'gooseneck', u'abl', u'screen', u'posit', u'care', u'posit', u'clamp', u'sag']\n",
      "\n",
      "--- review: This pop filter is great. It looks and performs like a studio filter. If you're recording vocals this will eliminate the pops that gets recorded when you sing.\n",
      "--- bow: [u'pop', u'filter', u'great', u'perform', u'studio', u'filter', u'vocal', u'pop']\n"
     ]
    }
   ],
   "source": [
    "import os               # for environ variables in Part 3\n",
    "from nlp_pipeline import extract_bow_from_raw_text\n",
    "import json\n",
    "\n",
    "docs = []\n",
    "with open('./reviews.json', 'r') as data_file:    \n",
    "    for line in data_file:\n",
    "        docs.append(json.loads(line))\n",
    "\n",
    "# extracting bows\n",
    "bows = list(map(lambda row: extract_bow_from_raw_text(row['reviewText']), docs))\n",
    "\n",
    "# displaying bows\n",
    "for i in range(len(docs)):\n",
    "    print(\"\\n--- review: {}\".format(docs[i]['reviewText']))\n",
    "    print(\"--- bow: {}\".format(bows[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Obtaining vocabulary and term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# term occurence = counting distinct words in each bag\n",
    "term_occ = list(map(lambda bow : Counter(bow), bows))\n",
    "\n",
    "# term frequency = occurences over length of bag\n",
    "term_freq = list()\n",
    "for i in range(len(docs)):\n",
    "    term_freq.append( {k: (v / float(len(bows[i])))\n",
    "                       for k, v in term_occ[i].items()} )\n",
    "\n",
    "# displaying occurences\n",
    "for i in range(len(docs)):\n",
    "    print(\"\\n--- review: {}\".format(docs[i]['reviewText']))\n",
    "    print(\"--- bow: {}\".format(bows[i]))\n",
    "    print(\"--- term_occ: {}\".format(term_occ[i]))\n",
    "    print(\"--- term_freq: {}\".format(term_freq[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Obtaining document frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# document occurence = number of documents having this word\n",
    "# term frequency = occurences over length of bag\n",
    "\n",
    "doc_occ = Counter( [word for bow in bows for word in set(bow)] )\n",
    "\n",
    "# document frequency = occurences over length of corpus\n",
    "doc_freq = {k: (v / float(len(docs)))\n",
    "            for k, v in doc_occ.items()}\n",
    "\n",
    "# displaying vocabulary\n",
    "print(\"\\n--- full vocabulary: {}\".format(doc_occ))\n",
    "print(\"\\n--- doc freq: {}\".format(doc_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transforming frequencies into a TF-IDF vector\n",
    "\n",
    "TF-IDF is an acronym for the product of two parts: the term frequency tf and what is called the inverse document frequency idf. The term frequency is just the counts in a term frequency vector. \n",
    "\n",
    "$tf(term,document) = \\# \\ of \\ times \\ a \\ term \\ appears \\ in \\ a \\ document$\n",
    "\n",
    "The idf part is defined in terms of the document frequency. The document frequency is \n",
    "\n",
    "$df(term,corpus) = \\frac{ \\# \\ of \\ documents \\ that \\ contain \\ a \\ term}{ \\# \\ of \\ documents \\ in \\ the \\ corpus}$\n",
    "\n",
    "The inverse document frequency is defined in terms of the document frequency as\n",
    "\n",
    "$idf(term,corpus) = \\log{\\frac{1}{df(term,corpus)}}$.\n",
    "\n",
    "It is called the inverse document frequency but really it is the log of the inverse document frequency. Finally tf-idf is just\n",
    "\n",
    "tf-idf $ = tf(term,document) * idf(term,corpus)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the minimum document frequency (in proportion of the length of the corpus)\n",
    "min_df = 0.3\n",
    "\n",
    "# filtering items to obtain the vocabulary\n",
    "vocabulary = [ k for k,v in doc_freq.items() if v >= min_df ]\n",
    "\n",
    "# print vocabulary\n",
    "print (\"-- vocabulary (len={}): {}\".format(len(vocabulary),vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create a dense matrix of vectors for each document\n",
    "# each vector has the length of the vocabulary\n",
    "vectors = np.zeros((len(docs),len(vocabulary)))\n",
    "\n",
    "# fill these vectors with tf-idf values\n",
    "for i in range(len(docs)):\n",
    "    for j in range(len(vocabulary)):\n",
    "        term     = vocabulary[j]\n",
    "        term_tf  = term_freq[i].get(term, 0.0)   # 0.0 if term not found in doc\n",
    "        term_idf = np.log(1 + 1 / doc_freq[term]) # smooth formula\n",
    "        vectors[i,j] = term_tf * term_idf\n",
    "\n",
    "# displaying results\n",
    "for i in range(len(docs)):\n",
    "    print(\"\\n--- review: {}\".format(docs[i]['reviewText']))\n",
    "    print(\"--- bow: {}\".format(bows[i]))\n",
    "    print(\"--- tfidf vector: {}\".format( vectors[i] ) )\n",
    "    print(\"--- tfidf sorted: {}\".format( \n",
    "            sorted( zip(vocabulary,vectors[i]), key=lambda x:-x[1] )\n",
    "         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
