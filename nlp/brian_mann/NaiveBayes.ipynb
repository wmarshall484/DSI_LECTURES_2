{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "A simple (naive) classifier that tends to work will with unstructured text data (i.e. spam detection).\n",
    "\n",
    "### Pros\n",
    "\n",
    "* Works well when # of features >> # of observations\n",
    "* Good at online learning (i.e. streaming data)\n",
    "* Simple to implement\n",
    "\n",
    "### Cons\n",
    "\n",
    "* Works poorly with irrelevant features (unlike trees)\n",
    "* Can be outperformed by more complicated models\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "Example with spam detection in email:\n",
    "\n",
    "Suppose $c$ is the classification of the email, \"spam\" or \"not spam\". and $X$ is our document (a set of words $X = \\{ x_i \\}$ in our vocabulary). \n",
    "\n",
    "Remeber Bayes' Theorem:\n",
    "\n",
    "$$ P(c | X) = \\frac{P(X | c) P(c)}{P(X)} $$\n",
    "\n",
    "If we make the assumption that the probabilities of each word $x_i$ appearing in $X$ is independent (which it probably isn't but...):\n",
    "\n",
    "$$ P(c | X) \\propto P(c) \\times P(x_1 | c) \\times \\cdots \\times P(x_n | c) $$\n",
    "\n",
    "### Training the model\n",
    "\n",
    "To compute $P(c | X)$ we need to know $P(c)$ and $P(x_i | c)$. \n",
    "\n",
    "* $P(c)$ = the probability that any given email is spam. Make some assumption about this based on your data or knowledge (i.e. you know 4 of every 10 emails is spam). \n",
    "\n",
    "* $\\displaystyle P(x | c) = \\frac{\\text{# of times x appears in emails of class c}}{\\text{# of words in emails of class c}}$\n",
    "\n",
    "__This doesn't quite work. Why not?__\n",
    "\n",
    "### Laplace Smoothing\n",
    "\n",
    "* Do something like $$P(x | c) = \\frac{\\text{# of times x appears in emails of class c} + \\alpha}{(\\text{# of words in emails of class c}) + \\alpha \\times (\\text{# of words in corpus})}$$\n",
    "\n",
    "\n",
    "## Log Likelihood\n",
    "\n",
    "* Probability values can be very close to 0. \n",
    "* Mathematically, no problem\n",
    "* Computationally, can get numerical under/overflow problems.\n",
    "\n",
    "Since \n",
    "\n",
    "$$ P(c | X) = P(c) \\times P(x_1 | c) \\times \\cdots \\times P(x_n | c) $$\n",
    "\n",
    "we have\n",
    "\n",
    "$$ \\log{P(c | X)} = \\log P(c) + \\sum_i \\log P(x_i | c)$$\n",
    "\n",
    "The result of our classifier will be\n",
    "\n",
    "$$argmax_c P(c | X)$$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
