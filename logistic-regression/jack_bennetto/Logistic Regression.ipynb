{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "### Jack Bennetto\n",
    "#### March 20, 2018\n",
    "\n",
    "## Standards/Objectives\n",
    "\n",
    " * Place logistic regression in the taxonomy of ML algorithms\n",
    " * Explain the key differences and similarities between logistic and linear regression.\n",
    " * Fit and interpret a logistic regression model in scikit-learn\n",
    " * Interpret the coefficients of logistic regression, using odds ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression as a model\n",
    "\n",
    "Logistic regression is a supervised-learning parametric classification model. It's generally the first thing you try when building a classifier, and is actually used in some production environments.\n",
    "\n",
    "Advantages:\n",
    "\n",
    " * Fast (for training and prediction)\n",
    " * Simple (few hyperparameters)\n",
    " * Interpretable\n",
    " * Provides probability\n",
    " \n",
    "Disadvantages\n",
    "\n",
    " * Requires feature engineering to capture non-linear relationships\n",
    " * Doesn't work for p > n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why not linear regression?\n",
    "\n",
    "Let's suppose we have some (fake) data, but that $y$ (the target) is always either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 100\n",
    "\n",
    "X = scs.uniform(-9, 18).rvs(npts).reshape(npts,1)\n",
    "y = scs.bernoulli(scipy.special.expit(X[:,0])).rvs(npts)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y, 'o', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just learned linear regression. Let's use that to predict $y$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "ax.plot(X, model.predict(X))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion: what's wrong with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to linear regression\n",
    "\n",
    "Recall that with linear regression we assume the data follows the form\n",
    "\n",
    "$$\\begin{align}\n",
    "Y & = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... \\beta_p X_p + \\epsilon \\\\\n",
    "  & = \\mathbf{X} \\beta + \\epsilon\n",
    "\\end{align}$$\n",
    "\n",
    "where again\n",
    "\n",
    "$$\\epsilon \\sim N(0, \\sigma)$$\n",
    "\n",
    "Alternatively, we could say\n",
    "$$Y \\sim N(\\mathbf{X} \\beta, \\sigma)$$\n",
    "\n",
    "From there, we want to find the values for $\\beta$ that are the most likely to produce the data. The MLE estimate gives us ordinary least squares.\n",
    "\n",
    "Question: what is MLE?\n",
    "\n",
    "Discussion: how can we to the build a classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a model\n",
    "\n",
    "To do any sort of prediction we need to create a model. Since we have two possible values of $y$ we assume the data is the result of a Bernoulli distribution, where $p$ is a function of $\\mathbf{X}$.\n",
    "\n",
    "$$Y \\sim Bernoulli(f(\\mathbf{X}))$$\n",
    "\n",
    "We want our model to include some parameters so, as with linear regression, we'll have the function depend on the product of those parameters and $\\mathbf{X}$.\n",
    "\n",
    "$$Y \\sim Bernoulli(f(\\mathbf{X} \\beta))$$\n",
    "\n",
    "or\n",
    "\n",
    "\n",
    "$$Y \\sim Bernoulli(f(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... \\beta_p X_p)$$\n",
    "\n",
    "For $f$ we want a function with values from 0 to 1, what's called a sigmoid function. There are a number of different choices, but (for reasons we'll talk about later), the usual choice is something called the logistic function.\n",
    "\n",
    "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Question: now that we have a model, how should we find the best fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "xpts = np.linspace(-6, 6, 100)\n",
    "ax.plot(xpts, 1/(1+np.exp(-xpts)), label='logistic', lw=2)\n",
    "ax.plot(xpts, scs.norm(0,1).cdf((2*np.pi)**.5/4 * xpts), label='error function/cdf of gaussian (rescaled)')\n",
    "ax.plot(xpts, np.arctan(np.pi/4*xpts)/np.pi + 0.5, label='arctan (rescaled)')\n",
    "ax.legend()\n",
    "ax.set_title(\"Assorted monotonic functions going from 0 to 1\")\n",
    "ax.set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we solve with maximum-likelihood estimation. Note that there isn't a close-form solution here; the computer has to solve numerically using some form of gradiant descent (we'll talk about this in the next few days)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (with fake data)\n",
    "\n",
    "We'll generate fake data that matches the distribution exactly and try to recover the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npts = 100\n",
    "beta0 = 0.0\n",
    "beta1 = 0.5\n",
    "\n",
    "X = scs.uniform(-9, 18).rvs(npts).reshape(npts,1)\n",
    "# the expit function is the same as the logistic function\n",
    "y = scs.bernoulli(logistic(beta0 + beta1*X[:,0])).rvs(npts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We graph the data; the vertical line shows the actual decision boundary where the probability is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = scs.uniform(-0.03,0.06).rvs(npts)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], y + jitter, s=10, alpha=0.5)\n",
    "ax.axvline(-beta0/beta1, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set C large to suppress regularization\n",
    "model = LogisticRegression(C=1000)\n",
    "model.fit(X, y)\n",
    "beta0hat = model.intercept_[0]\n",
    "beta1hat = model.coef_[0][0]\n",
    "print(\"beta0 =    {0:8.3f} beta1 =    {1:8.3f}\".format(beta0, beta1))\n",
    "print(\"beta0hat = {0:8.3f} beta1hat = {1:8.3f}\".format(beta0hat, beta1hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw the curve we fitted on the data, along with the actual curve used to create the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpts = np.linspace(-9, 9, 100)\n",
    "yhatpts = logistic(beta0hat + beta1hat * xpts)\n",
    "ypts = logistic(beta0 + beta1 * xpts)\n",
    "\n",
    "jitter = scs.uniform(-0.03,0.06).rvs(npts)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "ax.scatter(X[:,0], y + jitter, s=10, alpha=0.5, color='blue', label=\"generated data\")\n",
    "ax.plot(xpts, ypts, 'k', label='actual curve')\n",
    "ax.plot(xpts, yhatpts, 'r', label='fitted curve')\n",
    "ax.axhline(0.5, color='black')\n",
    "#ax.axvline(-beta0/beta1, color='black', label='actual boundary')\n",
    "ax.set_title(\"Fitted logistic curve\")\n",
    "ax.legend(loc='center right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log odds ratio\n",
    "\n",
    "In gampling people often talk about **odds**. If the local sportsball is favored to win 3-to-1 (or 3:1), that means that the ratio of the probability of winning is three times as great as the probability of loosing, so they have a 75% chance of winning. Odd of 1:1 are even; they are as likely to win as the are to loose.\n",
    "\n",
    "(In gambling people always give the larger number first, so a 25% chance of winning is said to be 3:1 against. We won't do that.)\n",
    "\n",
    "The **odds ratio** is the ratio of the of the probablity of the positive to the negative case, i.e., \n",
    "\n",
    "$$OR = \\frac{P(y=1)}{1-P(y=1)}$$\n",
    "\n",
    "Question: what's the odds ratio if $P(y=1) = 0.5$?\n",
    "\n",
    "Question: what if the probability of the positive class is 80%?\n",
    "\n",
    "Question: what if it's 20%?\n",
    "\n",
    "Question: what if it's 10%?\n",
    "\n",
    "The **log odds ratio** is just the log (base e) of that.\n",
    "\n",
    "Question: what is the log odds ratio if $P(y=1) = 0.5$\n",
    "\n",
    "Question: what if it's 80%?\n",
    "\n",
    "Question: what if it's 20%?\n",
    "\n",
    "So what does that have to do with logistic regression? The logistic function takes the log odds of something and returns the probability. Let's explore this a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpts = np.linspace(-5, 5)\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "\n",
    "ax.plot(xpts, logistic(xpts))\n",
    "\n",
    "xticks = np.arange(-5, 6, 1)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_yticks(logistic(xticks))\n",
    "\n",
    "ax.grid(color='g', linestyle='-', linewidth=1, alpha=0.5)\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-0, 1)\n",
    "ax.set_title(\"Logistic function\")\n",
    "ax.set_xlabel(\"log odds ratio\")\n",
    "ax.set_ylabel(\"probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10, 11)\n",
    "df = pd.DataFrame(['{:.3f}%'.format(a*100) for a in logistic(x)], index=x, columns=['probability'])\n",
    "df.index.name = 'log odds ratio'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The math\n",
    "\n",
    "If you're doing logistic regression, then the probability of something being in the positive class is\n",
    "$$P(y=1) = \\frac{1}{1+e^{-\\mathbf{X}\\beta}}$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\\begin{align}\n",
    "OR &= \\frac{P(y=1)}{1-P(y=1)} \\\\\n",
    "   &= \\frac{\\frac{1}{1+e^{-\\mathbf{X}\\beta}}}{1-\\frac{1}{1+e^{-\\mathbf{X}\\beta}}} \\\\\n",
    "   &= \\frac{\\frac{1}{1+e^{-\\mathbf{X}\\beta}}}{\\frac{1+e^{-\\mathbf{X}\\beta}}{1+e^{-\\mathbf{X}\\beta}}-\\frac{1}{1+e^{-\\mathbf{X}\\beta}}} \\\\\n",
    "   &= \\frac{1}{e^{-\\mathbf{X}\\beta}} \\\\\n",
    "   &= e^{\\mathbf{X}\\beta}\n",
    "\\end{align}\n",
    "$$\n",
    "so\n",
    "$$log(OR) = \\mathbf{X}\\beta$$\n",
    "\n",
    "So if you increase $X_i$ by 1, you increase $log(OR)$ by $\\beta_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundary\n",
    "\n",
    "Over the next couple weeks we'll talk about a number of different classification models. A good model will do more than just predict to which class something belongs; it will predict the probability that it is in that class.\n",
    "\n",
    "At some point, though, we need to make a decision. To do that we choose a **threshold** at which we will place something in one class or the other. The **decision boundary** is the surface in feature space at which the probability is equal to the threshold.\n",
    "\n",
    "Suppose we have two features, $X_1$ and $X_2$, and we set the threshold equal to 0.5. That corresponds to a log odds ratio of 0 so the decision boundary is at\n",
    "\n",
    "$$\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 = 0$$\n",
    "\n",
    "so\n",
    "\n",
    "$$ X_2 = \\frac{-\\beta_0}{\\beta_2} + \\frac{-\\beta_1}{\\beta_2}X_1 $$\n",
    "\n",
    "More broadly, for threshold $\\theta$, the decision boundary is the region for which\n",
    "\n",
    "$$\\theta = \\frac{1}{1+e^{-\\mathbf{X} \\beta}}$$\n",
    "\n",
    "$$\\theta + \\theta e^{-\\mathbf{X} \\beta} = 1$$\n",
    "\n",
    "$$e^{-\\mathbf{X} \\beta} = \\frac{1 - \\theta}{\\theta}$$\n",
    "\n",
    "$$\\mathbf{X} \\beta = \\ln{(\\frac{\\theta}{1 - \\theta})}$$\n",
    "\n",
    "Which again is the log odds ratio, so\n",
    "\n",
    "$$\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 = \\ln{(\\frac{\\theta}{1 - \\theta})}$$\n",
    "\n",
    "so\n",
    "\n",
    "$$X_1 = \\frac{\\ln{(\\frac{\\theta}{1 - \\theta})} - \\beta_0}{\\beta_2} +  \\frac{-\\beta_1}{\\beta_2}X_1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_classes(nptses, mus, sds):\n",
    "    \"\"\"\n",
    "    Generate normally distributed points in multiple classes\n",
    "    Parameters\n",
    "    ----------\n",
    "    nptses : array_like (1-d)\n",
    "        sequence of numbers, the count of points in each class\n",
    "    mus : array_like (2-d)\n",
    "        sequence of vectors, the means of the multivariate distributions for each class\n",
    "    mus : array_like (3-d)\n",
    "        sequence of 2-d symmetric tensors, the standard deviation of the multivariate\n",
    "        distributions for each class\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X : array (2-d)\n",
    "        features of generated points\n",
    "    y : array (2-d)\n",
    "        integer labels of points, starting at 0\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.zeros((0,2))\n",
    "    y = np.zeros((0,))\n",
    "    \n",
    "    for i, npts, mu, sd in zip(itertools.count(), nptses, mus, sds):\n",
    "        X = np.concatenate([X, scs.multivariate_normal(mu, sd).rvs(npts)])\n",
    "        y = np.concatenate([y, np.ones(npts)*i])\n",
    "    return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_classes((1000,1000),\n",
    "                       ((2.0, 2.5),\n",
    "                        (6.0, 0.0)),\n",
    "                       (((2.0, 0),\n",
    "                         (0, 3.0)),\n",
    "                        ((2.5, 0),\n",
    "                         (0, 3.0)))\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decision_boundary_x2(x, b0, b1, b2, threshold):\n",
    "    return (np.log((1 - threshold)/threshold) - b0 - x*b1 )/b2\n",
    "\n",
    "def plot_decision_boundary(X, y, model, ax=None):\n",
    "    '''plot 2-d array of points, with decision boundaries'''\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.scatter(X[:,0], X[:,1], color=np.where(y, 'g', 'b'), alpha=0.5, s=3)\n",
    "    ax.plot(*X[y==0].mean(axis=0).reshape(-1,1), color='b', marker='+', mew=4, ms=20)\n",
    "    ax.plot(*X[y==1].mean(axis=0).reshape(-1,1), color='g', marker='+', mew=4, ms=20)\n",
    "    ax.axis('equal')\n",
    "\n",
    "    xmin, xmax = X[:,0].min(), X[:,0].max()\n",
    "    xrng = np.array([2*xmin-xmax, 2*xmax-xmin])\n",
    "\n",
    "    ylim = ax.get_ylim()\n",
    "    xlim = ax.get_xlim()\n",
    "\n",
    "    beta0 = model.intercept_\n",
    "    beta1, beta2 = model.coef_[0]\n",
    "    print (beta0, beta1, beta2)\n",
    "    \n",
    "    for threshold, ls in zip(1/(1+np.exp(-np.arange(-3,4))), [':', '-.', '--', '-', '--', '-.', ':']):\n",
    "        ax.plot(xrng,\n",
    "                decision_boundary_x2(xrng, beta0, beta1, beta2, threshold),\n",
    "                color='r',\n",
    "                ls=ls,\n",
    "                label=\"{:.2f}%\".format(threshold*100))\n",
    "    ax.legend(title='threshold')\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_classes((1000,1000),\n",
    "                       ((2.0, 2.5),\n",
    "                        (6.0, 0.0)),\n",
    "                       (((2.0, 0),\n",
    "                         (0, 3.0)),\n",
    "                        ((2.5, 0),\n",
    "                         (0, 3.0)))\n",
    "                       )\n",
    "model = LogisticRegression(C=1000, intercept_scaling=100)\n",
    "model.fit(X, y)\n",
    "\n",
    "plot_decision_boundary(X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (end of morning lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afternoon Lecture – Evaluating a Binary Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "A [Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix) gives the count of instances based on the actual and predicted values of the target. For a binary classifier it looks like\n",
    "\n",
    "|                    |Predicted positive|Predicted negative |\n",
    "|--------------------|------------------|---------------|\n",
    "| **Actual positive**| true positive    | false negative|\n",
    "| **Actual negative**| false positive   | true negative |\n",
    "\n",
    "\n",
    "*True* and *false* refer to whether you are correct.\n",
    "\n",
    "*Positive* and *negative* refer to the **predicted** result.\n",
    "\n",
    "A *type-I error* is a false positive (which I remember because that phrase is more common than false negative).\n",
    "\n",
    "Accuracy $= \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "Sensitivity = Recall = TPR $= \\frac{TP}{TP+FN}$\n",
    "\n",
    "FPR $= \\frac{FP}{TN+FP}$\n",
    "\n",
    "Specificity $= \\frac{TN}{TN+FP}$\n",
    "\n",
    "Precision = PPV $= \\frac{TP}{TP+FP}$\n",
    "\n",
    "NPV $= \\frac{TN}{TN+FN}$\n",
    "\n",
    "![confusion matrix](Confusion_Matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-score\n",
    "\n",
    "$F_\\beta$ evaluates a test assuming that recall is $\\beta$ times as important as precision; it's a weighted harmonic mean of the two.\n",
    "\n",
    "$$F_\\beta = (1+\\beta^2) \\frac{\\text{precision} \\cdot \\text{recall}}{\\beta^2\\text{precision} + \\text{recall} } $$\n",
    "\n",
    "$$F_1 = 2 \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall} }  = \\frac{1}{\\frac{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}}{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves\n",
    "\n",
    "Any decent classification model will provide the probabilities that a data point is in one class or another. To visualize the overally goodness of a model we use a Receiver Operator Characteristic curve, which shows the TPR (a.k.a Sensitivity) and FPR (a.k.a. 1-Specificity) for various thresholds.\n",
    "\n",
    "Any alternative is the Precision-recall curve, which is more appropriate when you're more interested in the positive class.\n",
    "\n",
    "Models can be compared by the Area Under the Curve (AUC) of either graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_values(prob, y):\n",
    "    '''\n",
    "    Build dataframe of the various confusion-matrix ratios by threshold\n",
    "    from a list of predicted probabilities and actual y values\n",
    "    '''\n",
    "    df = pd.DataFrame({'prob': prob, 'y': y})\n",
    "    df.sort_values('prob', inplace=True)\n",
    "    \n",
    "    actual_p = df.y.sum()\n",
    "    actual_n = df.shape[0] - df.y.sum()\n",
    "\n",
    "    df['tn'] = (df.y == 0).cumsum()\n",
    "    df['fn'] = df.y.cumsum()\n",
    "    df['fp'] = actual_n - df.tn\n",
    "    df['tp'] = actual_p - df.fn\n",
    "\n",
    "    df['fpr'] = df.fp/(df.fp + df.tn)\n",
    "    df['tpr'] = df.tp/(df.tp + df.fn)\n",
    "    df['precision'] = df.tp/(df.tp + df.fp)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "    \n",
    "def plot_roc(ax, df):\n",
    "    ax.plot([1]+list(df.fpr), [1]+list(df.tpr), label=\"ROC\")\n",
    "    ax.plot([0,1],[0,1], 'k', label=\"random\")\n",
    "    ax.set_xlabel('fpr')\n",
    "    ax.set_ylabel('tpr')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_precision_recall(ax, df):\n",
    "    ax.plot(df.tpr,df.precision, label='precision/recall')\n",
    "    #ax.plot([0,1],[0,1], 'k')\n",
    "    ax.set_xlabel('recall')\n",
    "    ax.set_ylabel('precision')\n",
    "    ax.set_title('Precision/Recall Curve')\n",
    "    ax.plot([0,1],[df.precision[0],df.precision[0]], 'k', label='random')\n",
    "    ax.set_xlim(xmin=0,xmax=1)\n",
    "    ax.set_ylim(ymin=0,ymax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_classes((1000,1000),\n",
    "                       ((2.0, 2.5),\n",
    "                        (6.0, 0.0)),\n",
    "                       (((2.0, 0),\n",
    "                         (0, 3.0)),\n",
    "                        ((2.5, 0),\n",
    "                         (0, 3.0)))\n",
    "                       )\n",
    "model = LogisticRegression(C=1000)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax3) = plt.subplots(1,3, figsize=(18,6))\n",
    "df = calculate_threshold_values(model.predict_proba(X)[:,1], y)\n",
    "plot_roc(ax0, df)\n",
    "plot_precision_recall(ax1, df)\n",
    "plot_decision_boundary(X, y, model, ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The \"random\" black line is a model that guesses the class randomly, parameterized by the probability of guessing one class or another.\n",
    "\n",
    "There's a probabilistic interpretation of the AUC; Matt discusses it in http://madrury.github.io/jekyll/update/statistics/2017/06/21/auc-proof.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
