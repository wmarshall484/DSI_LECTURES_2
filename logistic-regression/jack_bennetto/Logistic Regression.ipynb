{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "### Jack Bennetto\n",
    "#### January 26, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standards/Objectives\n",
    "\n",
    " * Place logistic regression in the taxonomy of ML algorithms\n",
    " * Explain the key differences and similarities between logistic and linear regression.\n",
    " * Fit and interpret a logistic regression model in scikit-learn\n",
    " * Interpret the coefficients of logistic regression, using odds ratio\n",
    " * Explain ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression as a model\n",
    "\n",
    "Logistic regression is a supervised-learning parametric classification model. It's generally the first thing you try when building a classifier, and is actually used in some production environments.\n",
    "\n",
    "Advantages:\n",
    "\n",
    " * Fast\n",
    " * Simple (few hyperparameters)\n",
    " * Interpretable\n",
    " * Provides probability\n",
    " \n",
    "Disadvantages\n",
    "\n",
    " * Requires feature engineering to capture non-linear relationships\n",
    " * Doesn't work for p > n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to linear regression\n",
    "\n",
    "Recall that with linear regression we assume the data follows the form\n",
    "\n",
    "$$\\begin{align}\n",
    "Y & = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... \\beta_p X_p + \\epsilon \\\\\n",
    "  & = X \\beta + \\epsilon\n",
    "\\end{align}$$\n",
    "\n",
    "where again\n",
    "\n",
    "$$\\epsilon \\sim N(0, \\sigma)$$\n",
    "\n",
    "Alternatively, we could say\n",
    "$$Y \\sim N(X \\beta, \\sigma)$$\n",
    "\n",
    "From there, we want to find the values for $\\beta$ that are the most likely to produce the data. The MLE estimate gives us ordinary least squares.\n",
    "\n",
    "With logistic regression we assume $Y$ follows a Bernoulli distribution, where $p$ is given by\n",
    "\n",
    "$$p = f(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... \\beta_p X_p)$$\n",
    "\n",
    "so\n",
    "\n",
    "$$Y \\sim Bernoulli(f(X \\beta))$$\n",
    "\n",
    "We want a function with values from 0 to 1. A good candidate is the logistic function\n",
    "\n",
    "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Qe could have used other similar functions like the inverse tangent or the probit function, but this has better properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "xpts = np.linspace(-10, 10, 100)\n",
    "ax.plot(xpts, 1/(1+np.exp(-xpts)), label='logistic', lw=2)\n",
    "ax.plot(xpts, np.arctan(xpts)/np.pi + 0.5, label='arctan (rescaled)')\n",
    "ax.plot(xpts, (1+scipy.special.erf(xpts/np.sqrt(2)))/2, label='inverse probit')\n",
    "ax.legend(loc='best')\n",
    "ax.set_title(\"Assorted monotonic functions going from 0 to 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we solve with maximum-likelihood estimation. Note that there isn't a close-form solution here; the compute has to solve numerically using some form of gradiant descent (tomorrow's lecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (with fake data)\n",
    "\n",
    "We'll generate fake data that matches the distribution exactly and try to recover the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npts = 100\n",
    "beta0 = 0.0\n",
    "beta1 = 0.5\n",
    "\n",
    "X = scs.uniform(-9, 18).rvs(npts).reshape(npts,1)\n",
    "# the expit function is the same as the logistic function\n",
    "y = scs.bernoulli(scipy.special.expit(beta0 + beta1*X[:,0])).rvs(npts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We graph the data; the vertical line shows the decision boundary where the probability is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jitter = scs.uniform(-0.03,0.06).rvs(npts)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], y + jitter, s=10, alpha=0.5)\n",
    "ax.axvline(-beta0/beta1, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set C large to suppress regularization\n",
    "model = LogisticRegression(C=1000)\n",
    "model.fit(X, y)\n",
    "beta0hat = model.intercept_[0]\n",
    "beta1hat = model.coef_[0][0]\n",
    "print \"beta0 =    {0:8.3f} beta1 =    {1:8.3f}\".format(beta0, beta1)\n",
    "print \"beta0hat = {0:8.3f} beta1hat = {1:8.3f}\".format(beta0hat, beta1hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw the curve we fitted on the data, along with the actual decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xpts = np.linspace(-9, 9, 100)\n",
    "ypts = 1/(1 + np.exp(-(beta0hat + beta1hat * xpts)))\n",
    "\n",
    "jitter = scs.uniform(-0.03,0.06).rvs(npts)\n",
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "ax.scatter(X[:,0], y + jitter, s=10, alpha=0.5, label=\"generated data\")\n",
    "ax.plot(xpts, ypts, 'r', label='fitted curve')\n",
    "ax.axhline(0.5, color='black')\n",
    "ax.axvline(-beta0/beta1, color='black', label='actual boundary')\n",
    "ax.set_title(\"Fitted logistic curve\")\n",
    "ax.legend(loc='center right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-odds ratio\n",
    "\n",
    "The odds ratio is the ratio of the positive to the negative case, i.e., \n",
    "\n",
    "$$OR = \\frac{P(y=1)}{1-P(y=1)}$$\n",
    "\n",
    "E.g., something with a 75% chance of happening has 3:1 odds. If these are given by the logistic expression above,\n",
    "\n",
    "$$\\begin{align}\n",
    "OR &= \\frac{P(y=1)}{1-P(y=1)} \\\\\n",
    "   &= \\frac{\\frac{1}{1+e^{-X\\beta}}}{1-\\frac{1}{1+e^{-X\\beta}}} \\\\\n",
    "   &= \\frac{1}{e^{-X\\beta}} \\\\\n",
    "   &= e^{X\\beta}\n",
    "\\end{align}\n",
    "$$\n",
    "so\n",
    "$$log(OR) = X\\beta$$\n",
    "\n",
    "So if you increase $x_i$ by 1, you increase $log(OR)$ by $\\beta_i$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundary\n",
    "\n",
    "The **decision boundary** is the surface in feature space at which the probability is 0.5, so\n",
    "\n",
    "$$\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 = 0$$\n",
    "\n",
    "so\n",
    "\n",
    "$$ X_2 = \\frac{-\\beta_0}{\\beta_2} + \\frac{-\\beta_1}{\\beta_2}X_1 $$\n",
    "\n",
    "but you could use a different ratio. More broadly, for decision boundary $\\theta$,\n",
    "\n",
    "$$\\theta = \\frac{1}{1-e^{-x}}$$\n",
    "\n",
    "$$\\theta - \\theta e^{-x} = 1$$\n",
    "\n",
    "$$1 - \\theta = \\theta e^{-x}$$\n",
    "$$x = -\\ln{(\\frac{1}{\\theta} - 1)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_2d_dist(npts, mu, sd):\n",
    "    '''generate 2-d distribution of points from 2-tuples mu and sd,\n",
    "    returning npts-by-2 numpy array'''\n",
    "    X = np.zeros((npts, 2))\n",
    "    for i in [0,1]:\n",
    "        X[:,i] = scs.norm(mu[i], sd[i]).rvs(npts)\n",
    "    return X\n",
    "    \n",
    "def generate_classes(nptses, mus, sds):\n",
    "\n",
    "    X = np.zeros((0,2))\n",
    "    y = np.zeros((0,))\n",
    "    \n",
    "    for i,npts, mu, sd in zip(itertools.count(), nptses, mus, sds):\n",
    "        X = np.concatenate([X, generate_2d_dist(npts, mu, sd)])\n",
    "        y = np.concatenate([y, np.ones(npts)*i])\n",
    "    return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decision_boundary_x2(x, b0, b1, b2, threshold):\n",
    "    return (-x*b1 - b0 -np.log(1/threshold - 1))/b2\n",
    "\n",
    "def plot_decision_boundary(X, y, model):\n",
    "    '''plot 2-d array of points, with decision boundaries'''\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.scatter(X[:,0], X[:,1], color=np.where(y, 'g', 'b'), alpha=0.5, s=2)\n",
    "    ax.axis('equal')\n",
    "\n",
    "    xmin, xmax = X[:,0].min(), X[:,0].max()\n",
    "    xrng = np.array([2*xmin-xmax, 2*xmax-xmin])\n",
    "\n",
    "    ylim = ax.get_ylim()\n",
    "    xlim = ax.get_xlim()\n",
    "\n",
    "    beta0 = model.intercept_\n",
    "    beta1, beta2 = model.coef_[0]\n",
    "    \n",
    "    for threshold, ls in zip([.1, .25, .5, .75, .9], [':', '--', '-', '--', ':']):\n",
    "        ax.plot(xrng,\n",
    "                decision_boundary_x2(xrng, beta0, beta1, beta2, threshold),\n",
    "                color='r',\n",
    "                ls=ls,\n",
    "                label=\"threshold={}\".format(threshold))\n",
    "    ax.legend()\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = generate_classes((1000,1000),\n",
    "                       ((2.0,2.5),(6.0,0.0)),\n",
    "                       ((2.0,3.0),(2.5,3.0)))\n",
    "\n",
    "model = LogisticRegression(C=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "plot_decision_boundary(X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a binary classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "A [Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix) gives the count of instances based on the actual and predicted values of the target. For a binary classifier it looks like\n",
    "\n",
    "|                    |Predicted positive|Predicted negative |\n",
    "|--------------------|------------------|---------------|\n",
    "| **Actual positive**| true positive    | false negative|\n",
    "| **Actual negative**| false positive   | true negative |\n",
    "\n",
    "\n",
    "*True* and *false* refer to whether you are correct.\n",
    "\n",
    "*Positive* and *negative* refer to the **predicted** result.\n",
    "\n",
    "A *type-I error* is a false positive (which I remember because that phrase is more common than false negative).\n",
    "\n",
    "Accuracy $= \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "Sensitivity = Recall = TPR $= \\frac{TP}{TP+FN}$\n",
    "\n",
    "FPR $= \\frac{FP}{TN+FP}$\n",
    "\n",
    "Specificity $= \\frac{TN}{TN+FP}$\n",
    "\n",
    "Precision = PPV $= \\frac{TP}{TP+FP}$\n",
    "\n",
    "NPV $= \\frac{TN}{TN+FN}$\n",
    "\n",
    "![confusion matrix](Confusion_Matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-score\n",
    "\n",
    "$F_\\beta$ evaluates a test assuming that recall is $\\beta$ times as important as precision; it's a weighted harmonic mean of the two.\n",
    "\n",
    "$$F_\\beta = (1+\\beta^2) \\frac{\\text{precision} \\cdot \\text{recall}}{\\beta^2\\text{precision} + \\text{recall} } $$\n",
    "\n",
    "\n",
    "$$F_1 = 2 \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall} }  = \\frac{1}{\\frac{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}}{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves\n",
    "\n",
    "Any decent classification model will provide the probabilities that a data point is in one class or another. To visualize the overally goodness of a model we use a Receiver Operator Characteristic curve, which shows the TPR (a.k.a Sensitivity) and FPR (a.k.a. 1-Specificity) for various thresholds.\n",
    "\n",
    "Any alternative is the Precision-recall curve, which is more appropriate when you're more interested in the positive class.\n",
    "\n",
    "Models can be compared by the Area Under the Curve (AUC) of either graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_threshold_values(prob, y):\n",
    "    '''\n",
    "    Build dataframe of the various confusion-matrix ratios by threshold\n",
    "    from a list of predicted probabilities and actual y values\n",
    "    '''\n",
    "    df = pd.DataFrame({'prob': prob, 'y': y})\n",
    "    df.sort_values('prob', inplace=True)\n",
    "    \n",
    "    actual_p = df.y.sum()\n",
    "    actual_n = df.shape[0] - df.y.sum()\n",
    "\n",
    "    df['tn'] = (df.y == 0).cumsum()\n",
    "    df['fn'] = df.y.cumsum()\n",
    "    df['fp'] = actual_n - df.tn\n",
    "    df['tp'] = actual_p - df.fn\n",
    "\n",
    "    df['fpr'] = df.fp/(df.fp + df.tn)\n",
    "    df['tpr'] = df.tp/(df.tp + df.fn)\n",
    "    df['precision'] = df.tp/(df.tp + df.fp)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "    \n",
    "def plot_roc(ax, df):\n",
    "    \n",
    "    ax.plot([1]+list(df.fpr), [1]+list(df.tpr))\n",
    "    ax.plot([0,1],[0,1], 'k')\n",
    "    ax.set_xlabel(\"fpr\")\n",
    "    ax.set_ylabel(\"tpr\")\n",
    "    ax.set_title('ROC')\n",
    "    \n",
    "def plot_precision_recall(ax, df):\n",
    "    ax.plot(df.tpr,df.precision)\n",
    "    #ax.plot([0,1],[0,1], 'k')\n",
    "    ax.set_xlabel(\"recall\")\n",
    "    ax.set_ylabel(\"precision\")\n",
    "    ax.set_title('Precision/Recall')\n",
    "    ax.plot([0,1],[df.precision[0],df.precision[0]], 'k')\n",
    "    ax.set_xlim(xmin=0,xmax=1)\n",
    "    ax.set_ylim(ymin=0,ymax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = generate_classes((10000,10000),\n",
    "                       ((2.0,2.5),(6.0,0.0)),\n",
    "                       ((2.0,3.0),(2.5,3.0)))\n",
    "\n",
    "model = LogisticRegression(C=1000)\n",
    "model.fit(X, y)\n",
    "#plot_decision_boundary(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1,2, figsize=(12,6))\n",
    "df = calculate_threshold_values(model.predict_proba(X)[:,1], y)\n",
    "plot_roc(ax0, df)\n",
    "plot_precision_recall(ax1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
