<h1>Spark Demos </h1>

<h2>TLDR;</h2>
Spark is a distributed computing platform that has a python API.  For people accustomed to python programing, there are analogous functions such as map, filter, and sort.  The quickest way to get started is to grab a Spark 2.0 docker image attached to a Jupyter notebook, which you can find here: https://hub.docker.com/r/ezamir/jupyter-spark-2.0/

<h2>Background</h2>
Spark is an open sourced platform for distributed computation.  Originally written in scala, it has API's for scala, java, R, and of course, python.  You can read more on the Spark website http://spark.apache.org/

<h2>Getting Started</h2>
The first step is to get spark working on your machine locally.  It should go without saying that Sparks primary purpose is not to be run on a single machine.  With that said, one can explore many features by small scale experimentation.  There are two options for running locally.
<h3>Spark/Jupyter Docker image</h3>
There is a docker image that has all the instructions for getting up and running really quickly.  https://hub.docker.com/r/ezamir/jupyter-spark-2.0/ .  This is the quickest way to get started, but does require you to be comfortable with docker (if not, no time like the present to learn!)

