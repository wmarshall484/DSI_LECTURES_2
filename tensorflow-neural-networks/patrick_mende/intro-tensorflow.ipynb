{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Neural Networks\n",
    "\n",
    "## Introductory Tensorflow\n",
    "\n",
    "### Patrick Mende\n",
    "#### (Modified notebook from Jack Bennetto)\n",
    "\n",
    "#### August 16, 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Use TensorFlow to do calculations.\n",
    "* Explain the advantages and disadvantages of neural networks.\n",
    "* Explain the basic neural-network algorithms.\n",
    "* Build a simple neural network in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "try:\n",
    "    range = xrange\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "\n",
    "TensorFlow is a Google technology primarily designed to build neural networks. It's not just for neural networks – it can be used for other things as well – but that's the focus. This morning we'll learn about the basics of TensorFlow itself, and this afternoon we'll see how it's used for neural networks. Tomorrow we'll use it to build convolutional neural networks to process images.\n",
    "\n",
    "The main object in TensorFlow is a **tensor**, which in this context is mostly just an array that may have any number of dimensions.\n",
    "\n",
    "The first point to make is that computation in TensorFlow doesn't happen right away. First we build a **graph** that descibes the computation, and then we execute it. Let's start by building a simple graph to solve some simple linear algebra.\n",
    "\n",
    "\\\\[\n",
    "\\begin{bmatrix}\n",
    "3 & 3\n",
    "\\end{bmatrix} \\cdot\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "4 \\\\\n",
    "5\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "2 \\\\\n",
    "2\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "\\\\]\n",
    "\n",
    "What's this equal to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix1 = tf.constant([[3., 3]])\n",
    "matrix2 = tf.constant([[4.], [5]])\n",
    "matrix3 = tf.constant([[2.], [2]])\n",
    "\n",
    "total = tf.add(matrix2, matrix3)\n",
    "product = tf.matmul(matrix1, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **constant** is what it sounds like: an object that doesn't change. Let's look a bit at what we have. First we'll look at the types and print out the objects themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(matrix1))\n",
    "print(type(product))\n",
    "print(matrix1)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What's float32? Is that the same default as a float in numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(1.).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so they are all tensors. (Note that at this point no computation has been done and we don't have a result yet) As in numpy we can look at the shape of a tensor; getting these wrong is a frequent source of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix1.get_shape())\n",
    "print(matrix2.get_shape())\n",
    "print(matrix3.get_shape())\n",
    "print(total.get_shape())\n",
    "print(product.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this checks out. Note they are actually returning special objects, not just tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(matrix1.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually do anything with that we need to create a **session**. A session is a bit like a context in Spark; all TensorFlow computation happens within it. Running a tensor within a session evaluates in as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't want to worry about the session object all the time, we can create an **interactive session**. That installs it as the default session so we can evaluate an object directly. We'll use an interactive session from now on, but you might not always use one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some nodes don't have an `eval` method. For those (if we're using an interactive session and don't want to use the session object) we use the `run` method instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Multiply\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "in tensorflow, without cutting-and-pasting, ideally without looking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = tf.constant([[1],[1]])\n",
    "v2 = tf.constant([[1,1]])\n",
    "product = tf.matmul(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a matrix filled with zeros (or ones) with `tf.zeros` (or `tf.ones`) that work the same as in numpy. Or you can create them with `tf.constant` from numpy arrays.\n",
    "\n",
    "**Experiment:** Use `tf.zeros` to figure out tensorflow broadcasting rules. Are they the same as numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeds and placeholders\n",
    "\n",
    "**Placeholders** are tensors that don't have a specified value, but one that is filled in later with a **feed**. For example, suppose you want to build a graph that will multiply two numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the output we need to provide a feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.eval(feed_dict={input1:536, input2:7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this is the same as doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(output, feed_dict={input1:6, input2:7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this could take an array as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.eval(feed_dict={input1:[6], input2:[4,5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's because we didn't specify any input dimensions. It's good to specify the input shape if we know it (in the interests of our own mental health) but we frequently leave one dimension as `None` when we're doing batch jobs so we can vary the size of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input1 = tf.placeholder(tf.float32, shape=(3,))\n",
    "input2 = tf.placeholder(tf.float32, shape=(None,))\n",
    "output = tf.multiply(input1, input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.eval(feed_dict={input1:[1,2], input2:[5,5,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.eval(feed_dict={input1:[2,3], input2:[5,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.eval(feed_dict={input1:[2,3,3], input2:[5,5,5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See why it's good to specify dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Much of tensorflow followed a functional-programming model, but variables go around that.\n",
    "\n",
    "Variables are tensors that might change values instead of just having a single value once evaluated. These are used (for example) to represent the strength of a connection in a network. They have an initial value; you have to run a special function (`global_variables_initializer()`) to initialize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Solving an Optimization Problem\n",
    "\n",
    "Let's solve a simple optimization problem. We want to find the minimum of a function, but it's been a few years since we've had calculus and forgot how to take a derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpts = np.linspace(0, 12, 500)\n",
    "ypts = np.cos(xpts)\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "ax.plot(xpts, ypts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0, dtype=tf.float64)\n",
    "y = tf.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this we create an optimizer object (there are a bunch of different types) and use that to create a minimize operation that, when run, will (incrementally) minimize its loss. Running the operation does two things, first computes the gradients of the loss with respect to the variables in the graph, and then applies the gradients to the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1.0)\n",
    "train = optimizer.minimize(y)\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(1000):\n",
    "    if i%50 == 0:\n",
    "        print(\"x = {0:.16f}  y = {1:.12f}\".format(x.eval(), y.eval()))\n",
    "    train.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
