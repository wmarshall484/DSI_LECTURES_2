{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "### Jack Bennetto\n",
    "#### February 21, 2019\n",
    "\n",
    "(based on John Bourassa's lecture, based on my lecture in zipfian, based on the lecture from Jonathan Torrez)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Describe pros/cons of decision tree algorithm\n",
    "* Implement pseudocode for decision tree algorithm\n",
    "* Demonstrate concept of recursion and relate it to decision trees\n",
    "* Describe the impurity measures used and relate them to loss functions\n",
    "* State pruning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    " * Introduction\n",
    " * Predicting with a decision tree\n",
    " * Building a decision tree\n",
    " * Recursion\n",
    " * Loss functions\n",
    " * Entropy and purity\n",
    " * Decision-tree algorithm\n",
    " * Pre- and post-pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric vs. Non-Parametric Models\n",
    "\n",
    "\n",
    "### Parametric Models\n",
    "\n",
    "#### Linear Regression\n",
    "\n",
    "\n",
    "$$\\hat y = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_2 + ... + \\hat\\beta_i X_i $$\n",
    "    \n",
    "How many parameters can we describe it with?\n",
    "\n",
    "Can we ever change the number of parameters?\n",
    "\n",
    "What does using this model mean about the structure of our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric and Non-Parametric Models\n",
    "\n",
    "Class discussion: contrast the pros and cons of these two types of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets, tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "# Make it pretty\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Seed random functions for reproducibility\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "\n",
    "# Reduce the data down to 2 classes and 2 predictor variables\n",
    "X = X[y != 0, :2] \n",
    "\n",
    "# Add some noise so data points aren't exactly duplicated\n",
    "X = X + np.random.normal(0, .05, size = X.shape)\n",
    "\n",
    "# Change Sepal Length from cm to mm to cause scaling issues\n",
    "X[:,0] = X[:,0] * 10\n",
    "y = y[y != 0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save some points for later\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flower_data(ax, X, y):\n",
    "    ax.scatter(X[y == 0,0], X[y == 0,1], c = \"orange\", label = \"versicolor\")\n",
    "    ax.scatter(X[y == 1, 0], X[y == 1, 1], color = \"black\", label = \"virginica\")\n",
    "    ax.set_xlabel(\"Sepal Length (mm)\")\n",
    "    ax.set_ylabel(\"Sepal Width (cm)\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples from a multivariate normal distribution\n",
    "# which approximates the input data\n",
    "def gen_similar_samples(X, y, n_samples = 4, sample_size = 50):\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for _ in range(n_samples):\n",
    "        Xdata = np.zeros_like(X)\n",
    "        ydata = np.zeros_like(y)\n",
    "        for i, value in enumerate(np.unique(y)):\n",
    "            Xdata[i*sample_size:(i+1)*sample_size] = np.random.multivariate_normal(X[y == value].mean(axis = 0), \n",
    "                                                                                   np.cov(X[y == value].T), \n",
    "                                                                                   sample_size)\n",
    "            ydata[i*sample_size:(i+1)*sample_size] = value\n",
    "        Xs.append(Xdata)\n",
    "        ys.append(ydata)\n",
    "    \n",
    "    return list(zip(Xs, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our data\n",
    "tennis_df = pd.read_table('data/tennis.txt', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up a few things, based on my preferences and making calculating probabilities easier\n",
    "tennis_df.rename(columns={'playtennis': 'played'}, inplace=True)\n",
    "tennis_df['played'] = tennis_df['played'].apply(lambda x: 1 if x == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data\n",
    "tennis_df.sort_values('played')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Would You Determine If You Played Tennis?\n",
    "\n",
    "Class discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably need to do `pip install graphviz` to generate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='A simple classification tree')\n",
    "\n",
    "dot.node('O', 'outlook?', shape='diamond')\n",
    "dot.node('1', \"yes\", shape='rectangle')\n",
    "dot.node('H', 'humidity?', shape='diamond')\n",
    "dot.node('O2', 'outlook?', shape='diamond')\n",
    "dot.node('W', 'wind?', shape='diamond')\n",
    "dot.node('3', 'yes', shape='rectangle')\n",
    "dot.node('T', 'temperature?', shape='diamond')\n",
    "dot.node('4', 'yes', shape='rectangle')\n",
    "dot.node('5', \"no\", shape='rectangle')\n",
    "dot.node('2', \"no\", shape='rectangle')\n",
    "dot.node('W2', 'wind?', shape='diamond')\n",
    "dot.node('6', \"no\", shape='rectangle')\n",
    "dot.node('7', 'yes', shape='rectangle')\n",
    "\n",
    "dot.edge('O', '1', 'overcast')\n",
    "dot.edge('O', 'H', 'not overcast')\n",
    "dot.edge('H', 'O2', 'high')\n",
    "dot.edge('H', 'W', 'normal')\n",
    "dot.edge('W', '3', 'False')\n",
    "dot.edge('W', 'T', 'True')\n",
    "dot.edge('T', '4', 'mild')\n",
    "dot.edge('T', '5', 'cool')\n",
    "dot.edge('O2', '2', 'sunny')\n",
    "dot.edge('O2', 'W2', 'rainy')\n",
    "dot.edge('W2', '7', 'False')\n",
    "dot.edge('W2', '6', 'True')\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Decision trees are pretty clear if when the features are all binary. What if the features have multiple values?\n",
    "\n",
    "**Question:** What if the features have continuous values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: A **decision tree** is a machine-learning model that chooses a label based a series of questions, each about the value of one of the features, with each question based on the result of the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting from a decision tree\n",
    "\n",
    "A decision tree is a binary tree, with each **branch** (non-leaf) node having a **left and right child node**. Each branch node specifies a feature to split along with information on which values should pass to the left node, and which should pass to the right.\n",
    "\n",
    "In general that's specified with a single split value for each node.\n",
    "\n",
    "**For numeric features,** if that feature for a data point is less than the split value the data point is handled by the left node; if not, it's handled by the node on the right. **For categorical features,** if the feature is equal to the split value it is handled on the left, otherwise the right.\n",
    "\n",
    "Decision trees can be used for either classification or regression. For classification, the leaf nodes will predict probability the data point is in one class or the other. For regression, the leaf nodes predict a specific value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a regression tree\n",
    "### Example: insect wing sizes\n",
    "\n",
    "Load the dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insects = pd.read_csv('data/insects.csv')\n",
    "insects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** You want predict insect wingsize from the other features. Suppose you want to build a tree with a single branch, based on one of the three features. Which feature should you choose? What should you predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Suppose instead you were building a classifier, predicting the sex from the other features. How would the answer differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you were building a deeper tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside on recursion\n",
    "\n",
    "Recursion uses the idea of \"divide and conquer\" to solve problems. It divides a complex problem you are working on into smaller sub-problems that are easily solved, rather than trying to solve the complex problem directly.\n",
    "\n",
    "Recursive functions split the problem into two cases: the ***base case*** and the ***recursive case***. The function continually calls *itself* until it reaches the base case.\n",
    "\n",
    "* Base case: Stopping criteria, the simplest case that can be solved directly.\n",
    "* Recursive case: Function that splits the problem into the smaller subproblems.\n",
    "    \n",
    "### Three Laws of Recursion\n",
    "\n",
    "1. A recursive algorithm must have a base case.\n",
    "2. A recursive algorithm must call itself, recursively.\n",
    "2. A recursive algorithm must call itself with different arguments so as to move it toward the base case.\n",
    "\n",
    "### Example: Factorial\n",
    "\n",
    "Are the following functions the same?\n",
    "\n",
    "$$ f(x) = \\prod_{i=1}^xi $$\n",
    "\n",
    "$$f(x) =\n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t1  & \\mbox{if } x \\leq 1 \\\\\n",
    "\t\txf(x-1) & \\mbox otherwise\n",
    "\t\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code this together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(x):\n",
    "    \"\"\"Recursively calculate x!\"\"\"\n",
    "    # base case is when we get to x=0, which is 0! = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base, exp):\n",
    "    \"\"\"Recrsively caclulate base ** exp\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_str(s):\n",
    "    \"\"\"Recursively determine the length of a string\"\"\"\n",
    "    # base case, when should you stop?  \n",
    "    # recursive case, how can you reduce your problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** suppose you had a decision tree that was composed of `TreeNode` objects, each of which had a `left` and `right` child. How would you use recursion to predict the value of a data point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a decision tree\n",
    "\n",
    "To fit a decision tree, we want to find the split that will minimize our loss function. To do this we consider every possible feature in our training data, and for each feature consider every possible value, and of all those choose the one for which the loss function is smallest.\n",
    "\n",
    "So now we have a little tree with a single split. Let's suppose we stop there.\n",
    "\n",
    "**Question:** What should we predict if we're building a regression tree? A classification tree?\n",
    "\n",
    "A one-level tree is a pretty bad model.\n",
    "\n",
    "Once we've chosen our top-level split, we separate our data into two parts (for the left and right part). For each of those we again find the split that minimizes the loss function.\n",
    "\n",
    "For each of these we'd split the data into two parts, and for each part we'd find the best split, and we'd keep doing that, recursively, until...\n",
    "\n",
    "**Question:** when should we stop?\n",
    "\n",
    "We'll discuss this more later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "\n",
    "For a regression tree we generally used the mean squared residuals.\n",
    "\n",
    "$$\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "where $y_i$ is the actual value for data point $i$ and $\\hat{y}_i$ is the predicted probability.\n",
    "\n",
    "There are a couple choices for loss functions for binary classifiers. The most common is log loss, \n",
    "\n",
    "$$-\\frac{1}{N} \\sum_{i=0}^N y_i \\log{\\hat{p}_i} + (1 - y_i) \\log{(1 - \\hat{p}_i)}$$\n",
    "\n",
    "where $\\hat{p}_i$ is the predicted probability that $y_i$ is $1$.\n",
    "\n",
    "Another approach is Brier score loss,\n",
    "\n",
    "$$\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{p}_i)^2$$\n",
    "\n",
    "\n",
    "### Alternative formulation: minimizing impurity\n",
    "\n",
    "There's another way of seeing this that's more common, and in some ways clearer, but lacks the motivation of a loss function.\n",
    "\n",
    "We can also talk choosing the feature and value for the split that separates the data so the left and right sides are each as \"pure\" as possible. This is called \"minimizing the impurity\".\n",
    "\n",
    "In the case of regression, we measure the impurity of the data as the variance, and the total impurity after the split is the average if the data on the left side and the data on the right, **weighted by the number of points in each**.\n",
    "\n",
    "Minimizing this is exactly equivalent to minimizing the **mean squared residual**. The variance is the average sum of difference of the points and their mean, which is just our predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case if classification, we have two ways we can define impurity. One option is using the **Shannon entropy**, which is a measure of information the of random variable or set of options.\n",
    "\n",
    "Entropy is given by\n",
    "\n",
    "$$H(X) = -\\sum_i p_i \\log_2{p_i}$$\n",
    "\n",
    "where $p_i$ is the number of data in class $i$.\n",
    "\n",
    "\n",
    "This is **equivalent to minimizing log loss** (to within a constant factor, since Shannon entropy is generally defined with a base-2 logarithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option is called Gini impurity. \n",
    "The Gini impurity is equal to \n",
    "\n",
    "$$H(X) = 1 - \\sum_i p_i^2$$\n",
    "\n",
    "where, again, $p_i$ is the number of data in class $i$.\n",
    "\n",
    "The Gini impurity can be described in a number of ways, but one is that, assuming you predict classes randomly according to their fraction of the class, the probability that you are wrong.\n",
    "\n",
    "So suppose your values are 0, 0, and 1. For $2\\over 3$ of the values you have a $2\\over 3$ of being correct, and for $1\\over 3$ of the values you have a $1\\over 3$ of being correct, so your overall chance of being wrong is $1 - ({1 \\over 3})^2 - ({2 \\over 3})^2 = {4 \\over 9}$.\n",
    "\n",
    "\n",
    "This is **equivalent to minimizing the Brier score loss.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of problem | Loss function         | Impurity measure\n",
    "----------------|-----------------------|-----------------\n",
    "Regression      | Mean squared residual | Variance\n",
    "Classification  | Log loss              | Entropy\n",
    "Classification  | Brier score loss      | Gini impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlog2x(x):\n",
    "    '''return x * log2(x), returning 0 for x==0'''\n",
    "    return scipy.special.xlogy(x,x) / np.log(2)\n",
    "\n",
    "x = np.linspace(0, 1)\n",
    "entropy = - (xlog2x(x) + xlog2x(1-x))\n",
    "gini = 2 * (1 - x**2 - (1-x)**2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(x, entropy, label=\"Entropy\")\n",
    "ax.plot(x, gini, label=\"2 * Gini\")\n",
    "ax.set_ylabel(\"Entropy/Impurity\")\n",
    "ax.set_xlabel(\"Proportion of one class\")\n",
    "ax.set_title(\"Impurity of a Binary Decision-Tree Node\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(y):\n",
    "    \"\"\"Return the entropy of the array y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: 1d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    total_samples = y.shape[0]\n",
    "    summation = 0\n",
    "    \n",
    "    for class_i in np.unique(y):\n",
    "        prob = sum(y == class_i) / float(total_samples)\n",
    "        summation += prob * np.log2(prob)\n",
    "    \n",
    "    return -summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tennis = tennis_df['played'].values\n",
    "\n",
    "print(\"Entropy of original data set is {}\".format(calc_entropy(y_tennis)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a split\n",
    "\n",
    "In order to figure out the best split, we need to figuring out which minimizes the entropy, or minimizes the Gini impurity, for both sides of the split.\n",
    "\n",
    "This is **weighted by the number of data points on each side.**\n",
    "\n",
    "We generally look at the change in the total impurity from before the split to after. We sometimes talk about this (particularly when using entropy) as the **information gain**, the amount of information we get about the classes from a particular split.\n",
    "\n",
    "$$\\text{IG}(S, C) = H(S) - \\sum_{C_i \\in C} \\frac{|C_i|}{|S|} H(C_i)$$\n",
    "\n",
    "where \n",
    "\n",
    "$C$ = candidate partition of $S$,  and $|C_i|$, $|S|$ = Number of elements in $C_i$, $S$, and $H$ is the impurity/entropy of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(y, y1, y2, impurity_func):\n",
    "    \"\"\"Return the information gain of making the given split.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: 1d numpy array\n",
    "        Labels for parent node\n",
    "    \n",
    "    y1: 1d numpy array\n",
    "        Labels for potential child node 1\n",
    "    \n",
    "    y2: 1d numpy array\n",
    "        Labels for potential child node 2\n",
    "    \n",
    "    impurity_func: function\n",
    "        Function which calculates the impurity of the node \n",
    "        (e.g. Shannon Entropy)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    total_samples = float(y.shape[0])\n",
    "    child_imp = 0\n",
    "    y_impurity = impurity_func(y)\n",
    "    \n",
    "    for child_node in (y1, y2):\n",
    "        child_num = child_node.shape[0]\n",
    "        child_imp += (child_num / total_samples) * impurity_func(child_node)\n",
    "        \n",
    "    return y_impurity - child_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split on the temperature.\n",
    "\n",
    "y1 = tennis_df[tennis_df['temperature'] == 'hot']['played'].values\n",
    "y2 = tennis_df[tennis_df['temperature'] != 'hot']['played'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information Gain is {0}.\".format(calc_info_gain(y_tennis, y1, y2, calc_entropy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not much gain, maybe I really liked playing when the temperature was mild\n",
    "# Let's try that split\n",
    "\n",
    "y1 = tennis_df[tennis_df['temperature'] == 'mild']['played'].values\n",
    "y2 = tennis_df[tennis_df['temperature'] != 'mild']['played'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information Gain is {0}.\".format(calc_info_gain(y_tennis, y1, y2, calc_entropy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still not much headway, let's just try every possible split and see what works\n",
    "# And also confirm what we used our common sense algorithm we started with\n",
    "\n",
    "possible_splits = {}\n",
    "# Get just my features from the dataframe\n",
    "feature_cols = tennis_df.drop('played', axis=1).columns\n",
    "\n",
    "# For a given column, find all the unique possible values\n",
    "for col in feature_cols:\n",
    "    col_splits = np.unique(tennis_df[col])\n",
    "    # For each possible value, split the dataset using that value\n",
    "    for pos_val in col_splits:\n",
    "        y1 = tennis_df[tennis_df[col] == pos_val]['played'].values\n",
    "        y2 = tennis_df[tennis_df[col] != pos_val]['played'].values\n",
    "        # Calculate the information gain, save it for later\n",
    "        ig = calc_info_gain(y_tennis, y1, y2, calc_entropy)\n",
    "        key = \"{0}: {1}\".format(col, pos_val)\n",
    "        possible_splits[key] = ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out our results in a pretty way\n",
    "colname1 = \"Col Name: Value\"\n",
    "colname2 = \"Information Gain\"\n",
    "\n",
    "# :20 is specifying a column width, https://docs.python.org/3/library/string.html#formatspec\n",
    "print(\"{0:20} || {1}\".format(colname1, colname2))\n",
    "print(\"-\"*40)\n",
    "# operator.itemgetter(1) allows us to sort by the second item of the tuple\n",
    "for k,v in sorted(possible_splits.items(), key=operator.itemgetter(1), reverse=True):\n",
    "    print(\"{0:20} || {1}\".format(k, round(v, 4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting on overcast gave us the largest info gain\n",
    "# Let's look at what those child nodes look like and their respective entropies\n",
    "child_node_left = tennis_df[tennis_df['outlook'] == 'overcast']\n",
    "print(\"Entropy of left child node is {0}\".format(\n",
    "          calc_entropy(child_node_left['played'].values)))\n",
    "child_node_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, we got a pure node, that makes sense.\n",
    "# What about the other node?\n",
    "child_node_right = tennis_df[tennis_df['outlook'] != 'overcast']\n",
    "print(\"Entropy of right child node is {0}\".format(\n",
    "          calc_entropy(child_node_right['played'].values)))\n",
    "child_node_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the difference between entropy and Gini impurity?\n",
    "\n",
    "**Class workshop:** Assume we're using a decision tree to classify, have 50 spam and 50 non-spam emails in our training set, and have many different features that result in different splits. Make up to splits, one which is favored using entropy, the other is favored by Gini impurity.\n",
    "\n",
    "### How would you know how to stop?\n",
    "\n",
    "**Class discussion:** When would you stop? Potential problems?\n",
    "\n",
    "Will get to this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT Pseudocode\n",
    "\n",
    "Recursive partitioning algorithm\n",
    "\n",
    "```\n",
    "function BuildTree:\n",
    "    # base case, stop building tree\n",
    "    If every item in the dataset is in the same class\n",
    "    or there is not feature left to split the data:\n",
    "        return a leaf node with the class label\n",
    "    # recursive case, keep splitting stuff\n",
    "    Else:\n",
    "        find the best feature and value to split the data\n",
    "        split the dataset\n",
    "        create a node\n",
    "        for each split\n",
    "            call Build Tree and add the result as a child of the node\n",
    "        return node\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Decision Trees\n",
    "\n",
    "Class discussion: what are some problems you foresee with this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_tree(ax, X, y, model=None, fit = True):\n",
    "    ax.plot(X[y==0, 0], X[y==0, 1], 'r.', label='versicolor')\n",
    "    ax.plot(X[y==1, 0], X[y==1, 1], 'b.', label='virginica')\n",
    "    ax.set_title(\"Classifying Iris with Decision Trees\")\n",
    "    ax.set_xlabel(\"Sepal Length (mm)\")\n",
    "    ax.set_ylabel(\"Sepal Width (cm)\")\n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    if model is None:\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "    if fit:\n",
    "        model.fit(X, y)\n",
    "    \n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    plot_classification_thresholds(ax, X, y, 0, model.tree_, xlim, ylim)\n",
    "    \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "def plot_classification_thresholds(ax, X, y, inode, tree, xlim, ylim):\n",
    "    threshold = tree.threshold[inode]\n",
    "    if tree.feature[inode] == -2:\n",
    "        color = ['r', 'b'][np.argmax(tree.value[inode])]\n",
    "        ax.add_patch(Rectangle((xlim[0], ylim[0]), xlim[1]-xlim[0], ylim[1]-ylim[0], fc=color, alpha=0.3))\n",
    "        return\n",
    "    if tree.feature[inode] == 0:\n",
    "        ax.plot((threshold, threshold), ylim, 'k', lw=0.5)\n",
    "        plot_classification_thresholds(ax, X, y, tree.children_left[inode],  tree, (xlim[0], threshold), ylim)\n",
    "        plot_classification_thresholds(ax, X, y, tree.children_right[inode], tree, (threshold, xlim[1]), ylim)\n",
    "    else:\n",
    "        ax.plot(xlim, (threshold, threshold), 'k', lw=0.5)\n",
    "        plot_classification_thresholds(ax, X, y, tree.children_left[inode],  tree, xlim, (ylim[0], threshold))\n",
    "        plot_classification_thresholds(ax, X, y, tree.children_right[inode], tree, xlim, (threshold, ylim[1]))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = gen_similar_samples(X, y, 1)[0]\n",
    "model = tree.DecisionTreeClassifier()\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_classification_tree(ax, X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is some risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gen_similar_samples(X, y, 1)[0]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_classification_tree(ax, X, y, model, fit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we don't let it split so many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 10)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_classification_tree(ax, X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the Best Tree\n",
    "\n",
    "* Cross validate!\n",
    "    * Train trees with different parameters, see which performs best on validation set\n",
    "    * No different than any other model\n",
    "\n",
    "## Pruning\n",
    "\n",
    "We call the idea of modifying a decision tree to improve its performance **pruning**.\n",
    "\n",
    "There are two approaches: **pre-pruning** (limiting the tree as we build it) and **post-pruning** (sometimes just called \"pruning\"; chopping back the tree after it is built.\n",
    "\n",
    "### Pre\n",
    "\n",
    "Prune as we build the tree, control hyper-parameters\n",
    "\n",
    "Class discussion: what can we control?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post\n",
    "\n",
    "Post-pruning (also just called pruning) involves cutting back the tree after it's been built based on the test-set error.\n",
    "\n",
    "* Merge leaves if doing so decreases *test-set* error\n",
    "* If not leaves, consider each branch first (recursively)\n",
    "\n",
    "#### Pseudocode\n",
    "```\n",
    "function Prune:\n",
    "    if either left or right is not a leaf:\n",
    "        call Prune on those that aren't\n",
    "    if both left and right are (now) leaf nodes:\n",
    "        calculate error associated with merging two leaf nodes\n",
    "        calculate error associated without merging two leaf nodes\n",
    "        if merging results in lower error:\n",
    "            merge the leaf nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of Decision Trees\n",
    "\n",
    "Class discussion: what do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decision Tree Algorithms\n",
    "\n",
    "There are some famous variants of the decision tree algorithm:\n",
    "\n",
    "### ID3\n",
    "\n",
    "Short for Iterative Dichotomiser 3, the original Decision Tree algorithm developed by Ross Quinlan (who's responsible for a lot of proprietary decision tree algorithms) in the 1980's.\n",
    "\n",
    "* designed for only categorial features\n",
    "* splits categorical features completely\n",
    "* uses entropy and information gain to pick the best split\n",
    "\n",
    "### CART\n",
    "\n",
    "Short for Classification and Regression Tree was invented about the same time as ID3 by Breiman, Friedman, Olshen and Stone. The CART algorithm has the following properties:\n",
    "\n",
    "* handles both categorial and continuous data\n",
    "* always uses binary splits\n",
    "* uses gini impurity to pick the best split\n",
    "\n",
    "Algorithms will be called CART even if they don't follow all of the specifications of the original algorithm.\n",
    "\n",
    "### C4.5\n",
    "\n",
    "This is Quinlan's first improvement on the ID3 algorithm. The main improvements are:\n",
    "\n",
    "* handles continuous data\n",
    "* implements pruning to reduce overfitting\n",
    "\n",
    "### C5.0\n",
    "\n",
    "This is supposedly better, but it's proprietary so we don't have access to the specifics of the improvements."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
