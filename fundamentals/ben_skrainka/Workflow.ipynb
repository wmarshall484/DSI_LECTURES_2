{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science workflow\n",
    "\n",
    "Whenever you start a data science project, you should follow a workflow, which will help you:\n",
    "\n",
    "* Perform all steps in analysis\n",
    "* Produce reproducible results and track data provenance\n",
    "* Avoid simple errors\n",
    "* Produce higher quality work\n",
    "\n",
    "The [Common industry standard process for data mining](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining) (CRISP-DM) is a good workflow to use, unless you know better.  \n",
    "\n",
    "Make sure that you also think about correctness, and integrate *Verification, Validation, & Uncertainty Quantification (VV & UQ)* with your workflow:\n",
    "\n",
    "*  *Verify* that your code correctly implements your model ('solves the equations right') \n",
    "*  *Validate* that your model has high fidelity with reality ('solves the right equations').  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Verification and Validation in Scientific Computing](http://www.amazon.com/Verification-Validation-Scientific-Computing-Oberkampf/dp/0521113601/ref=sr_1_1?ie=UTF8&qid=1445036147&sr=8-1&keywords=verification+and+validation) is an excellent reference.\n",
    "* Benjamin S. Skrainka's talk on [\"Correctness in Data Science\"](https://youtu.be/kex-UXZTGU4) provides a quick introduction and much practical advice.\n",
    "* [Fundamentals of Machine Learning for Predictive Data Analytics](https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics) has a good discussion of CRISP-DM plus worked case studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business understanding\n",
    "\n",
    "Every thing starts with business understanding.  Speak with your stakeholders:\n",
    "\n",
    "* What is the business problem you need to answer?\n",
    "* What are the requirements?\n",
    "* How do you measure success?\n",
    "\n",
    "Do not proceed until you have answered these questions.  Often, it is not clear what success looks like or even what you should use as a lable (target) to train you model.  The metric for success will typically be a business quantity like 'decrease churn rate 10%' instead of improving AUC or MAPE.  Consequently, you need to tune your model based on the right business outcome.  Make sure you always state results in business terms like this policy will save $100 MM or decrease fraud by 10%.\n",
    "\n",
    "Note: These steps are an interative process. E.g., after performing a step, such as **Modeling**, you may discover a mistake which causes you to repeat an earlier process, such as **data cleaning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data understanding\n",
    "\n",
    "After you define the business problem, you need to determine what data is available.  Ponder the following:\n",
    "\n",
    "* What datasets are available?\n",
    "* How can you combine them to produce a dataset to answer their business questions?\n",
    "* Do you need to collect additional data?\n",
    "* Does your data have a label (target) or do you need to generate one, perhaps by using [MechTurk](https://www.mturk.com/mturk/welcome)or equivalent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation\n",
    "\n",
    "To prepare a dataset for modeling, you should first explore the data and, concurrently, figure out how to clean it.  At the end of this step, you should have a dataset you can use to build a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Load data and perform minimal cleaning\n",
    "\n",
    "Start by loading your data so that you can begin exploring it.  Perform only the most minimal cleaning necessary -- overcleaning can remove valuable information (signal).  Pro tip:  if your data is huge, start by making sure everything works on a small subset of your data, like a single shard.  You want to be able to interate quickly and get your pipeline working before attempting full-scale analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates\n",
    "\n",
    "Working with dates is frustrating and tricky.  Start by converting all dates into a `datetime` object using `datetime.datetime.strptime()`.  Next, you may need to add fixed effects (dummy variables) to handle shocks caused by day, week, month, year, or day of week.  For example, \"Single's Day\" (November 11) in China causes a huge spike Internet purchases.  Also, you may need to normalize data by the number of (working) days per month.  This is common with data on sales or GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Exploratory data analysis (EDA)\n",
    "\n",
    "Get to know the strengths and weaknesses of your data:\n",
    "\n",
    "* What are the strengths and weaknesses?\n",
    "* Any weird values?  outliers? missing values? malformed/unstructured fields?\n",
    "* What is the nature of your missing values?  Are they missing at random?  If not, how are you going to deal with them?\n",
    "* Compute summary statistics\n",
    "* Plot features to see if they have predictive power?  If you have a lot of data, draw a subset -- and make sure your results don't depend on the subset you have chosen.\n",
    "* Plot histograms of label and key features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Feature engineering\n",
    "\n",
    "Finally, assemble your final dataset.  Feature engineering -- how you construct the features for your model -- is often more important than what model you choose.  Some issues:\n",
    "\n",
    "* Compute a target/label if one doesn't exist -- this will require domain expertise\n",
    "* Handle missing values -- can you bin or are missing values *missing at random* so you can drop them?\n",
    "* Handle outliers -- should you bin the data to make it discrete?\n",
    "* Replace categorical variables with dummy variables, which `scikit-learn` requires, unlike `R`\n",
    "* Transform data:\n",
    "  *  Take `log` of data, which is often useful with long-tailed data\n",
    "  *  Possibly, quantize continuous to handle non-linear behavior\n",
    "  * Convert text data to features using:\n",
    "    * *Natural Language Processing* (NLP)\n",
    "    * *Term frequency-inverse document frequency* (TF-IDF)\n",
    "    * *[feature hashing](https://en.wikipedia.org/wiki/Feature_hashing)* trick\n",
    "    * Compute n-grams, etc.\n",
    "* Rationalize address data into standard USPS format\n",
    "\n",
    "Be careful to avoid using *endogenous* features, i.e., those which are codetermined with the outcome.  For example, if you regress `quantity` on `price`, `price` is almost always endogenous because it is codetermined from the interaction between the buyer and the seller.  Consequently, in the regression model \n",
    "\n",
    "\n",
    "$$q_{it} = \\alpha_0 + \\alpha_1 * price + \\epsilon$$\n",
    "\n",
    "\n",
    "$\\mathbb{E}[price * \\epsilon] \\neq 0$, which violates the assumptions needed to use linear regression.\n",
    "\n",
    "Now you should be ready to start modeling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "\n",
    "Start by producing a 'shitty' first model.  If it performs too well, you should be suspicious.  Look for *information leakage*, i.e., a single variable which predicts the outcome (almost) perfectly.  This often happens with time series data when you have a feature which contains information from future periods.  It also occurs, when a feature is derived from the label.  You may want to run *one-in* or *one-out* reports to test for this problem.\n",
    "\n",
    "Next refine the model and determine which features are important.  You should use *cross-validation* to tune parameter settings and find a candidate model.  Use diagnostic tools to determine which features are most important.  Do the results agree with your intuition?  Also, test that the assumptions needed to use your model are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Before releasing the model to the wild, you should evaluation it.  One of the best ways to do this is to design and run an experiment such as an A/B test.  If that is not possible you can also use an approach like [Bayesian structural time series models](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41854.pdf) or some other method that let's you determine causally whether your awesome new model has the desired impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment\n",
    "\n",
    "Finally, you model is ready for deployment!  Then the process will start all over:  you may need to keep retraining and retuning the model as the competitive environment changes.  Also, follow on studies are common, so plan for change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Most likely at several points along the workflow, you will need to present your results to non-technical (MBA) stakeholders.  Make sure you have a easily digested explanation and graphic to support your findings.  Modern companies are keen to make *data-driven decisions*.  As a data scientist, you are a key part of this revolution -- doing things according to the 4Ps is no longer good enough, because we are drowning in data and can measure what actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
