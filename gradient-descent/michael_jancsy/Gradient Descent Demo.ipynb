{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.spatial.distance import norm\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import time\n",
    "\n",
    "def gradient_descent(X, y, \n",
    "                     cost_function, gradient_of_cost_function, \n",
    "                     initial_guess, learning_rate=.1, \n",
    "                     threshold=1e-3, max_iter=1e3):\n",
    "    params = initial_guess\n",
    "    param_history = [(initial_guess[0], initial_guess[1], cost_function(X, y, params))]\n",
    "    improvement = threshold\n",
    "    old_cost = 100000\n",
    "    iterations = 0\n",
    "    time_history = [time.time()]\n",
    "    while (norm(gradient_of_cost_function(X, y, params)) >= threshold \n",
    "           and iterations < max_iter):\n",
    "        iterations += 1\n",
    "        params -= learning_rate*gradient_of_cost_function(X, y, params)\n",
    "        cost = cost_function(X, y, params)\n",
    "        param_history.append((params[0], params[1], cost)) # for plotting\n",
    "        improvement = np.abs(cost - old_cost)/old_cost\n",
    "        old_cost = cost\n",
    "        time_history.append(time.time())\n",
    "    if iterations == max_iter:\n",
    "        print \"max iterations reached\"\n",
    "    print \"Final gradient of cost function %s\" %gradient_of_cost_function(X, y, params)\n",
    "    print \"Final params %s\" %params\n",
    "    return param_history, time_history\n",
    "\n",
    "def stochastic_gradient_descent(X, y, \n",
    "                     cost_function, gradient_of_cost_function, \n",
    "                     initial_guess, learning_rate=.1, \n",
    "                     threshold=1e-3, max_iter=1e3, batch_size=1):\n",
    "    batch_size = min(batch_size, X.shape[0])\n",
    "    params = initial_guess\n",
    "    param_history = [(initial_guess[0], initial_guess[1])]\n",
    "    improvement = threshold\n",
    "    old_cost = 100000\n",
    "    iterations = 0\n",
    "    time_history = [time.time()]\n",
    "    while (norm(gradient_of_cost_function(X, y, params)) >= threshold \n",
    "           and iterations < max_iter):\n",
    "        # select indices of mini-batch\n",
    "        min_index = batch_size*iterations % X.shape[0]\n",
    "        indices = []\n",
    "        while len(indices) < batch_size:\n",
    "            indices.append((min_index + len(indices)) % X.shape[0])\n",
    "        Xi, yi = X[indices], y[indices]\n",
    "        # update parameters\n",
    "        params -= learning_rate*gradient_of_cost_function(Xi, yi, params)\n",
    "        cost = cost_function(Xi, yi, params)\n",
    "        param_history.append((params[0], params[1])) # for plotting\n",
    "        improvement = np.abs(cost - old_cost)/old_cost\n",
    "        old_cost = cost\n",
    "        iterations += 1\n",
    "        time_history.append(time.time())\n",
    "    if iterations == max_iter:\n",
    "        print \"max iterations reached\"\n",
    "    print \"Final gradient of cost function %s\" %gradient_of_cost_function(X, y, params)\n",
    "    print \"Final params %s\" %params\n",
    "    return param_history, time_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_results(X, y, cost_function, param_history):\n",
    "    params = param_history[-1][0:2]\n",
    "    x_params = np.array([params[0] - (params[0]-p[0]) for p in param_history] +\n",
    "                [params[0] + (params[0]-p[0]) for p in param_history])\n",
    "    x_params.sort()\n",
    "    y_params = np.array([params[1] - (params[1]-p[1]) for p in param_history] +\n",
    "                [params[1] + (params[1]-p[1]) for p in param_history])\n",
    "    y_params.sort()\n",
    "    samples = list(product(x_params, y_params))\n",
    "    costs = [cost_function(X, y, np.array([p[0], p[1]])) for p in samples]\n",
    "    costs = np.reshape(costs, (len(x_params), -1))\n",
    "    cost_surface = Surface(\n",
    "        x = x_params,\n",
    "        y = y_params,\n",
    "        z = costs,\n",
    "        colorscale = [[0, 'rgb(31,119,180)'], \n",
    "                      [0.5, 'rgb(143, 123, 196)'], \n",
    "                      [1, 'rgb(255,127,97)']],\n",
    "        name='Cost Function'\n",
    "    )\n",
    "    param_history = Scatter3d(\n",
    "        x = x_params,\n",
    "        y = y_params,\n",
    "        z = [p[2] for p in param_history],\n",
    "        mode = 'lines+markers'\n",
    "    )\n",
    "    data_3d_plot = Data([cost_surface, param_history])\n",
    "    figure_3d = Figure(data=data_3d_plot)\n",
    "    return figure_3d\n",
    "\n",
    "def plot_sgd_results(X, y, cost_function, param_history):\n",
    "    x_history = [p[0] for p in param_history]\n",
    "    y_history = [p[1] for p in param_history]\n",
    "    x_params = np.linspace(min(x_history),\n",
    "                           max(x_history),\n",
    "                           100)\n",
    "    y_params = np.linspace(min(y_history),\n",
    "                           max(y_history),\n",
    "                           100)\n",
    "    samples = list(product(x_params, y_params))\n",
    "    demo_points = OrderedDict()\n",
    "    for p in param_history:\n",
    "        best_sample = samples[0]\n",
    "        min_distance = ((p[0]-best_sample[0])**2+(p[1]-best_sample[1])**2)**.5\n",
    "        for sample in samples:\n",
    "            d = ((p[0]-sample[0])**2+(p[1]-sample[1])**2)**.5\n",
    "            if d < min_distance:\n",
    "                best_sample = sample\n",
    "                min_distance = d\n",
    "        demo_points[tuple(p)] = best_sample\n",
    "    costs = [cost_function(X, y, np.array([p[0], p[1]])) for p in samples]\n",
    "    costs = np.reshape(costs, (len(x_params), -1))\n",
    "    cost_surface = Surface(\n",
    "        x = x_params,\n",
    "        y = y_params,\n",
    "        z = costs,\n",
    "        colorscale = [[0, 'rgb(31,119,180)'], \n",
    "                      [0.5, 'rgb(143, 123, 196)'], \n",
    "                      [1, 'rgb(255,127,97)']],\n",
    "        name='Cost Function'\n",
    "    )\n",
    "    param_history = Scatter3d(\n",
    "        x = [d[0] for d in demo_points],\n",
    "        y = [d[1] for d in demo_points],\n",
    "        z = [cost_function(X, y, d) for d in demo_points],\n",
    "        mode = 'lines+markers'\n",
    "    )\n",
    "    data_3d_plot = Data([cost_surface, param_history])\n",
    "    figure_3d = Figure(data=data_3d_plot)\n",
    "    return figure_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(X, params):\n",
    "    y_predicted = X.dot(params)\n",
    "    return y_predicted\n",
    "\n",
    "X, y = make_regression(n_samples = 50, n_features = 2, n_informative=2, random_state=0)\n",
    "X = (X - X.mean(axis=0))/X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient of cost function [-0.00036218 -0.00086667]\n",
      "Final params [ 42.71922179  61.1163727 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/567.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEAR REGRESSION WITHOUT REGULARIZATION\n",
    "\n",
    "def ols_cost_function(X, y, params):\n",
    "    '''\n",
    "    OLS from linear regression\n",
    "    '''\n",
    "    n_observations = X.shape[0]\n",
    "    avg_squared_residuals = ((predict(X, params) - y)**2).sum()/(2*n_observations)\n",
    "    return avg_squared_residuals\n",
    "\n",
    "def ols_gradient_of_cost_function(X, y, params):\n",
    "    n_observations = X.shape[0]\n",
    "    gradient = (predict(X, params) - y).dot(X)/n_observations\n",
    "    return gradient\n",
    "\n",
    "gd_param_history, gd_time_history = gradient_descent(X, y, ols_cost_function, ols_gradient_of_cost_function,\n",
    "                initial_guess = np.array([0., 0.]))\n",
    "\n",
    "figure_3d = plot_results(X, y, ols_cost_function, gd_param_history)\n",
    "py.iplot(figure_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient of cost function [-0.00037271 -0.00087987]\n",
      "Final params [ 41.06629797  58.59902384]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/569.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEAR REGRESSION WITH L2 REGULARIZATION\n",
    "\n",
    "def ridge_cost_function(X, y, params, lambda_=5.):\n",
    "    '''\n",
    "    OLS from linear regression\n",
    "    '''\n",
    "    n_observations = X.shape[0]\n",
    "    avg_squared_residuals = (((predict(X, params) - y)**2).sum()\n",
    "                             + lambda_*(params**2).sum())/(2*n_observations)\n",
    "    return avg_squared_residuals\n",
    "\n",
    "def ridge_gradient_of_cost_function(X, y, params, lambda_=2.):\n",
    "    n_observations = X.shape[0]\n",
    "    gradient = ((predict(X, params) - y).dot(X)\n",
    "               + lambda_*params)/n_observations\n",
    "    return gradient\n",
    "\n",
    "ridge_param_history, ridge_time_history = gradient_descent(X, y, ridge_cost_function, ridge_gradient_of_cost_function,\n",
    "                                   initial_guess = np.array([0., 0.]))\n",
    "\n",
    "figure_3d = plot_results(X, y, ridge_cost_function, ridge_param_history)\n",
    "py.iplot(figure_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/571.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LASSO\n",
    "PARAM_HISTORY = [] \n",
    "\n",
    "LAMBDA_ = 50000.\n",
    "\n",
    "def lasso_cost_function(X, y, params, lambda_=LAMBDA_):\n",
    "    '''\n",
    "    OLS from linear regression\n",
    "    '''\n",
    "    n_observations = X.shape[0]\n",
    "    avg_squared_residuals = (((predict(X, params) - y)**2).sum()\n",
    "                             + lambda_*sum(np.abs(params)))/(2*n_observations)\n",
    "    return avg_squared_residuals\n",
    "\n",
    "x_params = np.linspace(-5, 5, 100)\n",
    "y_params = np.linspace(-5, 5, 100)\n",
    "samples = list(product(x_params, y_params))\n",
    "costs = [lasso_cost_function(X, y, np.array([p[0], p[1]])) for p in samples]\n",
    "costs = np.reshape(costs, (len(x_params), -1))\n",
    "cost_surface = Surface(\n",
    "    z = costs,\n",
    "    x = x_params,\n",
    "    y = y_params,\n",
    "    colorscale = [[0, 'rgb(31,119,180)'], \n",
    "                  [0.5, 'rgb(143, 123, 196)'], \n",
    "                  [1, 'rgb(255,127,97)']],\n",
    "    name='Cost Function'\n",
    ")\n",
    "\n",
    "data_3d_plot = Data([cost_surface])\n",
    "figure_3d = Figure(data=data_3d_plot)\n",
    "py.iplot(figure_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max iterations reached\n",
      "Final gradient of cost function [-1.33573467  0.45502579]\n",
      "Final params [ 41.45343437  61.55137444]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/369.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD: LINEAR REGRESSION\n",
    "sgd_param_history, sgd_time_history = stochastic_gradient_descent(X, y, ols_cost_function, \n",
    "                                                ols_gradient_of_cost_function,\n",
    "                                                initial_guess=np.array([0., 0.]),\n",
    "                                                learning_rate=.1)\n",
    "figure_3d = plot_sgd_results(X, y, ols_cost_function, sgd_param_history)\n",
    "py.iplot(figure_3d, filename = 'Linear Regression - Gradient Descent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max iterations reached\n",
      "Final gradient of cost function [-0.07039159  0.12712869]\n",
      "Final params [ 42.65627649  61.24856424]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/573.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MINIBATCH SGD: LINEAR REGRESSION WITHOUT REGULARIZATION\n",
    "minibatch_param_history, minibatch_time_history = stochastic_gradient_descent(X, y, ols_cost_function, \n",
    "                                                ols_gradient_of_cost_function,\n",
    "                                                initial_guess=np.array([0., 0.]),\n",
    "                                                learning_rate=.1, batch_size=5)\n",
    "figure_3d = plot_sgd_results(X, y, ols_cost_function, minibatch_param_history)\n",
    "py.iplot(figure_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # PLOT GD, SGD, and minibatch SGD convergence\n",
    "# gd_convergence = Scatter(\n",
    "#     x = [i for i,j in enumerate(gd_param_history)],\n",
    "#     y = [ols_cost_function(X, y, (p[0], p[1])) for p in gd_param_history],\n",
    "#     mode = 'lines',\n",
    "#     name = 'Batch Gradient Descent'\n",
    "# )\n",
    "\n",
    "# sgd_convergence = Scatter(\n",
    "#     x = [i for i,j in enumerate(sgd_param_history)],\n",
    "#     y = [ols_cost_function(X, y, (p[0], p[1])) for p in sgd_param_history],\n",
    "#     mode = 'lines',\n",
    "#     name = 'SGD'\n",
    "# )\n",
    "\n",
    "# minibatch_convergence = Scatter(\n",
    "#     x = [i for i,j in enumerate(minibatch_param_history)],\n",
    "#     y = [ols_cost_function(X, y, (p[0], p[1])) for p in minibatch_param_history],\n",
    "#     mode = 'lines',\n",
    "#     name = 'Mini-batch SGD'\n",
    "# )\n",
    "\n",
    "# data = Data([gd_convergence, sgd_convergence, minibatch_convergence])\n",
    "# figure = Figure(data=data)\n",
    "# py.iplot(figure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/575.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLOT GD, SGD, and minibatch SGD convergence on log scale\n",
    "gd_convergence = Scatter(\n",
    "    x = [i for i,j in enumerate(gd_param_history)],\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in gd_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'Batch Gradient Descent'\n",
    ")\n",
    "\n",
    "sgd_convergence = Scatter(\n",
    "    x = [i for i,j in enumerate(sgd_param_history)],\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in sgd_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'SGD'\n",
    ")\n",
    "\n",
    "minibatch_convergence = Scatter(\n",
    "    x = [i for i,j in enumerate(minibatch_param_history)],\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in minibatch_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'Mini-batch SGD'\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    xaxis=XAxis(\n",
    "        #type='log',\n",
    "        autorange=True\n",
    "    ),\n",
    "    yaxis=YAxis(\n",
    "        type='log',\n",
    "        autorange=True\n",
    "    )\n",
    ")\n",
    "data = Data([gd_convergence, sgd_convergence, minibatch_convergence])\n",
    "figure = Figure(data=data, layout=layout)\n",
    "py.iplot(figure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # PLOT GD, SGD, and minibatch SGD convergence over time\n",
    "# gd_convergence = Scatter(\n",
    "#     x = [t/gd_time_history[0] for t in gd_time_history],\n",
    "#     y = [ols_cost_function(X, y, (p[0], p[1])) for p in gd_param_history],\n",
    "#     mode = 'lines',\n",
    "#     name = 'Batch Gradient Descent'\n",
    "# )\n",
    "\n",
    "# sgd_convergence = Scatter(\n",
    "#     x = [t/sgd_time_history[0] for t in sgd_time_history],\n",
    "#     y = [ols_cost_function(X, y, (p[0], p[1])) for p in sgd_param_history],\n",
    "#     mode = 'lines',\n",
    "#     name = 'SGD'\n",
    "# )\n",
    "\n",
    "# minibatch_convergence = Scatter(\n",
    "#     x = [t/minibatch_time_history[0] for t in minibatch_time_history],\n",
    "#     y = [ols_cost_function(X, y, (p[0], p[1])) for p in minibatch_param_history],\n",
    "#     mode = 'lines',\n",
    "#     name = 'Mini-batch SGD'\n",
    "# )\n",
    "\n",
    "# layout = Layout(\n",
    "#     xaxis=XAxis(\n",
    "#         #type='log',\n",
    "#         autorange=True\n",
    "#     ),\n",
    "#     yaxis=YAxis(\n",
    "#         type='log',\n",
    "#         autorange=True\n",
    "#     )\n",
    "# )\n",
    "# data = Data([gd_convergence, sgd_convergence, minibatch_convergence])\n",
    "# figure = Figure(data=data, layout=layout)\n",
    "# py.iplot(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
