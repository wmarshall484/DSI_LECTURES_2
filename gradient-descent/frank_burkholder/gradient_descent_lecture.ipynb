{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and Gradient Descent Lecture\n",
    "\n",
    "F. Burkholder (credit T. Heilman and A. Richards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this lecture is expose you to what is happening behind the scenes when you are calling `.fit` on some of sklearn's machine learning models to determine model coefficients (a.k.a. $\\beta$, $\\theta$, parameters, weights)  \n",
    "\n",
    "This same process also helps determine weights in a neural network - so we will revisit this topic when we get to neural nets in module 2.  \n",
    "\n",
    "Gradient Descent all by itself is not a machine learning model - it's a way of solving for coefficients (in some model) given coefficients that need to be determined, true and predicted target values (from the model that uses the coefficients), and a **cost function** that quantifies how different the the predicted and true values are across the training data.\n",
    "\n",
    "Gradient Descent is one way of performing [mathematical optimization.](https://en.wikipedia.org/wiki/Mathematical_optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "Mathematical optimization includes finding \"best available\" values of some **objective function** given a defined domain (or input).\n",
    "\n",
    "Example objective functions:\n",
    "* The time spent on preparations before leaving your house so that you can arrive at work on time.\n",
    "* Getting a job after the DSI given the time associated with all the work associated with graduation (assignments, case studies, capstones, mock interviews, career services, applying for jobs).\n",
    "* Deciding what to do now so that you can retire at a young age.\n",
    "* Finding the maximum or minimum of some mathematical function.\n",
    "\n",
    "In an optimization problem you decide whether you are looking for the objective function's maximum or minimum.\n",
    "\n",
    "\n",
    "## Optimization in machine learning\n",
    "\n",
    "In [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) our task is to choose a model, including its coefficients, that will train on existing data and then perform well on unseen data.\n",
    "\n",
    "Here are two examples of objective functions in machine learning:\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "Find coefficients $\\theta$ that **minimize** the mean squared residual:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i - h_\\theta(x_i))^2 $$\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "Find coefficients $\\theta$ that **maximize** the likelihood of the classifying the true values correctly.\n",
    "\n",
    "$$  L(\\theta) = \\sum_{i=1}^N (y_i \\ln h_\\theta (x_i) + (1- y_i)\\ln(1- (h_\\theta (x_i))) $$\n",
    "\n",
    "Note that $h_\\theta(x)$ are predictions of the model, otherwise known as $\\hat{y}$.\n",
    "\n",
    "In both cases we trying to optimize $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent - a way to find the coefficients.\n",
    "\n",
    "[Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) is a first-order(based on the multi-dimensional derivative called the gradient) iterative optimization algorithm for finding the minimum of a function.\n",
    "\n",
    "To find a local minimum, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.\n",
    "\n",
    "$$ \\beta_{new} = \\beta_{old} - \\alpha \\cdot \\frac{\\nabla J}{\\partial \\beta}$$\n",
    "\n",
    "$ \\beta_{new} $ is the new estimate of the model coefficients  \n",
    "$ \\beta_{old} $ is the old estimate of the model coefficients  \n",
    "$ \\alpha $ is the learning rate, the tunable parameter that adjusts how much of a step is taken in the direction of the gradient  \n",
    "$ \\frac{\\nabla J}{\\partial \\beta} $ is the gradient, a measure of how much the cost function is increasing with respect to each of the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent in one dimension\n",
    "\n",
    "Let's start with a simplified example, a cost function of $ J = 3x^2 $\n",
    "\n",
    "*J* is the cost, *x* is the feature/coefficient/parameter that we are trying to minimize. \n",
    "\n",
    "Gradient descent requires: \n",
    "* cost function, $J$\n",
    "* the gradient of the cost function, in this case $ \\frac{\\nabla J}{\\partial x} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(x):\n",
    "    return 3*x**2\n",
    "\n",
    "def grad_cost_func(x):\n",
    "    return 6*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from calculus that we can find the minimum of this function at x = 0. \n",
    "\n",
    "For demonstation purposes, we pretend that we don't know this, and we will start with a guess of x = 5 for the minimum.\n",
    "\n",
    "Let's plot this, for a visual..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping our guesses in a list for reasons that will become clear later....\n",
    "guesses = [5]\n",
    "\n",
    "def plot_cost(x_guess):\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(111) \n",
    "    x = np.linspace(-6, 6)\n",
    "    y = cost_func(x)\n",
    "    ax.plot(x, y)\n",
    "    y_guess = [cost_func(xg) for xg in x_guess]\n",
    "    ax.plot(x_guess, y_guess, 'ro')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    \n",
    "    labels = ['step {}'.format(i) for i in range(len(x_guess))]\n",
    "    for label, x, y in zip(labels, x_guess, y_guess):\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y), xytext=(-20, 20),\n",
    "            textcoords='offset points', ha='right', va='bottom',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "            arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "   \n",
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this one-dimensional case, we can visually inspect and see that we are pretty far from the minimum! \n",
    "\n",
    "Let's compute the gradient at this point to update our \"guess\" for x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = grad_cost_func(guesses[-1])\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is huge at our guess! If we simply adjusted by that amount, we would overshoot the minimum by far! This is why we use the learning rate to adjust our guess by small steps. Let's try a learning rate of .05, so we don't go too far. Since we are doing gradient DESCENT, we should subtract the gradient from our guess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "guess_update = guesses[-1] - learning_rate*grad\n",
    "# let's keep our guesses in a list...\n",
    "guesses.append(guess_update)\n",
    "\n",
    "print(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot including our new guess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot closer. Let's do this three more times and see where we land..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    grad = grad_cost_func(guesses[-1])\n",
    "    guess_update = guesses[-1] - learning_rate*grad\n",
    "    guesses.append(guess_update)\n",
    "\n",
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as we get closer to the minimum, the gradient gets smaller and so the guesses step more slowly. This is a good thing - a natural property that makes it harder for us to overshoot!\n",
    "\n",
    "Let's see if 5 more times does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    grad = grad_cost_func(guesses[-1])\n",
    "    guess_update = guesses[-1] - learning_rate*grad\n",
    "    guesses.append(guess_update)\n",
    "\n",
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks pretty close, let's inspect the list to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\\tguess\")\n",
    "for i, guess in enumerate(guesses,1):\n",
    "    print(\"{0}\\t{1:0.3f}\".format(i, guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't quite get to the minimum, but with more steps it would."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple example where there was only one coefficient to find (there was just one feature).  For most machine learning models, there are multiple features and therefore coefficients to find for each feature.\n",
    "\n",
    "In this case you take a multi-dimensional derivative called the gradient.\n",
    "\n",
    "##  Gradient Formula\n",
    "* The gradient is the multivariate analogue of the derivative.\n",
    "\n",
    "$$ \\nabla f = \\sum_{i=1}^P\\frac{\\partial f}{\\partial x_i} \\vec{e_i}$$\n",
    "\n",
    "where:  \n",
    "$ \\nabla f$ is the gradient of function $f$  \n",
    "$ \\sum_{i=1}^P$ is the sum over all the predictors (columns) $P$  \n",
    "$ \\frac{\\partial f}{\\partial x_i}$ is the partial derivative of $f$ with respect to predictor $x_i$  \n",
    "$ e_i$ indicates in the direction of the predictor $x_i$\n",
    "\n",
    "Simple example.  Say there were columns $x$, $y$, and $z$ in our X array, \n",
    "defined to go in directions $\\vec{i}, \\vec{j}, \\vec{k}$.  \n",
    "So $$ \\nabla f = \\frac{\\partial f}{\\partial x} \\vec{i} + \\frac{\\partial f}{\\partial y} \\vec{j}+ \\frac{\\partial f}{\\partial z} \\vec{k}$$\n",
    "\n",
    "Say $$ f = 2x + 3y^{2} - sin(3z) $$\n",
    "\n",
    "The gradient is:  \n",
    "\n",
    "$$ \\nabla f = 2\\vec{i} + 6y\\vec{j} - 3cos(3z)\\vec{k} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pair assignment\n",
    "\n",
    "In your assignment today you'll be working through the gradient descent algorithm for logistic regression.  \n",
    "\n",
    "In this notebook we'll work through an example using linear regression.\n",
    "\n",
    "### First, recall the objective functions\n",
    "\n",
    "#### Linear Regression\n",
    "\n",
    "We want to find coefficients $\\theta$ that minimize the mean squared residual:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i - h_\\theta(x_i))^2 $$\n",
    "\n",
    "#### Logistic Regression\n",
    "\n",
    "We want to find coefficients $\\theta$ that maximize the likelihood of the classifying the true values correctly.\n",
    "\n",
    "$$  L(\\theta) = \\sum_{i=1}^N (y_i \\ln h_\\theta (x_i) + (1- y_i)\\ln(1- (h_\\theta (x_i))) $$\n",
    "\n",
    "To use gradient **descent** we would like to find a minimum instead of a maximum.  So we multiply the maximum likelihood by -1 to change the objective function in to a cost function.\n",
    "\n",
    "$$  J(\\theta) = -\\sum_{i=1}^N (y_i \\ln h_\\theta (x_i) + (1- y_i)\\ln(1- (h_\\theta (x_i))) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent demo\n",
    "First, instantiate a small \"dataset\" X, with 2 features and 10 rows, and **true** beta coefficients (that gradient descent will determine later in the notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # set random seed\n",
    "X = np.random.random((10, 2))\n",
    "# define true betas that will be used to calculate y\n",
    "# the goal will be to converge on the true betas using X, y, and gradient descent\n",
    "true_betas = np.array([3, 4]).reshape(-1, 1) # go ahead and turn this into a column vector \n",
    "print(\"The betas (or weights, or theta in cost functions above) gradient descent will try to find are:\")\n",
    "print(true_betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically we know our Xs and ys, but are actually trying to solve for the best values of beta. In this exampe the true beta values are used calculate y, and then X and y are used in gradient descent to try to determine what the beta values were.\n",
    "\n",
    "Note - we already know the correct answer for our coefficients, which is a good way to practice our algorithm - we already know the correct answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.dot(X,true_betas).reshape(-1, 1) # keep this as a column vector so linear algebra goes smoothly\n",
    "print(\"X array:\")\n",
    "print(np.around(X,2))\n",
    "print(\"\\ny array:\")\n",
    "print(np.around(y,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that np.around did not change the values in the arrays\n",
    "# but simple made it nice for displaying\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for Gradient Descent\n",
    "\n",
    "**1. Compute gradient of the cost function.**  \n",
    "Compute the gradient (derivative) of this below. You may find it helpful to first think of it as just one row of data.\n",
    "\n",
    "$$ J_i(\\beta) = \\frac{1}{2}((y_i - x_i \\cdot \\beta))^2 $$\n",
    "where  \n",
    "\n",
    "$ y_i $ is the ith y value (a scalar)  \n",
    "$ x_i $ is a row vector of two values in this case (X has two columns): [$x_{i,0}$, $x_{i,1}$]  \n",
    "$ \\beta $ is a column vector of the coefficents: $[\\beta_0, \\beta_1]^T$  \n",
    "$ x_i \\cdot \\beta $ is the dot product of these two vectors, yielding a scalar\n",
    "\n",
    "After you have the single row gradient figured out, how would you use all the rows to accumulate (i.e. add) the gradients for $\\beta_1$ and $\\beta_2$?  \n",
    "**Hint: an efficient solution uses the transpose of one of the matrices and the dot product**\n",
    "\n",
    "Put the gradient in a function that will return the gradient vector for given X, betas, and y. This vector should have the same shape as your coefficient array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad_func(X, beta_guess, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for solution...\n",
    "</summary>\n",
    "```\n",
    "def mse_grad_func(X, beta_guess, y):\n",
    "    return np.dot(X.T, np.dot(X, beta_guess)-y)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Adjust weights/parameters by the gradient of the cost function scaled by the learning rate** Update the betas given the gradient of the cost function that was just computed, scaled by the learning rate. This is gradient DESCENT, so we should subtract our update. \n",
    "\n",
    "Write a function that performs a parameter update and returns updated parameters (This is very simple - should be a one liner, use numpy. DO NOT OVERTHINK THIS!). Since our problem is simple, the default learning rate is (relatively) high at 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramater_update(betas, grad, lr=0.02):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for solution...\n",
    "</summary>\n",
    "```\n",
    "def paramater_update(betas, grad, lr=0.02):\n",
    "    return betas - lr * grad\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Compute objective function, a.k.a the cost function**  \n",
    "We've done this. We are doing a linear regression, so we will use the mean squared error cost function. \n",
    "$$ J(\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i - h_\\theta(x_i))^2 $$\n",
    "\n",
    "**4. Check for convergence**  \n",
    "More later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Using the gradient and the parameter update functions, you can perform simple gradient descent.**  \n",
    "Start with guesses for beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_guess = np.ones((2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below as many times as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "print('Iteration {}'.format(i))\n",
    "grad = mse_grad_func(X, beta_guess, y)\n",
    "print('The gradient is: {0:0.2f}, {1:0.2f}'.format(grad[0][0], grad[1][0]))\n",
    "beta_guess = paramater_update(beta_guess, grad)\n",
    "print('New values of beta: {0:0.2f}, {1:0.2f}'.format(beta_guess[0][0], beta_guess[1][0]))\n",
    "print('  Recall true beta: {0:0.2f}, {1:0.2f}'.format(true_betas[0][0], true_betas[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together! \n",
    "\n",
    "If you have done your math right, this should be a step in the right direction. But it takes some iterating to get to the correct answer. \n",
    "\n",
    "Write a function with a for loop below to perform the full gradient descent. Experiment with values of max_iter to see how long it takes to converge to the correct parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_gradient_descent(X, y, beta_guess = np.ones((2,1)), lr = .02, max_iter = 100): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for solution...\n",
    "</summary>\n",
    "```\n",
    "def simple_gradient_descent(X, y, beta_guess = np.ones((2,1)), lr = .02, max_iter = 100): \n",
    "    for i in range(max_iter):\n",
    "        grad = mse_grad_func(X, beta_guess, y)\n",
    "        beta_guess = paramater_update(beta_guess, grad)\n",
    "    return beta_guess\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did you get the right betas?\n",
    "betas = simple_gradient_descent(X, y)\n",
    "print(\"Calculated betas: {}\".format(np.around(betas.ravel(), decimals = 2)))\n",
    "print(\"      True betas: {}\".format(np.around(true_betas.ravel(), decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Convergence Criterion\n",
    "We did the simplest case of convergence criteria, a set number of iterations. In practice, you would want to use a more sophisticated convergence criterion - i.e. stopping iterations when your result stops significantly improving.\n",
    "\n",
    "Copy and paste your function from above into the second block below, but improve it by adding the following stopping criteria in addition to maximum iterations. Feel free to adjust the default paramaters if you don't like the results.\n",
    "\n",
    "* Change in cost function $ (cost_{old} - cost_{new}) / cost_{old} < \\epsilon $\n",
    "\n",
    "The stopping criteria requires the cost to be calculated.  Write a function to do that in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your cost function here (hint - see Gradient Descent Step 3)\n",
    "def cost_function(X, y, beta_guess):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for solution...\n",
    "</summary>\n",
    "```\n",
    "def cost_function(X, y, beta_guess):\n",
    "    return 1/X.shape[0] * np.sum((y - np.dot(X, beta_guess))**2)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_with_conv(X, y, beta_guess = np.ones((2,1)), lr = .02, max_iter = 10000, epsilon = 0.01): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for solution...\n",
    "</summary>\n",
    "```\n",
    "def gradient_descent_with_conv(X, y, beta_guess = np.ones((2,1)), lr = .02, max_iter = 10000, epsilon = 0.001): \n",
    "    cost_array = []\n",
    "    for i in range(max_iter):\n",
    "        cost_new = cost_function(X, y, beta_guess)\n",
    "        cost_array.append(cost_new)\n",
    "        if i > 2:\n",
    "            cost_old = cost_array[-2]\n",
    "            if abs(cost_old - cost_new)/cost_old < epsilon:\n",
    "                print('Convergence met at iteration {0}.'.format(i))\n",
    "                break\n",
    "        grad = mse_grad_func(X, beta_guess, y)\n",
    "        beta_guess = paramater_update(beta_guess, grad)\n",
    "    return beta_guess\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = gradient_descent_with_conv(X, y)  # you may need to play with the learning rate, max_iter, and epsilon\n",
    "print(\"Calculated betas: {}\".format(np.around(betas.ravel(), decimals = 2)))\n",
    "print(\"      True betas: {}\".format(np.around(true_betas.ravel(), decimals = 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
