{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "    · Write down and explain NMF equation\n",
    "    · Compare and contrast NMF, SVD, PCA and K-means\n",
    "    · Implement Alternating Least Squares algorithm\n",
    "    · Use NMF to find and interpret latent topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "    · Problems with SVD for topic analysis\n",
    "    · Introduce NMF\n",
    "    · Review solving linear equations\n",
    "    · Alternating Least Sqaures\n",
    "    · NMF for topic analysis example\n",
    "    · Pair exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic analysis\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's look at users ratings of different movies. The ratings are from 1-5. A rating of 0 means the user hasn't watched the movie.\n",
    "\n",
    "|       | Matrix | Alien | StarWars | Casablanca | Titanic |\n",
    "| ----- | ------ | ----- | -------- | ---------- | ------ |\n",
    "| **Alice** |      1 |     2 |        2 |          0 |      0 |\n",
    "|   **Bob** |      3 |     5 |        5 |          0 |      0 |\n",
    "| **Cindy** |      4 |     4 |        4 |          0 |      0 |\n",
    "|   **Dan** |      5 |     5 |        5 |          0 |      0 |\n",
    "| **Emily** |      0 |     2 |        0 |          4 |      4 |\n",
    "| **Frank** |      0 |     0 |        0 |          5 |      5 |\n",
    "|  **Greg** |      0 |     1 |        0 |          2 |      2 |\n",
    "\n",
    "Note that the first three movies (Matrix, Alien, StarWars) are Sci-fi movies and the last two (Casablanca, Titanic) are Romance. We will be able to mathematically pull out these topics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = np.array([[1, 2, 2, 0, 0],\n",
    "              [3, 5, 5, 0, 0],\n",
    "              [4, 4, 4, 0, 0],\n",
    "              [5, 5, 5, 0, 0],\n",
    "              [0, 2, 0, 4, 4],\n",
    "              [0, 0, 0, 5, 5],\n",
    "              [0, 1, 0, 2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try and pull out the topics with SVD\n",
    "from numpy.linalg import svd\n",
    "k = 2\n",
    "\n",
    "movies = ['Matrix','Alien','StarWars','Casablanca','Titanic']\n",
    "users = ['Alice','Bob','Cindy','Dan','Emily','Frank','Greg']\n",
    "\n",
    "# Compute SVD\n",
    "U, sigma, VT = svd(M)\n",
    "\n",
    "# Make pretty\n",
    "U, sigma, VT = (np.around(x,2) for x in (U,sigma,VT))\n",
    "U = pd.DataFrame(U, index=users)\n",
    "VT = pd.DataFrame(VT, columns=movies)\n",
    "\n",
    "# Keep top two concepts\n",
    "U = U.iloc[:,:k]\n",
    "sigma = sigma[:k]\n",
    "VT = VT.iloc[:k,:]\n",
    "\n",
    "print U\n",
    "print sigma\n",
    "print VT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. What do the concepts mean?\n",
    "2. To which concept(s) does each user/document belong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print answers[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with SVD for topic analysis\n",
    "\n",
    "**Recall:** $M = U S V^T$\n",
    "\n",
    "1. The number of columns in $U$ can differ from the number of rows in $V^T$. I.e. The number of latent features differs in $U$ and $V^T$, which is weird.\n",
    "\n",
    "2. Values in $U$ and $V^T$ can be negative, which is weird and hard to interpret. For example, suppose a latent feature is the genre 'Sci-fi'. This feature can be positive (makes sense), zero (makes sense), or negative (what does that mean?).\n",
    "\n",
    "3. SVD forces us to fill in missing values, then SVD models those missing values, which is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Can you think of a way to potentially factor a matrix that will respect constraints #1 and #2?\n",
    "\n",
    "We won't cover issue #3 today, but Jack may talk about it tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer goes here\n",
    "\n",
    "# Potential answers are at the bottom\n",
    "# print answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-negative Matrix Factorization (NMF)\n",
    "\n",
    "<img src='nmf.png' width = 40% />\n",
    "\n",
    "<p style=\"text-align: center;\">$r$ is the number of latent features</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion** What convenient properties in SVD do we lose when using non-negative matrix factorization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer goes here\n",
    "\n",
    "# Potential answers are at the bottom\n",
    "# print answers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "### System of Linear Equations Exact Solver\n",
    "$$ Ax = b$$\n",
    "\n",
    "$$ \\begin{bmatrix} 1 & 2 \\\\ -3 & 4 \\end{bmatrix} \\left[ \\begin{array}{c} x_1 \\\\ x_2 \\end{array} \\right] = \\left[ \\begin{array}{cc} 7 \\\\ -9 \\end{array} \\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [-3, 4]])\n",
    "b = np.array([7, -9])\n",
    "\n",
    "print np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares Solver\n",
    "\n",
    "What if we have an overdetermined system of linear equations? E.g.\n",
    "\n",
    "$$ \\begin{bmatrix} 1 & 2 \\\\ -3 & 4 \\\\ 1 & -4 \\end{bmatrix} \\left[ \\begin{array}{c} x_1 \\\\ x_2 \\end{array} \\right] = \\left[ \\begin{array}{cc} 7 \\\\ -9 \\\\ 17 \\end{array} \\right] $$\n",
    "\n",
    "An exact solution is not guaranteed, so we must do something else. Least Squares dictates that we find the $x$ that minimizes the residual sum of squares (RSS).\n",
    "\n",
    "(Note: This is the solver we use when doing Linear Regression!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [-3, 4], [1, -4]])\n",
    "b = np.array([7, -9, 17])\n",
    "\n",
    "print np.linalg.lstsq(A, b)[0]\n",
    "print \"Residual sum of squares (error): {}\".format(np.linalg.lstsq(A, b)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Least Squares Solver\n",
    "\n",
    "What if you want to constrain the solution to be non-negative?\n",
    "\n",
    "We have optomizers for that too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import nnls\n",
    "\n",
    "A = np.array([[1, 2], [3, 4], [1, 4]])\n",
    "b = np.array([7, 2, 4])\n",
    "\n",
    "# A = np.array([[1, 2], [-3, 4], [1, -4]])\n",
    "# b = np.array([7, -9, 17])\n",
    "\n",
    "print nnls(A, b)[0]\n",
    "print \"Residual sum of squares (error): {}\".format(nnls(A, b)[1] ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Alternating Leasts Squares\n",
    "\n",
    "**Question** Given a matrices $A$ and $B$, leasts squares and non-negative least squares find the solution $X$ that minimizes the error (RSS) in $A * X = B$. So can you guess what alternating least squares is, and how may we apply it to NMF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.choice(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print answers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement the first two steps of alternating least squares\n",
    "\n",
    "# Set up our matrix V we want to decompose\n",
    "V = np.random.rand(10,15)\n",
    "\n",
    "# Initialize a random matrix W\n",
    "W = np.random.rand(10,5)\n",
    "\n",
    "# Solve for H using a least squares solver\n",
    "H = np.linalg.lstsq(W, V)[0]\n",
    "\n",
    "# Clip H so there are no negative values\n",
    "H[H < 0] = 0\n",
    "\n",
    "# Print the current error. Why did the error go up?\n",
    "print np.linalg.norm(V - np.dot(W,H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solve for W using H\n",
    "W = np.linalg.lstsq(H, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dang that blew up... Let's do some math to figure out why and what we could have done\n",
    "\n",
    "**Question** np.linalg.lstsq(W, V) solves $W * H = V$. To solve for W we need to solve $H * W = V$ which is invalid due to the dimensions of H and W. What can we do to our matrices to make this fix this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print random.choice(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print answers[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Using the answer provided, go ahead and solve for W and print out the new error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Error should be lower than the error we established above\n",
    "W = solve_for_w(H, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat solving for H in terms of W and W in terms of H until\n",
    "# you are \"satisfied\" with your result (low enough error) or reach some\n",
    "# maximum number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General vs. non-negative least squares solver\n",
    "\n",
    "Non-negative least squares solver:\n",
    "    \n",
    "    · Returns result with least squares error given non-negativity constraint\n",
    "    · While alternating, converges to a local minimum\n",
    "    · Orders of magnitude slower than general least squares solver\n",
    "\n",
    "General least squares solver:\n",
    "    \n",
    "    · Returns result with least squares error with no constraints\n",
    "    · While alternating, converges to a stationary point (saddle point or minimum)\n",
    "    · Much much faster\n",
    "    · Have to clip the matrix at every iteration to ensure non-negativity\n",
    "   \n",
    "In industry the general least squares solver is commonly used. The tradeoff between speed and strong convergence seems to be worth it. For more information check out: http://users.wfu.edu/plemmons/papers/BBLPP-rev.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF for topic analysis\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's look at users ratings of different movies. The ratings are from 1-5. A rating of 0 means the user hasn't watched the movie.\n",
    "\n",
    "|       | Matrix | Alien | StarWars | Casablanca | Titanic |\n",
    "| ----- | ------ | ----- | -------- | ---------- | ------ |\n",
    "| **Alice** |      1 |     2 |        2 |          0 |      0 |\n",
    "|   **Bob** |      3 |     5 |        5 |          0 |      0 |\n",
    "| **Cindy** |      4 |     4 |        4 |          0 |      0 |\n",
    "|   **Dan** |      5 |     5 |        5 |          0 |      0 |\n",
    "| **Emily** |      0 |     2 |        0 |          4 |      4 |\n",
    "| **Frank** |      0 |     0 |        0 |          5 |      5 |\n",
    "|  **Greg** |      0 |     1 |        0 |          2 |      2 |\n",
    "\n",
    "Note that the first three movies (Matrix, Alien, StarWars) are Sci-fi movies and the last two (Casablanca, Titanic) are Romance. We will be able to mathematically pull out these topics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def fit_nmf(r):\n",
    "    nmf = NMF(n_components=r)\n",
    "    nmf.fit(M)\n",
    "    W = nmf.transform(M)\n",
    "    H = nmf.components_\n",
    "    return nmf.reconstruction_err_\n",
    "\n",
    "error = [fit_nmf(i) for i in range(1,6)]\n",
    "plt.plot(range(1,6), error)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Reconstruction Errror')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What might be the optimal r (number of topics) value and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print random.choice(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print answers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit using 2 hidden concepts\n",
    "nmf = NMF(n_components=2)\n",
    "nmf.fit(M)\n",
    "W = nmf.transform(M)\n",
    "H = nmf.components_\n",
    "print 'RSS = %.2f' % nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make interpretable\n",
    "W, H = (np.around(x,2) for x in (W,H))\n",
    "W = pd.DataFrame(W,index=users)\n",
    "H = pd.DataFrame(H,columns=movies)\n",
    "\n",
    "print W \n",
    "print H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interpreting Concepts\n",
    "\n",
    "**Rethink this part**\n",
    "#### Think of NMF like 'fuzzy clustering'\n",
    "- The concepts are like clusters\n",
    "- Each row (document, user, etc...) can belong to more than one concept\n",
    "\n",
    "**Discussion**\n",
    "1. What do the concepts (clusters) mean?\n",
    "2. To which concept(s) does each user/document belong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print answers[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify reconstruction\n",
    "print np.around(W.dot(H),2)\n",
    "print pd.DataFrame(M, index=users, columns=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is concept 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 2 movies in genre 0\n",
    "top_movies = H.iloc[0].sort_values(ascending=False).index[:3]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which users align with concept 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 2 users for genre 1\n",
    "top_users = W.iloc[:,0].sort_values(ascending=False).index[:2]\n",
    "top_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What concepts does Emily align with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W.loc['Emily']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are all the movies in each concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of movies in each concept\n",
    "thresh = .2  # movie is included if at least 20% of max weight\n",
    "for g in range(2):\n",
    "    all_movies = H.iloc[g,:]\n",
    "    included = H.columns[all_movies >= (thresh * all_movies.max())]\n",
    "    print \"Concept %i contains: %s\" % (g, ', '.join(included))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which users are associated with each concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Users in each concept\n",
    "thresh = .2  # user is included if at least 20% of max weight\n",
    "for g in range(2):\n",
    "    all_users = W.iloc[:,g]\n",
    "    included = W.index[all_users >= (thresh * all_users.max())]\n",
    "    print \"Concept %i contains: %s\" % (g, ', '.join(included))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zipfian/topicmodeling/blob/master/pair.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions and lists\n",
    "(Not part of the material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answers = [\"One approach we could try is to limit S to be a square matrix and \" +\n",
    "           \"enforce positivity requirements on all matrices (including M). If this were \" +\n",
    "           \"possible, then we could multiply S into U or V which may result in the \" +\n",
    "           \"decomposition M = H * W with everything being positive.\",\n",
    "           \n",
    "           \"SVD is nice because it has a closed form solution that will always exist. \" +\n",
    "           \"NMF on the other hand does not. NMF can be approximated through various \" +\n",
    "           \"numerical techniques. \" +\n",
    "           \"Today we will using alternating least squares.\",\n",
    "           \n",
    "           \"Alternating least squares solves the least squares equation for H while \" +\n",
    "           \"leaving W fixed, then solves the least squares equation for W while \" +\n",
    "           \"leaving H fixed. This process continues and alternates until either \" +\n",
    "           \"the error is reduced to some amount or you hit some number of max iterations\",\n",
    "           \n",
    "           \"We can solve the equation (W * H).T = V.T or H.T * W.T = V.T for W.T. We just \" +\n",
    "           \"need to remember to transpose our final answer.\",\n",
    "           \n",
    "           \"At r = 2 there is a significant change in the amount of benefit we are \" +\n",
    "           \"gaining from adding aditional features. At higher r values, we will end up \" +\n",
    "           \"be adding dimensions that don't necessarily help much. In a modeling sense \" +\n",
    "           \"this would be similar to overfitting our data. This is typically not a problem \" +\n",
    "           \"though since we are using NMF in the first place to do dimensionality reduciton.\",\n",
    "           \n",
    "           \"There are no perfect answers here. The problem is that there are positive and \" +\n",
    "           \"negative values and it is really hard to interpret what they mean exactly. \" +\n",
    "           \"Should we be looking at the absolute value of the numbers, or maybe just the \" +\n",
    "           \"max without considering the sign? There seem to be issues with both of those \" +\n",
    "           \"approaches. Maybe something more sofisticated would work, or maybe we should \" +\n",
    "           \"just use a different tool...\",\n",
    "           \n",
    "           \"Here all of the values are positive. A large positive number can be \" +\n",
    "           \"interpretted as an item belonging to a certain topic. We can then look at the \" +\n",
    "           \"items that belong to a topic and make some sort of best guess as to what the \" +\n",
    "           \"topics are. These guesses will be heavily influenced by the type of data that \" +\n",
    "           \"populated the original matrix as well as the business question we are trying to \" +\n",
    "           \"answer.\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "students = [\"Suresh\",\"Sally\",\"Corbin\",\"Danius\",\"David\",\"Dustin\",\"Eduardo\",\"Evan\",\"Grier\",\"Jane\",\"Jared\",\"Jonathan T.\",\"Jonathan B.\",\"Kathy\",\"Morgan\",\"Nicholas \",\"Rob D.\",\"Rob W.\",\"Rob F. \",\"Sal\",\"Scott\",\"Sean \",\"Stefanie\",\"Sydney\",\"Zane\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_for_w(H, v):\n",
    "    # Solve for W leaving H fixed\n",
    "    W = np.linalg.lstsq(H.T, V.T)[0].T\n",
    "\n",
    "    # Clip W so there are no negative values\n",
    "    W[W < 0] = 0\n",
    "    \n",
    "    print np.linalg.norm(V - np.dot(W,H))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
