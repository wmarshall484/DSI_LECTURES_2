{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    " * define \"topic modeling\"\n",
    " * use matrix factorization find a reduced-dimension approximation to the data\n",
    " * interpret the new dimensions as vectors that group together the original features into \"latent topics\" or \"latent features\"\n",
    " * implement an alternating-least-squares algorithm to solve NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is topic modeling?\n",
    "\n",
    "Say we have a matrix of word count vectors for a large corpus of **unlabeled documents**\n",
    "\n",
    "|doc_id | word_1 | word_2 | ... | word_10000 |\n",
    "|--|--|--|--|--|\n",
    "|**1**|0|11|...|0|\n",
    "|**2**|0|0|...|0|\n",
    "|**3**|0|3|...|2|\n",
    "\n",
    "How could we find out what these documents are _about_? Even though we don't have labels for these documents, is there a way to sort out documents about sports from documents about music? Is there a way to discover **latent (hidden) topics** in the corpus?\n",
    "\n",
    "Topic modeling is a kind of **unsupervised learning**: an attempt to distinguish structure in unlabeled data. \n",
    "\n",
    "Today we'll see a mathematical transformation that turns the above feature matrix into something like the below:\n",
    "\n",
    "- a new, reduced-dimension feature matrix where the features are \"topic weights\"\n",
    "\n",
    "|doc_id | topic_A | topic_B | topic_C |\n",
    "|--|--|--|--|\n",
    "|**1**|0.2|0.1|1.1|\n",
    "|**2**|1.3|0|0.4|\n",
    "|**3**|0.4|1.4|0.2|\n",
    "\n",
    "- a matrix of word (original feature) to topic (latent feature) weights\n",
    "\n",
    "| &nbsp; | word_1 | word_2 | ... | word_10000 |\n",
    "|--|--|--|--|--|\n",
    "|**topic_A**|0.01|0|...|0|\n",
    "|**topic_B**|0.2|0.1|...|0.3|\n",
    "|**topic_C**|0|1.3|...|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this give us?\n",
    "- Each document has a strength of association with each topic. This is a **soft clustering** of documents into topics.\n",
    "- Each word has a weight associated with each topic; the topics also represent clusters of features (words).\n",
    "\n",
    "#### What does this lack?\n",
    "- We still don't know what each topic **is**. This still requires a human to read the words associated with each topic and assign some kind of label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: unbaking a cake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you have the following information:\n",
    "- a cake recipe that says \"2 cups flour, 1 cup brown sugar\"\n",
    "- nutritional facts for flour and sugar:\n",
    "  - \"1 cup of flour contains 90g carbohydrates, 13g protein, 1g fat\"\n",
    "  - \"1 cup of brown sugar contains 200g carbohydrates, 1g protein, 0g fat\"\n",
    "\n",
    "How do you get the nutritional content of the cake? Easy: linear algebra. The cake is a linear combination of ingredients, and each ingredient is a linear combination of nutrients.\n",
    "\n",
    "Let's call the recipe vector $\\vec{w} = \\begin{bmatrix} w_{flour} & w_{sugar} \\end{bmatrix} = \\begin{bmatrix} 2 & 1 \\end{bmatrix} $\n",
    "\n",
    "And let's make a matrix of the nutritional content of each ingredient:\n",
    "$$ H = \\begin{bmatrix} f_{carb} & f_{prot} & f_{fat} \\\\ s_{carb} & s_{prot} & s_{fat} \\end{bmatrix} = \n",
    "\\begin{bmatrix} 90 & 13 & 1 \\\\ 200 & 1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "then the cake vector is\n",
    "$$ \\vec{v} = \\begin{bmatrix} v_{carb} & v_{prot} & v_{fat} \\end{bmatrix} \n",
    "= \\vec{w}H \n",
    "=\\begin{bmatrix} 2 & 1 \\end{bmatrix} \n",
    "\\begin{bmatrix} 90 & 13 & 1 \\\\ 200 & 1 & 0 \\end{bmatrix}\n",
    "= \\begin{bmatrix} 380 & 27 & 2 \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know this seems trivial so far, but bear with me. Say we had many different recipes: $\\vec{w_1}, \\vec{w_2}, \\ldots$. Each would give a different cake: $\\vec{v_1}, \\vec{v_2}, \\ldots$. We can write all this in matrix form: $V = WH$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "    v_{1,carb}   & v_{1,prot} & v_{1,fat}\\\\\n",
    "    v_{2,carb}   & v_{2,prot} & v_{2,fat}\\\\\n",
    "    v_{3,carb}   & v_{3,prot} & v_{3,fat}\\\\\n",
    "    \\vdots       & \\vdots & \\vdots\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    w_{1,flour}  & w_{1,sugar} \\\\\n",
    "    w_{2,flour}  & w_{2,sugar} \\\\\n",
    "    w_{3,flour}  & w_{3,sugar} \\\\\n",
    "    \\vdots       & \\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "f_{carb} & f_{prot} & f_{fat} \\\\ s_{carb} & s_{prot} & s_{fat} \n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem 1: unknown recipes\n",
    "Say we know the nutritional information for each cake, but we don't know the recipes. In fact, the true recipes might even contain other ingredients. Can we solve for a \"best guess\" flour & sugar recipe for each cake?\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "    290   & 14 & 1\\\\\n",
    "    380   & 27 & 1\\\\\n",
    "    120   & 7 & 0.5\\\\\n",
    "    \\vdots       & \\vdots & \\vdots\n",
    "\\end{bmatrix}\n",
    "\\approx\n",
    "\\begin{bmatrix}\n",
    "    w_{1,flour}  & w_{1,sugar} \\\\\n",
    "    w_{2,flour}  & w_{2,sugar} \\\\\n",
    "    w_{3,flour}  & w_{3,sugar} \\\\\n",
    "    \\vdots       & \\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "90 & 13 & 1 \\\\ \n",
    "200 & 1 & 0\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impossibility of an exact solution become apparent when we try to solve for $\\vec{w_2}$\n",
    "$$\n",
    "\\begin{align}\n",
    "380 &= 90w_{2f} + 200w_{2s} \\\\\n",
    "27 &= 13w_{2f} + 1w_{2s} \\\\\n",
    "1 &= 1w_{2f} + 0w_{2s} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an overdetermined system of equations. There is no set of values for $w_{2f},w_{2s}$ that will make all three equations true. So let's get as close as possible using a \"least squares\" estimate.\n",
    "\n",
    "Let $$\\vec{v_2}_{true} = \\begin{bmatrix} 380 \\\\ 27 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "and our estimate \n",
    "$$\\hat{\\vec{v_2}} = \n",
    "\\begin{bmatrix} \n",
    "90 & 200  \\\\ \n",
    "13 & 1  \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "w_{2,flour}  \\\\ \n",
    "w_{2,sugar} \\\\\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares estimate for $\\vec{w_2}$ is the vector that minimizes the squared error\n",
    "$$ ||\\vec{v_2}_{true} - \\hat{\\vec{v_2}}|| = \\sum_{i\\in\\{f,c,p\\}}(v_{2true, i} - \\hat{v}_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky for us, least squares optimization is an ancient problem. Let's use the implementation in `numpy.linalg.lstsq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return the least-squares solution to a linear matrix equation.\n",
       "\n",
       "Solves the equation `a x = b` by computing a vector `x` that\n",
       "minimizes the Euclidean 2-norm `|| b - a x ||^2`.  The equation may\n",
       "be under-, well-, or over- determined (i.e., the number of\n",
       "linearly independent rows of `a` can be less than, equal to, or\n",
       "greater than its number of linearly independent columns).  If `a`\n",
       "is square and of full rank, then `x` (but for round-off error) is\n",
       "the \"exact\" solution of the equation.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : (M, N) array_like\n",
       "    \"Coefficient\" matrix.\n",
       "b : {(M,), (M, K)} array_like\n",
       "    Ordinate or \"dependent variable\" values. If `b` is two-dimensional,\n",
       "    the least-squares solution is calculated for each of the `K` columns\n",
       "    of `b`.\n",
       "rcond : float, optional\n",
       "    Cut-off ratio for small singular values of `a`.\n",
       "    For the purposes of rank determination, singular values are treated\n",
       "    as zero if they are smaller than `rcond` times the largest singular\n",
       "    value of `a`.\n",
       "\n",
       "    .. versionchanged:: 1.14.0\n",
       "       If not set, a FutureWarning is given. The previous default\n",
       "       of ``-1`` will use the machine precision as `rcond` parameter,\n",
       "       the new default will use the machine precision times `max(M, N)`.\n",
       "       To silence the warning and use the new default, use ``rcond=None``,\n",
       "       to keep using the old behavior, use ``rcond=-1``.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "x : {(N,), (N, K)} ndarray\n",
       "    Least-squares solution. If `b` is two-dimensional,\n",
       "    the solutions are in the `K` columns of `x`.\n",
       "residuals : {(1,), (K,), (0,)} ndarray\n",
       "    Sums of residuals; squared Euclidean 2-norm for each column in\n",
       "    ``b - a*x``.\n",
       "    If the rank of `a` is < N or M <= N, this is an empty array.\n",
       "    If `b` is 1-dimensional, this is a (1,) shape array.\n",
       "    Otherwise the shape is (K,).\n",
       "rank : int\n",
       "    Rank of matrix `a`.\n",
       "s : (min(M, N),) ndarray\n",
       "    Singular values of `a`.\n",
       "\n",
       "Raises\n",
       "------\n",
       "LinAlgError\n",
       "    If computation does not converge.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "If `b` is a matrix, then all array results are returned as matrices.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Fit a line, ``y = mx + c``, through some noisy data-points:\n",
       "\n",
       ">>> x = np.array([0, 1, 2, 3])\n",
       ">>> y = np.array([-1, 0.2, 0.9, 2.1])\n",
       "\n",
       "By examining the coefficients, we see that the line should have a\n",
       "gradient of roughly 1 and cut the y-axis at, more or less, -1.\n",
       "\n",
       "We can rewrite the line equation as ``y = Ap``, where ``A = [[x 1]]``\n",
       "and ``p = [[m], [c]]``.  Now use `lstsq` to solve for `p`:\n",
       "\n",
       ">>> A = np.vstack([x, np.ones(len(x))]).T\n",
       ">>> A\n",
       "array([[ 0.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 2.,  1.],\n",
       "       [ 3.,  1.]])\n",
       "\n",
       ">>> m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
       ">>> print(m, c)\n",
       "1.0 -0.95\n",
       "\n",
       "Plot the data along with the fitted line:\n",
       "\n",
       ">>> import matplotlib.pyplot as plt\n",
       ">>> plt.plot(x, y, 'o', label='Original data', markersize=10)\n",
       ">>> plt.plot(x, m*x + c, 'r', label='Fitted line')\n",
       ">>> plt.legend()\n",
       ">>> plt.show()\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.linalg.lstsq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[380],\n",
       "       [ 27],\n",
       "       [  1]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtrue = np.array([[380],[27],[1]])\n",
    "vtrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtrue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90,  13,   1],\n",
       "       [200,   1,   0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = np.array([[90,13,1],[200,1,0]])\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90, 200],\n",
       "       [ 13,   1],\n",
       "       [  1,   0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.99369079],\n",
       "        [1.00284112]]),\n",
       " array([0.99369079]),\n",
       " 2,\n",
       " array([219.40669262,  11.47620288]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(H.T, vtrue, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_t, resid, rank, singular_values = np.linalg.lstsq(H.T, vtrue, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99369079],\n",
       "       [1.00284112]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99369079, 1.00284112]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_t.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99369079])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[380.00039589],\n",
       "       [ 26.92082145],\n",
       "       [  1.99369079]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vhat = H.T.dot(w)\n",
    "vhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[380],\n",
       "       [ 27],\n",
       "       [  1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtrue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this with the whole matrix of cakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[290. ,  14. ,   1. ],\n",
       "       [380. ,  27. ,   1. ],\n",
       "       [120. ,   7. ,   0.5]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.array([[290, 14, 1],[380,27,1],[120,7,0.5]])\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90,  13,   1],\n",
       "       [200,   1,   0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT, _, _, _ = np.linalg.lstsq(H.T, V.T, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        ],\n",
       "       [1.99369079, 1.00284112],\n",
       "       [0.50989732, 0.37054623]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WT.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _moral of story: yes, we can solve for unknown recipes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem 2: known recipes, unknown ingredient nutrition\n",
    "We know the cake nutritional content and the recipes. Can we deduce the ingredient nutritional content?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "    290   & 14 & 1\\\\\n",
    "    380   & 27 & 1\\\\\n",
    "    120   & 7 & 0.5\\\\\n",
    "    \\vdots       & \\vdots & \\vdots\n",
    "\\end{bmatrix}\n",
    "\\approx\n",
    "\\begin{bmatrix}\n",
    "    2  & 2 \\\\\n",
    "    2  & 1 \\\\\n",
    "    1  & 2 \\\\\n",
    "    \\vdots       & \\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "f_{carb} & f_{prot} & f_{fat} \\\\ s_{carb} & s_{prot} & s_{fat} \n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we'll have a big system of equations needing a least squares estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[290. ,  14. ,   1. ],\n",
       "       [380. ,  27. ,   1. ],\n",
       "       [120. ,   7. ,   0.5]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 1],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.array([[2,2],[2,1],[1,2]])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[208.23529412,  14.64705882,   0.5       ],\n",
       "       [-51.76470588,  -5.35294118,   0.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H, _, _, _ = np.linalg.lstsq(W, V, rcond=None)\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, negative nutritional content doesn't really make sense, does it? Let's hold that thought for a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem 3 (the cool one): both unknown\n",
    "We know the nutritional content of the cake, but we don't know the recipes or the ingredient nutrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "    290   & 14 & 1\\\\\n",
    "    380   & 27 & 1\\\\\n",
    "    120   & 7 & 0.5\\\\\n",
    "    \\vdots       & \\vdots & \\vdots\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    w_{1,flour}  & w_{1,sugar} \\\\\n",
    "    w_{2,flour}  & w_{2,sugar} \\\\\n",
    "    w_{3,flour}  & w_{3,sugar} \\\\\n",
    "    \\vdots       & \\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "f_{carb} & f_{prot} & f_{fat} \\\\ s_{carb} & s_{prot} & s_{fat} \n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like too many unknowns. But here's an approach that turns out to work pretty well: **alternating least squares (ALS)**:\n",
    "\n",
    "- initialize $W$ and $H$ full of random numbers\n",
    "- Hold $H$ constant and solve for $W$ using least-squares. Set any negative values to 0.\n",
    "- Now hold $W$ constant and solve for $H$, again clipping negative values to 0.\n",
    "- Repeat the last two steps until you have converged on a solution\n",
    "\n",
    "This process is not globally convex, meaning that if you run it twice, you may get different values for $W$ and $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the factor matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ V \\approx WH $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V$ is the data: an $(n \\times p)$ matrix ($n$ rows, $p$ features)\n",
    "\n",
    "$W$ is an $(n \\times k)$ matrix mapping *rows* to *topics (latent features)*\n",
    "\n",
    "$H$ is a $(k \\times p)$ matrix mapping *topics (latent features)* to *features*\n",
    "\n",
    "Note that $k$, the number of topics (latent features), is a **hyperparameter**: you have to pick it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cake example above, we could observe the nutritional information for each cake (carbs, protein, fat), but we knew that there was some other process for constructing cakes, some smaller set of latent features (\"ingredients\"), where each latent feature is a linear combination of the raw features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the text example, we observe the word counts for each document, but we know that documents tend to be about certain topics, and different topics will have different counts for certain groups of words. NMF gives us topics as linear combinations of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other uses\n",
    "- image processing: treat each image as a \"bag of pixels\", a single long vector where each pixel is a feature and its value is its intensity. Running NMF on a corpus of images of faces can find the latent features (which, remember, are just linear combinations of raw features) that represent noses, ears, etc. [See this paper](references/1999-Lee-Seung-Learning-Parts-of-Objects-by-NMF.pdf)\n",
    "- bioinformatics\n",
    "- \"music structure\": [see this paper](http://www.mirlab.org/conference_papers/international_conference/ISMIR%202010/ISMIR_2010_papers/ismir2010-73.pdf)\n",
    "- recommendation systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
