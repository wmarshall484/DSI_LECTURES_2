{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from stringstamper import StringStamper\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Oriented Programming and Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we will be using the `sklearn` library to give examples of how object oriented programming is used in practice.  Our objective is not so much to learn about `sklearn`, but to explore how a professionally developed, widely used library uses the organizational principles of object oriented programming to provide a good user experience.\n",
    "\n",
    "The main theme of our explorations will be the power of **Providing a Consistent Interface**.\n",
    "\n",
    "One of the fundamental commandments of OOP is:\n",
    "\n",
    "> Program to an interface instead of an implementation.\n",
    "\n",
    "Sklearn is a stellar example of this important programming philosophy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Example: The String Stamper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our exploration, let's review the basic concepts of object oriented programming using a simple `class` I wrote called `StringStamper`.\n",
    "\n",
    "Here's how string stamper works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hobbit. Property of Matt.\n",
      "The Lord of the Rings. Property of Matt.\n",
      "The Hobbit. Property of Jack.\n",
      "The Lord of the Rings. Property of Jack.\n"
     ]
    }
   ],
   "source": [
    "# Create a new object:\n",
    "ss_matt = StringStamper(message=\"Property of Matt.\")\n",
    "\n",
    "# Use the object to stamp something:\n",
    "print(ss_matt.stamp(\"The Hobbit.\"))\n",
    "\n",
    "# Use the SAME object to stamp a different thing:\n",
    "print(ss_matt.stamp(\"The Lord of the Rings.\"))\n",
    "\n",
    "# Create a DIFFERENT string stamper object:\n",
    "ss_jack = StringStamper(message=\"Property of Jack.\")\n",
    "\n",
    "# Jack has a different copy of the hobbit.\n",
    "print(ss_jack.stamp(\"The Hobbit.\"))\n",
    "print(ss_jack.stamp(\"The Lord of the Rings.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "- What things above can be considered *objects* in python?\n",
    "- What things above can be considered *classes*?\n",
    "- Where did we use a *constructor*, i.e. where did we create new objects?\n",
    "- What things above can be considered *methods*?\n",
    "- What is the type of `ss_matt` and `ss_jack`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code for the `StringStamper`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StringStamper:\n",
    "    \"\"\"Stamps a message on the end of a string.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    message: str\n",
    "      A message to stamp on the end of a string.\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    $ stamper = StringStamper(\"Property of Matt.\")\n",
    "    $ stamper.stamp(\"Elements of Statistical Learning.\")\n",
    "    \"Elements of Statistical Learning. Property of Matt.\"\n",
    "    \"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "    def stamp(self, string):\n",
    "        return string + \" \" + self.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "- What does the `class` keyword do here?\n",
    "- What does the `__init__` method do?\n",
    "- What does the notation `self.message = message` do?\n",
    "- What does `self` refer to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, as data scientists, we will be **consumers** of code written in an object oriented style.  So let's spend the rest of the lesson studying an important example of this style from teh `sklearn` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn and the Transformer Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sklearn](https://scikit-learn.org/stable/) or or scikit-learn is the standard library for machine learning in python.  It contains many, many tools that will take a very long time for us to explore.  Our goal for today will be to explore only a small corner of it, the [transformers](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n",
    "\n",
    "**Transformers** are tools that transform data sets.  This is a very common operation, we have some set of data, and we want to modify it in some consistent way for use in some task.  Sklearn has a very consistent way that it expresses these types of operations, and it leverages the concepts of OOP very heavily in creating a consistent user experience.\n",
    "\n",
    "Let's start with a couple of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most ubiquitous transformers is the `StandardScaler`, which is used to **standardize** a data set.\n",
    "\n",
    "A vector $x$ is said to be **standardized** if it has mean zero and standard deviation one.  If we take *any* vector, then we can transform it into a standardized one by subtracting its mean and dividing by its standard deviation.  This process is called **standardization**.\n",
    "\n",
    "$$ X_{\\text{standardized}} = \\frac{x - \\bar x}{\\text{sd}(x)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have some experience with `numpy`, then you can probably see that standardizing a numpy array is quite simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 0, 2, 2, 0, 1, 0, 2])\n",
    "x_standardized = (x - np.mean(x)) / np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and standard deviation of the standardized vector are zero and one respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of standardized vector:  0.0\n",
      "Stanard deviation of standardized vector:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of standardized vector: \", np.mean(x_standardized))\n",
    "print(\"Stanard deviation of standardized vector: \", np.std(x_standardized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to standardization is simple and understandable, which are certainly virtues!  It does start to run into some issues when used in real production machine learning code though:\n",
    "\n",
    "  - We often want to standardize many vectors together in a bundle, but use different means and standard deviations for the different vectors.  This becomes awkward with the straight numpy approach.\n",
    "  - Because of a concept called *data leakage* which we will discuss later, it is often neccessary to standardize one vector, and then use the **same** mean and standard deviation to transform other different vectors.  This requires us to memorize a bunch of means and standard deviations, and it's good to have an organizaing principle for this type of work.\n",
    "  \n",
    "Whenever we are in a situation where data transformations of some kind depend on some **parameters** (like the mean and standard deviation of the vector), the concept of object oriented programming starts to shine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn includes a class used for standardizing all of the columns in a data set.\n",
    "\n",
    "The `StandardScalar` class implements the **transformation interface**.   Here's how you use it.\n",
    "\n",
    "#### 1. Create a `StandardScalar` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standardizer = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  Fit the `StandardScaler` object to a data set.\n",
    "\n",
    "Use the `fit` method, and pass in the data set you would like to standardize.  Behind the scenes this computes and memorizes the mean and standard deviation of all the columns in the dataset.\n",
    "\n",
    "We'll use a data set about distanse to wells in bangladesh as our working example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>switch</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>dist</th>\n",
       "      <th>assoc</th>\n",
       "      <th>educ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.826000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>47.321999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>20.966999</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>21.486000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>40.874001</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    switch  arsenic       dist  assoc  educ\n",
       "id                                         \n",
       "1        1     2.36  16.826000      0     0\n",
       "2        1     0.71  47.321999      0     0\n",
       "3        0     2.07  20.966999      0    10\n",
       "4        1     1.15  21.486000      0    12\n",
       "5        1     1.10  40.874001      1    14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells = pd.read_csv('./wells.dat', sep=' ', index_col='id')\n",
    "wells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewdrury/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardizer.fit(wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "\n",
    "Notice that calling the fit method doesn't seem to really **do** much of anything.  So, what happens behind the scenes when we call the `fit` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Transform a (possibly) different data set with the `StandardScaler` object.\n",
    "\n",
    "Use the `transform` method on *any* dataset to perform the standardization (i.e., subtract the memorized mean from each column and divide by its memorized standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewdrury/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "wells_standardized = standardizer.transform(wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a **new** dataset that is a transformed version of our wells dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5c5afab460b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwells_standardized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "wells_standardized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh?\n",
    "\n",
    "This is a common issue when working with sklearn: it is designed to work with numpy arrays, but **not** data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wells_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the transformed data back into a dataframe using standard pandas techniques we've already learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wells_standardized = pd.DataFrame(wells_standardized, columns=wells.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>switch</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>dist</th>\n",
       "      <th>assoc</th>\n",
       "      <th>educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859436</td>\n",
       "      <td>0.634996</td>\n",
       "      <td>-0.818923</td>\n",
       "      <td>-0.855947</td>\n",
       "      <td>-1.202115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.859436</td>\n",
       "      <td>-0.855245</td>\n",
       "      <td>-0.026249</td>\n",
       "      <td>-0.855947</td>\n",
       "      <td>-1.202115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.163554</td>\n",
       "      <td>0.373075</td>\n",
       "      <td>-0.711287</td>\n",
       "      <td>-0.855947</td>\n",
       "      <td>1.287521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.859436</td>\n",
       "      <td>-0.457848</td>\n",
       "      <td>-0.697797</td>\n",
       "      <td>-0.855947</td>\n",
       "      <td>1.785448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859436</td>\n",
       "      <td>-0.503006</td>\n",
       "      <td>-0.193850</td>\n",
       "      <td>1.168297</td>\n",
       "      <td>2.283375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     switch   arsenic      dist     assoc      educ\n",
       "0  0.859436  0.634996 -0.818923 -0.855947 -1.202115\n",
       "1  0.859436 -0.855245 -0.026249 -0.855947 -1.202115\n",
       "2 -1.163554  0.373075 -0.711287 -0.855947  1.287521\n",
       "3  0.859436 -0.457848 -0.697797 -0.855947  1.785448\n",
       "4  0.859436 -0.503006 -0.193850  1.168297  2.283375"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_standardized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "What's going on here, why is there only two unique values of `switch` in the standardized data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85943576, -1.1635541 ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_standardized.loc[:, \"switch\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "What is the mean and standard deviation of the columns in `wells_standardized`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of column switch: -0.00\n",
      "Standard Deviation of column switch: 1.00\n",
      "Mean of column arsenic: -0.00\n",
      "Standard Deviation of column arsenic: 1.00\n",
      "Mean of column dist: 0.00\n",
      "Standard Deviation of column dist: 1.00\n",
      "Mean of column assoc: -0.00\n",
      "Standard Deviation of column assoc: 1.00\n",
      "Mean of column educ: 0.00\n",
      "Standard Deviation of column educ: 1.00\n"
     ]
    }
   ],
   "source": [
    "for name, (_, col) in zip(wells.columns, wells_standardized.T.iterrows()):\n",
    "    print(\"Mean of column {}: {:2.2f}\".format(name, col.mean()))\n",
    "    print(\"Standard Deviation of column {}: {:2.2f}\".format(name, col.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization (Binning)\n",
    "\n",
    "It is occasionally useful to take a continuous feature, and convert it into a discrete feature by binning together the value of the original feature that fall withing certain ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we start with the feature vector:\n",
    "\n",
    "$$ x = \\left( \\begin{array}{cccccccccc} 0.00 & 0.15 & 0.71 & 0.79 & 0.37 & 1.00 & 0.36 & 0.06 & 0.04 & 0.15 \\end{array} \\right) $$\n",
    "\n",
    "We may have occassion to bin this into three buckets, say:\n",
    "\n",
    "$$ B_1 = \\left( -\\infty, \\frac{1}{3} \\right\\rbrack, \\ B_2 = \\left( \\frac{1}{3}, \\frac{2}{3} \\right\\rbrack, \\ B_3 = \\left( \\frac{2}{3}, 1 \\right\\rbrack $$\n",
    "\n",
    "If we label any data point in the first bucket as a `0`, and in the second bucket as a `1`, and any in the final bucket as a `2`, then this would transform our vector into:\n",
    "\n",
    "$$ x_{\\text{bucketed}} = \\left( \\begin{array}{cccccccccc} 0 & 0 & 2 & 2 & 2 & 2 & 1 & 0 & 0 & 0 \\end{array} \\right) $$\n",
    "\n",
    "Sklearn also contains a tool for this type of operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: Sklearn tools are designed to work with *column* vectors!\n",
    "# This means you will often have to reshape(-1, 1) your row vectors into column vectors.\n",
    "x = np.array([0.00, 0.15, 0.71, 0.79, 0.37, 1.00, 0.36, 0.06, 0.04, 0.15]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a `KBinsDiscretizer` object.\n",
    "\n",
    "This time we need to supply a few parameters: the number of bins we want, and a strategy for computing the endpoints of the bins.  For information on what strategies are implemented, and how these strategies work, see [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer).\n",
    "\n",
    "**Note**: You'll find in the documentation that there is a simple strategy that sklearn has **not** implemented: the user supplying the endpoints manually!  This happens often, where a tool provides some useful things, but not the thing that you really need.  This is why it is important to get practice programming, and develop the courage to build and test your own tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Fit the KBinsDiscretizer object to a data set.\n",
    "\n",
    "This works the same way as fitting the `StandardScaler` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KBinsDiscretizer(encode='ordinal', n_bins=3, strategy='quantile')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binner.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "Again, what's going on behind the scenes when we call the `fit` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Transform a (possibly) different data set with the `KBinsDiscretizer` object.\n",
    "\n",
    "Again, this works the same way as within `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binner.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, we can transform a different array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binner.transform(np.random.uniform(size=(10, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Own Transformer: Grabbing Specific Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in our last example that we may find need to create our own transformers.  Let's try our hand by creating a simple one that simply picks out specific columns in a data set. So, for example, we should be able to use our transformers to:\n",
    "\n",
    "  - Select the first column only.\n",
    "  - Select all but the last column.\n",
    "  - Select the columns at even indexes.\n",
    "  \n",
    "  \n",
    "#### The Transformer interface.  \n",
    "\n",
    "To define a transformer, we need to define a class that implements both `fit` and `transform` methods.  This framework of \"write a class that implements certain methods\" is very, very important in object oriented programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnSelector:\n",
    "    \"\"\"Select columns out of an array or DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    idxs: np.array of int\n",
    "      The column indexes to select.\n",
    "    \"\"\"\n",
    "    def __init__(self, idxs):\n",
    "        self.idxs = np.asarray(idxs)\n",
    "        \n",
    "    # Fit here doesn't need to do anything.  We already know the indices of the columns\n",
    "    # we want to keep.\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        # Need to teat pandas data frames and numpy arrays slightly differently since the [...] \n",
    "        # indexing behaves differently for arrays and data frames.\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.iloc[:, self.idxs]\n",
    "        return X[:, self.idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few rules we need to follow:\n",
    "\n",
    "  - `fit` needs to be defined as either `fit(self, *args, **kwargs)` (if we do not need to look at the data to fit the transformer), or `fit(self, X, *args, **kwargs)` (if we *do* need to look at the data).\n",
    "  - `fit` needs to return `self`.  This is a common oversight, and will case problems when using `Pipeline` below if forgotten.\n",
    "  - `transform` needs to be defined as `transform(self, X, **transform_params)`, and returns the transformed data set.\n",
    "  \n",
    "This process, of implementing certain methods under some constraints, is called **coding to an interface**.  As long as it is done properly, it allows us to seamlessly use our objects inside of code that was designed to work with built in transformer objects.\n",
    "\n",
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the first column\n",
    "column_selector = ColumnSelector([0])\n",
    "column_selector.fit()\n",
    "wells_column_selected = column_selector.transform(wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure our new DataFrame has exactly one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>switch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    switch\n",
       "id        \n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "5        1\n",
       "6        1\n",
       "7        1\n",
       "8        1\n",
       "9        1\n",
       "10       1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_column_selected.iloc[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Objects: Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>switch</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>dist</th>\n",
       "      <th>assoc</th>\n",
       "      <th>educ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.826000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>47.321999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>20.966999</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>21.486000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>40.874001</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    switch  arsenic       dist  assoc  educ\n",
       "id                                         \n",
       "1        1     2.36  16.826000      0     0\n",
       "2        1     0.71  47.321999      0     0\n",
       "3        0     2.07  20.966999      0    10\n",
       "4        1     1.15  21.486000      0    12\n",
       "5        1     1.10  40.874001      1    14"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the neat ideas that transformers allow is **chaining**.  We can take a single input dataset and apply multiple transformations in sequence.  This process is often called **pipelining** because we have metaphorically plumbed together a sequence of transformations.\n",
    "\n",
    "The `Pipeline` class in sklearn allows us to chain together transformers, and optionally end the chain with a single regression or classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_pipeline = Pipeline([\n",
    "    # Select the columns that contain continuous data: arsenic and dist.\n",
    "    ('continuous_column_selector', ColumnSelector([1, 2])),\n",
    "    ('standardize', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have chained together some of the transformers we discussed earlier:\n",
    "\n",
    "```\n",
    "X --ColumnSelector--> X_continuous_columns \n",
    "  --StandardScalar--> X_continuous_columns_standardized \n",
    "```\n",
    "\n",
    "Once we have a `Pipeline` we only have to `fit` it **one time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('continuous_column_selector', <__main__.ColumnSelector object at 0x12e4bf748>), ('standardize', StandardScaler(copy=True, with_mean=True, with_std=True))])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_pipeline.fit(wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has **many, many advantages**.\n",
    "\n",
    "  - It allows us to write **less code**.  Every line of code we write contains potential bugs, bugs are bad.\n",
    "  - It creates a **conceptual unit**.  The `Pipeline` makes clear that each of these transformations is intended to be used **together**.  This makes the code easier to understand.\n",
    "  - It makes our code **harder to abuse**.  Since we intend the transformers to be used together, we would like other developers or our future selves to think hard about whether they want to separate them.\n",
    "  - It make the code more re-usable.  Future developers only have to do **one thing** to reuse all our transformers, instead of needing to `fit` all of them separately, this reduces the chance of mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our pipeline is fit, we can use it to transform our data set.  This applies **both** the transformers in the `Pipeline` **in sequence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63499567, -0.81892321],\n",
       "       [-0.85524506, -0.02624912],\n",
       "       [ 0.37307458, -0.71128737],\n",
       "       ...,\n",
       "       [-1.0358803 , -1.05592488],\n",
       "       [-0.9184674 , -0.66255101],\n",
       "       [-0.90040387, -0.71448445]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_pipeline.transform(wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the various transformers and regressors/classifiers by using the `named_steps` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.65693046 48.33186257]\n",
      "[ 1.10720366 38.47230347]\n"
     ]
    }
   ],
   "source": [
    "# The column means memorized by the pipeling.\n",
    "print(wells_pipeline.named_steps['standardize'].mean_)\n",
    "# The column standard deviations memorized by the pipeline.\n",
    "print(wells_pipeline.named_steps['standardize'].scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These contain the means and standard deviations of the two columns in the data set that we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of arsenic:  1.656930463576163\n",
      "Standard Deviation of arsenic:  1.1072036618468495\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of arsenic: \", np.mean(wells['arsenic']))\n",
    "print(\"Standard Deviation of arsenic: \", np.std(wells['arsenic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "\n",
    "When were these means and standard deviations computed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Custom Transformer in a Pipeline: Polynomial Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is useful to fit a **polynomial term** in a regression model (stay tuned!).  So, instead of creating a regression like\n",
    "\n",
    "$$ \\text{WingSize} \\approx a + b \\times \\text{Latitude} $$\n",
    "\n",
    "We would fit a polynomial curve, for example, a quadratic like\n",
    "\n",
    "$$ \\text{WingSize} \\approx a + b \\times \\text{Latitude} + b \\times \\text{Latitude}^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first task is to write a transformer class that consumes a **single** column, and creates a matrix with the square, cube, etc of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolynomialExpansion:\n",
    "    \"\"\"Transform a single column array or data frame using a polynomial.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    idxs: np.array of int\n",
    "      The column indexes to select.\n",
    "    \"\"\"\n",
    "    def __init__(self, degree):\n",
    "        self.degree = degree\n",
    "        \n",
    "    def fit(self, *args, **kwargs):\n",
    "        # We still don't need to do anything when we fit this transformer, \n",
    "        # it doesn't need to learn anything from the data!\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        # Initialize our return value as a matrix of all zeros.\n",
    "        # We are going to overwrite all of these zeros in the code below.\n",
    "        X_poly = np.zeros((X.shape[0], self.degree))\n",
    "        # The first column in our transformed matrix is just the vector we started with.\n",
    "        X_poly[:, 0] = X.squeeze()\n",
    "        # Cleverness Alert:\n",
    "        # We create the subsequent columns by multiplying the most recently created column\n",
    "        # by X.  This creates the sequence X -> X^2 -> X^3 -> etc...\n",
    "        for i in range(2, self.degree + 1):\n",
    "            X_poly[:, i-1] = X_poly[:, i-2] * X.squeeze()\n",
    "        return X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 2.,  4.,  8.],\n",
       "       [ 3.,  9., 27.],\n",
       "       [ 4., 16., 64.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1], [2], [3], [4]])\n",
    "poly = PolynomialExpansion(3)\n",
    "poly.fit(X)\n",
    "poly.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this in a pipeline if our initial matrix has more than one column:  \n",
    "\n",
    "  - We use the `ColumnSelector` to grab a single column.\n",
    "  - Then a `PolynomialExpansion` to make ten polynomial columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('distance_selector', <__main__.ColumnSelector object at 0x12dc742b0>), ('quadratic_expansion', <__main__.PolynomialExpansion object at 0x12dc74390>)])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_poly = Pipeline([\n",
    "    ('distance_selector', ColumnSelector([2])),\n",
    "    ('quadratic_expansion', PolynomialExpansion(2))\n",
    "])\n",
    "dist_poly.fit(wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can transform the data frame to get our polynomial terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  16.82600021,  283.11428319],\n",
       "       [  47.3219986 , 2239.37155114],\n",
       "       [  20.96699905,  439.61504933],\n",
       "       ...,\n",
       "       [   7.70800018,   59.41326682],\n",
       "       [  22.84199905,  521.75692078],\n",
       "       [  20.84399986,  434.47233028]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_distance = dist_poly.transform(wells)\n",
    "quadratic_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second column is indeed the square of the first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_distance[:, 1] == quadratic_distance[:, 0]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Objects: FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to create a polynomial expansion using **two** features in our model?\n",
    "\n",
    "To accomplish this, we would need to grab two different columns, take a polynomial transformation of them individually, and then re-join the results into a single matrix:\n",
    "\n",
    "```  \n",
    "    +--- Select Column 1 --- Polynomial Expansion ---+\n",
    "X --+                                                +--- Rejoin --> X transfomed\n",
    "    +--- Select Column 2 --- Polynomial Expansion ---+\n",
    "```\n",
    "\n",
    "The splitting and rejoining operation can be accomplished with another sklean feature, the `FeatureUnion`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A silly example of `FeatureUnion`.\n",
    "\n",
    "Here's a simple example:\n",
    "\n",
    "```  \n",
    "    +--- Select Column 1 ---+\n",
    "X --+                       +--- Rejoin --> X transfomed\n",
    "    +--- Select Column 2 ---+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   2.36]\n",
      " [1.   0.71]\n",
      " [0.   2.07]\n",
      " ...\n",
      " [0.   0.51]\n",
      " [0.   0.64]\n",
      " [1.   0.66]]\n"
     ]
    }
   ],
   "source": [
    "two_columns = FeatureUnion([\n",
    "    ('arsenic_selector', ColumnSelector([0])),\n",
    "    ('distance_selector', ColumnSelector([1]))\n",
    "])\n",
    "two_columns.fit(wells)\n",
    "print(two_columns.transform(wells))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all we've done is selected the first two columns, which is admittedly, kind of silly.  In this case we could have just used `ColumnSelector([0, 1])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>switch</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>dist</th>\n",
       "      <th>assoc</th>\n",
       "      <th>educ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.826000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>47.321999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>20.966999</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>21.486000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>40.874001</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    switch  arsenic       dist  assoc  educ\n",
       "id                                         \n",
       "1        1     2.36  16.826000      0     0\n",
       "2        1     0.71  47.321999      0     0\n",
       "3        0     2.07  20.966999      0    10\n",
       "4        1     1.15  21.486000      0    12\n",
       "5        1     1.10  40.874001      1    14"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more useful example of `FeatureUnion`.\n",
    "\n",
    "Let's end by putting together the example I outlined above:\n",
    "\n",
    "```  \n",
    "    +--> Select Column 1 --> Standardize --> Polynomial ---+\n",
    "X --+                                                      +--- Rejoin --> X transfomed\n",
    "    +--> Select Column 2 --> Standardize --> Polynomial ---+\n",
    "```\n",
    "\n",
    "We will use polynomials of degree 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wells_pipeline = FeatureUnion([\n",
    "    ('arsenic_quadratic', Pipeline([\n",
    "        ('arsenic_selector', ColumnSelector([1])),\n",
    "        ('arsenic_standardizer', StandardScaler()),\n",
    "        ('quadratic_expansion', PolynomialExpansion(2))\n",
    "    ])),\n",
    "    ('distance_quadratic', Pipeline([\n",
    "        ('distance_selector', ColumnSelector([2])),\n",
    "        ('distance_standardizer', StandardScaler()),\n",
    "        ('quadratic_expansion', PolynomialExpansion(2))         \n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now a pipline of considerable complexity.  Even so, using it is exactly the same as any of the simpler pipelines that we constructed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('arsenic_quadratic', Pipeline(memory=None,\n",
       "     steps=[('arsenic_selector', <__main__.ColumnSelector object at 0x12c3d25f8>), ('arsenic_standardizer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('quadratic_expansion', <__main__.PolynomialExpansion object at 0x12c3d..., with_std=True)), ('quadratic_expansion', <__main__.PolynomialExpansion object at 0x12c3d20f0>)]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_pipeline.fit(wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wells_quadratic = wells_pipeline.transform(wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.34995675e-01,  4.03219507e-01, -8.18923213e-01,\n",
       "         6.70635228e-01],\n",
       "       [-8.55245061e-01,  7.31444115e-01, -2.62491165e-02,\n",
       "         6.89016115e-04],\n",
       "       [ 3.73074576e-01,  1.39184639e-01, -7.11287369e-01,\n",
       "         5.05929721e-01],\n",
       "       ...,\n",
       "       [-1.03588030e+00,  1.07304800e+00, -1.05592488e+00,\n",
       "         1.11497735e+00],\n",
       "       [-9.18467395e-01,  8.43582357e-01, -6.62551010e-01,\n",
       "         4.38973841e-01],\n",
       "       [-9.00403871e-01,  8.10727132e-01, -7.14484453e-01,\n",
       "         5.10488034e-01]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_quadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Exercise:\n",
    "\n",
    "Find another combination of transformers, `Pipeline`s, and `FeatureUnion`s that accomplishes the same task, then code it up and try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
