{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Objectives\n",
    "\n",
    "- Learn how to connect to and run Postgres queries from Python\n",
    "- Understand psycopg2's cursors, executes, and commits\n",
    "- Learn how to generate dynamic queries through Python string formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining SQL and Python\n",
    "\n",
    "Often you will find yourself working with data that are only accessable through SQL.  However, your machine learning capabilities are built in Python.  To resolve this issue, we can simply set up a connection from Python to the SQL database to bring the data to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we care?\n",
    "\n",
    "- SQL based databases are extremely common in almost all industry environments\n",
    "- Can leverage the benefit of SQL's structure and scalability, while maintaining the flexibility of Python\n",
    "- Very useful for scaled data pipelines, pre-cleaning, data exploration\n",
    "- Allows for dynamic query generation and hence automations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## psycopg2\n",
    "\n",
    "- A Python library that allows for connections with PostgresSQL databases to easily query and retrieve data for analysis.\n",
    "- [Documentation--Includes Installation Instructions](http://initd.org/psycopg/docs/install.html)\n",
    "- In addition to what's listed in the documentation, if you have the anaconda distribution of Python \n",
    "```python \n",
    "conda install psycopg2 \n",
    "```\n",
    "worked for me\n",
    "- There are similar packages for other flavors of SQL that work much the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Workflow\n",
    "\n",
    "1. Establish connection to Postgres database using psycopg2\n",
    "2. Create a cursor\n",
    "3. Use the cursor to execute SQL queries\n",
    "4. Commit SQL actions\n",
    "4. Close the cursor and connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough 1: Creating a database from Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database\n",
    "- Connections must be established using an existing database, username, database IP/URL, and maybe passwords\n",
    "- If you need to create a database, you can first connect to Postgres using the dbname 'postgres' to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "conn = pg2.connect(dbname='postgres', user='isaac', host='localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x1045af9d0; dsn: 'user=isaac host=localhost dbname=postgres', closed: 0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commits\n",
    "\n",
    "- Data changes are not actually stored until you choose to commit\n",
    "- You can choose to have automatic commit by using ` autocommit = True`\n",
    "- When connecting directly to the Postgres Server to initiate server level commands such as creating a database, you must use the `autocommit = True` option since Postgres does not have \"temporary\" transactions at the database level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Cursor\n",
    "\n",
    "- A cursor is a control structure that enables traversal over the records in a database\n",
    "- Executes and fetches data\n",
    "- When the cursor points at the resulting output of a query, it can only read each observation once.  If you choose to see a previously read observation, you must rerun the query. \n",
    "- Can be closed without closing the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute('DROP DATABASE IF EXISTS temp;')\n",
    "cur.execute('CREATE DATABASE temp;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disconnect from the cursor and database\n",
    "- Cursors and Connections must be closed using .close() or else Postgres will lock certain operation on the database/tables to connection is severed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close() # This is optional\n",
    "conn.close() # Closing the connection also closes all cursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x1045af9d0; dsn: 'user=isaac host=localhost dbname=postgres', closed: 1>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough 2: Lets use our new database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname='temp', user='isaac', host='localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE logins (\n",
    "            userid integer, \n",
    "            tmstmp timestamp, \n",
    "            type varchar(10)\n",
    "        );\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Insert data into new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY logins \n",
    "        FROM '/Users/isaac/galvanize/DSI_Lectures/sql-python/clayton/logins_data/logins01.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV;\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a query to get 30 records from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT *\n",
    "        FROM logins\n",
    "        LIMIT 30;\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at our data one line at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, datetime.datetime(2013, 11, 20, 3, 20, 6), 'mobile')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many lines at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(823, datetime.datetime(2013, 11, 20, 3, 20, 49), 'web'),\n",
       " (953, datetime.datetime(2013, 11, 20, 3, 28, 49), 'web'),\n",
       " (612, datetime.datetime(2013, 11, 20, 3, 36, 55), 'web'),\n",
       " (269, datetime.datetime(2013, 11, 20, 3, 43, 13), 'web'),\n",
       " (799, datetime.datetime(2013, 11, 20, 3, 56, 55), 'web'),\n",
       " (890, datetime.datetime(2013, 11, 20, 4, 2, 33), 'mobile'),\n",
       " (330, datetime.datetime(2013, 11, 20, 4, 54, 59), 'mobile'),\n",
       " (628, datetime.datetime(2013, 11, 20, 4, 57, 22), 'mobile'),\n",
       " (398, datetime.datetime(2013, 11, 20, 5, 3, 19), 'mobile'),\n",
       " (482, datetime.datetime(2013, 11, 20, 5, 4, 43), 'mobile')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetchmany(n) to get n rows\n",
    "cur.fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or everything at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(581, datetime.datetime(2013, 11, 20, 5, 12, 3), 'mobile'),\n",
       " (370, datetime.datetime(2013, 11, 20, 5, 26, 46), 'mobile'),\n",
       " (230, datetime.datetime(2013, 11, 20, 5, 28, 29), 'web'),\n",
       " (596, datetime.datetime(2013, 11, 20, 5, 28, 36), 'web'),\n",
       " (274, datetime.datetime(2013, 11, 20, 5, 43, 8), 'mobile'),\n",
       " (581, datetime.datetime(2013, 11, 20, 5, 47, 10), 'web'),\n",
       " (417, datetime.datetime(2013, 11, 20, 5, 54, 37), 'mobile'),\n",
       " (185, datetime.datetime(2013, 11, 20, 5, 56, 22), 'mobile'),\n",
       " (371, datetime.datetime(2013, 11, 20, 5, 58, 35), 'mobile'),\n",
       " (133, datetime.datetime(2013, 11, 20, 5, 59, 7), 'web'),\n",
       " (621, datetime.datetime(2013, 11, 20, 6, 1, 46), 'web'),\n",
       " (306, datetime.datetime(2013, 11, 20, 6, 3, 23), 'mobile'),\n",
       " (509, datetime.datetime(2013, 11, 20, 6, 4, 43), 'web'),\n",
       " (505, datetime.datetime(2013, 11, 20, 6, 9, 52), 'web'),\n",
       " (678, datetime.datetime(2013, 11, 20, 6, 34, 18), 'web'),\n",
       " (889, datetime.datetime(2013, 11, 20, 6, 36, 32), 'mobile'),\n",
       " (202, datetime.datetime(2013, 11, 20, 6, 43, 33), 'mobile'),\n",
       " (614, datetime.datetime(2013, 11, 20, 6, 47, 55), 'mobile'),\n",
       " (882, datetime.datetime(2013, 11, 20, 6, 49), 'mobile')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetchall() grabs all remaining rows\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Queries\n",
    "\n",
    "- A Dynamic Query is a query that generates based on context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "We have 8 login csv files that we need to insert into the logins table.  Instead of doing a COPY FROM query 8 times, we should utilize Python (or any future languages) to make this more efficient.  This is possible due to tokenized strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets get an idea of how many records we start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10000L,)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os is needed because we want to dynamically identify the files we need to insert using listdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a query template and determine file path for imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use string formatting to generate a query for each approved file.\n",
    "\n",
    "### [WARNING: BEWARE OF SQL INJECTION](http://initd.org/psycopg/docs/usage.html)\n",
    "### NEVER use + or % to reformat strings to be used with .execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM logins WHERE userid = 589; DROP TABLE logins;\n",
      "SELECT * FROM logins WHERE tmstmp > 2014-08-01\n"
     ]
    }
   ],
   "source": [
    "#num = 579\n",
    "num = '589; DROP TABLE logins;'\n",
    "terribly_unsafe = \"SELECT * FROM logins WHERE userid = \" + str(num)\n",
    "print terribly_unsafe\n",
    "\n",
    "\n",
    "date_cut = datetime.datetime(2014,8,1)#\"2014-08-01\"\n",
    "#date_cut = date_cut+\"; DROP TABLE logins;\"\n",
    "preferred = \"SELECT * FROM logins WHERE tmstmp > %s\" % date_cut\n",
    "print preferred\n",
    "# Python is happy, but if num or date_cut included something malicious\n",
    "## your data could be at risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY logins \n",
    "        FROM %(file_path)s\n",
    "        DELIMITER ','\n",
    "        CSV;\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logins02.csv inserted into table.\n",
      "logins03.csv inserted into table.\n",
      "logins04.csv inserted into table.\n",
      "logins05.csv inserted into table.\n",
      "logins06.csv inserted into table.\n",
      "logins07.csv inserted into table.\n",
      "logins08.csv inserted into table.\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/Users/Isaac/galvanize/DSI_Lectures/sql-python/clayton/logins_data/'\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv') and file_name != 'logins01.csv':\n",
    "        path=os.path.join(folder_path,file_name)\n",
    "        cur.execute(query, {'file_path':path})\n",
    "        print '{0} inserted into table.'.format(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check the total number of records we have right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10000L,)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget to commit your changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'psycopg2.extensions.connection' object has no attribute 'commitJ'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ddcd75ac1ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommitJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'psycopg2.extensions.connection' object has no attribute 'commitJ'"
     ]
    }
   ],
   "source": [
    "conn.commitJ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close your connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Things to Remember\n",
    "\n",
    "* Connections must be established using an existing database, username, database IP/URL, and maybe passwords\n",
    "* If you have no created databases, you can connect to Postgres using the dbname 'postgres' to initialize db commands\n",
    "* Data changes are not actually stored until you choose to commit. This can be done either through `conn.commit()` or setting `autocommit = True`.  Until commited, all transactions is only temporary stored.\n",
    "* Autocommit = True is necessary to do database commands like CREATE DATABASE.  This is because Postgres does not have temporary transactions at the database level.\n",
    "* If you ever need to build similar pipelines for other forms of database, there are libraries such Pyodbc which operates essentially the same\n",
    "* SQL connection databases utilizes cursors for data traversal and retrieval.  This is kind of like an iterator in Python.\n",
    "* Cursor operations typically goes like the following:\n",
    "    - execute a query\n",
    "    - fetch rows from query result if it is a SELECT query\n",
    "    - because it is iterative, previously fetched rows can only be fetched again by rerunning the query\n",
    "    - close cursor through .close()\n",
    "* Cursors and Connections must be closed using .close() or else Postgres will lock certain operation on the database/tables to connection is severed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise\n",
    "\n",
    "You're given a file called `playgolf.csv` in the data folder.  The file is comma delimited and the first row is the header.  Without opening and looking at the file, create a table and insert the data. Here is the header and first row:\n",
    "\n",
    "\n",
    "|Date|Outlook|Temperature|Humidity|Windy|Result|\n",
    "|----|-------|-----------|--------|-----|------|\n",
    "|07-01-2014|sunny|85|85|false|Don't Play|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
