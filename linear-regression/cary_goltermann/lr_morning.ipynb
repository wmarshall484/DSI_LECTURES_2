{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "52ce26f3-3de8-41ac-83bb-971e2325e85c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "## Fitting a Line to Data\n",
    "\n",
    "#### Cary Goltermann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f46f2d18-c938-48fc-b93d-2a99b2ba9e0e"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Objectives\n",
    "By the end of the lesson you will be able to answer:\n",
    "* Why is it called **Linear** Regression?\n",
    "* How do we choose the \"best\" line?\n",
    "* How do we evaluate our model?\n",
    "* What hypothesis are we testing in Linear Regression?\n",
    "* How do we interpret statsmodel output?\n",
    "* What are the assumptions of Linear Regression?\n",
    "* How do we verify that the assumptions are met by our model?\n",
    "* How do we compare linear models to each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression Overview\n",
    "### Fitting a line\n",
    "### Linear relationships, Exact vs Inexact\n",
    "### Where do we put the line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Linear Regression Overview\n",
    "### Linear relationships, Exact vs Inexact\n",
    "<img src=\"images/exact.png\" width=\"400px\" style=\"float: left\"></img>\n",
    "<img src=\"images/inexact.png\" width=\"450px\" style=\"float: left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choosing a Line\n",
    "\n",
    "<center><img src=\"images/line_placement.png\" width=\"580px\"></img></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Line Questions (2 mins):\n",
    "* How many possible lines are there that can \"fit\" the data?\n",
    "* How do we determine the best line of all these?\n",
    "* Sum of errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Expressing our model\n",
    "## Simple (Bivariate) Linear Regression\n",
    "* What you're presuming the world looks like:\n",
    "    $$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
    "<br>\n",
    "* $\\beta_0$ and $\\beta_1$ are unknown constants that represent the intercept and slope\n",
    "* $\\epsilon$, the error term, is i.i.d $N(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The Linear Model: what you've created from data to estimate the world:\n",
    "    $$ \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x $$\n",
    "<br> \n",
    "* $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ are model coefficient estimates\n",
    "* $\\hat{y}$ indicates the prediction of $y$ based on $X=x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Expressing our model\n",
    "## Multiple Linear Regression\n",
    "* Model in matrix form\n",
    "\n",
    "<center><img src=\"images/matrix_form.png\" width=\"500px\"></img></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Design Matrix $X$\n",
    "<img src=\"images/design_matrix.png\" width=\"800px\"></img>\n",
    "* Coefficient Matrix $\\beta$\n",
    "<img src=\"images/coefficient_matrix.png\" width=\"800px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assessing Model Fit\n",
    "### RSS\n",
    "$RSS = SSE = \\sum_{i=1}^{n}{(y_i - \\hat{y_i})^2}$\n",
    "* How far off were we? Squared.\n",
    "* In units of dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### RSE (aka  RMSE)\n",
    "$RSE = RMSE = \\sqrt{\\frac{RSS}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^{n}{(y_i - \\hat{y_i})^2}}{n - p - 1}}$\n",
    "* How far off were we, on average, controlling for degrees of freedom lost?\n",
    "* Similarly, we have the standard error (biased or not depending on DOF), $s.e. = \\frac{\\sum_{i=1}^{n}{(y_i - \\hat{y_i})^2}}{n - p - 1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Types of Fit\n",
    "Can have the same line but different fit.\n",
    "<center><img src=\"images/tight_loose_fit.png\" width=\"900px\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $R^2$: Coefficient of Determination\n",
    "\n",
    "$$ R^2 = 1 - FUV = 1 - \\frac{Unexplained}{TSS} = \\frac{Explained}{TSS} $$\n",
    "\n",
    "* Fraction unexplained variance, $FUV$\n",
    "* Total sum of square deviations, $TSS$: $\\sum_{i=1}^{n}(y_1 - \\bar{y})^2$\n",
    "* Explained/Regression sum of square deviations, $(E/R)SS$: $\\sum_{i=1}^{n}(\\hat{y_1} - \\bar{y})^2$\n",
    "* Error/Residual sum of square deviations, $(E/R)SS$: $\\sum_{i=1}^{n}(y_1 - \\hat{y_1})^2$\n",
    "* $TSS = Explained + Unexplained$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deviations: Visually\n",
    "<center><img src=\"images/rss.png\" width=\"600px\"></img><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $R^2$: Visually\n",
    "<img src=\"images/r2_1.png\" width=\"350px\" style=\"float: left\"></img>\n",
    "<img src=\"images/r2_0_line.png\" width=\"320px\" style=\"float: left\"></img>\n",
    "<img src=\"images/r2_0_quad.png\" width=\"350px\" style=\"float: left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Notes on images:\n",
    "    * We can have two lines with the same slope and intercept, each of which is the best fit line, and they can still be differently \"good\" fits if the data is spread out\n",
    "    * If we didn't have a model, we would just predict the mean, so that's what we compare ourselves against to see how good our model is\n",
    "    * We could have data that clearly has a signal but a low $R^2$ if we aren't properly modeling it; low $R^2$ isn't necessarily grounds for concluding there's no signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis Testing Revisited\n",
    "\n",
    "Question: What are the parameters we are estimating in linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> Our beta coefficients </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Question: Given that we are estimating parameters, what do you think that our null and alternative hypotheses should be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> $H_0: \\beta_1 = 0 \\qquad H_A: \\beta_1 \\ne 0 $ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpreting Model Output\n",
    "\n",
    "### Using statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ultramann/anaconda3/envs/python2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GNP.deflator</th>\n",
       "      <th>GNP</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Armed.Forces</th>\n",
       "      <th>Population</th>\n",
       "      <th>Year</th>\n",
       "      <th>Employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>83.0</td>\n",
       "      <td>234.289</td>\n",
       "      <td>235.6</td>\n",
       "      <td>159.0</td>\n",
       "      <td>107.608</td>\n",
       "      <td>1947</td>\n",
       "      <td>60.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>88.5</td>\n",
       "      <td>259.426</td>\n",
       "      <td>232.5</td>\n",
       "      <td>145.6</td>\n",
       "      <td>108.632</td>\n",
       "      <td>1948</td>\n",
       "      <td>61.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>88.2</td>\n",
       "      <td>258.054</td>\n",
       "      <td>368.2</td>\n",
       "      <td>161.6</td>\n",
       "      <td>109.773</td>\n",
       "      <td>1949</td>\n",
       "      <td>60.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>89.5</td>\n",
       "      <td>284.599</td>\n",
       "      <td>335.1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>110.929</td>\n",
       "      <td>1950</td>\n",
       "      <td>61.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>96.2</td>\n",
       "      <td>328.975</td>\n",
       "      <td>209.9</td>\n",
       "      <td>309.9</td>\n",
       "      <td>112.075</td>\n",
       "      <td>1951</td>\n",
       "      <td>63.221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GNP.deflator      GNP  Unemployed  Armed.Forces  Population  Year  \\\n",
       "1947          83.0  234.289       235.6         159.0     107.608  1947   \n",
       "1948          88.5  259.426       232.5         145.6     108.632  1948   \n",
       "1949          88.2  258.054       368.2         161.6     109.773  1949   \n",
       "1950          89.5  284.599       335.1         165.0     110.929  1950   \n",
       "1951          96.2  328.975       209.9         309.9     112.075  1951   \n",
       "\n",
       "      Employed  \n",
       "1947    60.323  \n",
       "1948    61.122  \n",
       "1949    60.171  \n",
       "1950    61.187  \n",
       "1951    63.221  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gnp = pd.read_csv('http://vincentarelbundock.github.io/Rdatasets/csv/datasets/longley.csv', index_col=0)\n",
    "df_gnp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>GNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>1.0</td>\n",
       "      <td>234.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>1.0</td>\n",
       "      <td>259.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>1.0</td>\n",
       "      <td>258.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>1.0</td>\n",
       "      <td>284.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1.0</td>\n",
       "      <td>328.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const      GNP\n",
       "1947    1.0  234.289\n",
       "1948    1.0  259.426\n",
       "1949    1.0  258.054\n",
       "1950    1.0  284.599\n",
       "1951    1.0  328.975"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_gnp.GNP  # Set up our design matrix, X\n",
    "X = sm.add_constant(X)  # We need to manually add a constant, aka intercept, when working with statsmodels\n",
    "y = df_gnp.Employed # Set up our target, y\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ultramann/anaconda3/envs/python2/lib/python2.7/site-packages/scipy/stats/stats.py:1557: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=16\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Employed</td>     <th>  R-squared:         </th> <td>   0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   415.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 05 Jul 2017</td> <th>  Prob (F-statistic):</th> <td>8.36e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:24:17</td>     <th>  Log-Likelihood:    </th> <td> -14.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    16</td>      <th>  AIC:               </th> <td>   33.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    14</td>      <th>  BIC:               </th> <td>   35.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   51.8436</td> <td>    0.681</td> <td>   76.087</td> <td> 0.000</td> <td>   50.382</td> <td>   53.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GNP</th>   <td>    0.0348</td> <td>    0.002</td> <td>   20.374</td> <td> 0.000</td> <td>    0.031</td> <td>    0.038</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.925</td> <th>  Durbin-Watson:     </th> <td>   1.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.382</td> <th>  Jarque-Bera (JB):  </th> <td>   1.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.664</td> <th>  Prob(JB):          </th> <td>   0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.759</td> <th>  Cond. No.          </th> <td>1.66e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               Employed   R-squared:                       0.967\n",
       "Model:                            OLS   Adj. R-squared:                  0.965\n",
       "Method:                 Least Squares   F-statistic:                     415.1\n",
       "Date:                Wed, 05 Jul 2017   Prob (F-statistic):           8.36e-12\n",
       "Time:                        16:24:17   Log-Likelihood:                -14.904\n",
       "No. Observations:                  16   AIC:                             33.81\n",
       "Df Residuals:                      14   BIC:                             35.35\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         51.8436      0.681     76.087      0.000      50.382      53.305\n",
       "GNP            0.0348      0.002     20.374      0.000       0.031       0.038\n",
       "==============================================================================\n",
       "Omnibus:                        1.925   Durbin-Watson:                   1.619\n",
       "Prob(Omnibus):                  0.382   Jarque-Bera (JB):                1.215\n",
       "Skew:                           0.664   Prob(JB):                        0.545\n",
       "Kurtosis:                       2.759   Cond. No.                     1.66e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.66e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = sm.OLS(y, X)\n",
    "est = est.fit()\n",
    "est.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Let's not look at all of this output yet, focus on the middle part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# a utility function to only show the coefficient section of summary\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def short_summary(est, part):\n",
    "    return HTML(est.summary().tables[part].as_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   51.8436</td> <td>    0.681</td> <td>   76.087</td> <td> 0.000</td> <td>   50.382</td> <td>   53.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GNP</th>   <td>    0.0348</td> <td>    0.002</td> <td>   20.374</td> <td> 0.000</td> <td>    0.031</td> <td>    0.038</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_summary(est, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Talking points on short summary:\n",
    "* Constant, GNP coefficients\n",
    "    * Sanity check - do they point the right direction\n",
    "    * Rough magnitude check (if you have a sense)\n",
    "* Are the p values significant\n",
    "* Confidence intervals, is 0 in the interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now let's look at the full summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Employed</td>     <th>  R-squared:         </th> <td>   0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   415.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 05 Jul 2017</td> <th>  Prob (F-statistic):</th> <td>8.36e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:24:17</td>     <th>  Log-Likelihood:    </th> <td> -14.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    16</td>      <th>  AIC:               </th> <td>   33.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    14</td>      <th>  BIC:               </th> <td>   35.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   51.8436</td> <td>    0.681</td> <td>   76.087</td> <td> 0.000</td> <td>   50.382</td> <td>   53.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GNP</th>   <td>    0.0348</td> <td>    0.002</td> <td>   20.374</td> <td> 0.000</td> <td>    0.031</td> <td>    0.038</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.925</td> <th>  Durbin-Watson:     </th> <td>   1.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.382</td> <th>  Jarque-Bera (JB):  </th> <td>   1.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.664</td> <th>  Prob(JB):          </th> <td>   0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.759</td> <th>  Cond. No.          </th> <td>1.66e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               Employed   R-squared:                       0.967\n",
       "Model:                            OLS   Adj. R-squared:                  0.965\n",
       "Method:                 Least Squares   F-statistic:                     415.1\n",
       "Date:                Wed, 05 Jul 2017   Prob (F-statistic):           8.36e-12\n",
       "Time:                        16:24:17   Log-Likelihood:                -14.904\n",
       "No. Observations:                  16   AIC:                             33.81\n",
       "Df Residuals:                      14   BIC:                             35.35\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         51.8436      0.681     76.087      0.000      50.382      53.305\n",
       "GNP            0.0348      0.002     20.374      0.000       0.031       0.038\n",
       "==============================================================================\n",
       "Omnibus:                        1.925   Durbin-Watson:                   1.619\n",
       "Prob(Omnibus):                  0.382   Jarque-Bera (JB):                1.215\n",
       "Skew:                           0.664   Prob(JB):                        0.545\n",
       "Kurtosis:                       2.759   Cond. No.                     1.66e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.66e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We pick 100 hundred points equally spaced from the min to the max\n",
    "X_prime = np.linspace(X.GNP.min(), X.GNP.max(), 100)[:, np.newaxis]\n",
    "X_prime = sm.add_constant(X_prime)  # add constant as we did before\n",
    "\n",
    "# Now we calculate the predicted values\n",
    "y_hat = est.predict(X_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1135342d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIuQnBCtnPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113534790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X.GNP, y, alpha=0.3)  # Plot the raw data\n",
    "plt.xlabel(\"Gross National Product\")\n",
    "plt.ylabel(\"Total Employment\")\n",
    "plt.plot(X_prime[:, 1], y_hat, 'r', alpha=0.9)  # Add the regression line, colored in red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "44f566e4-975c-4dd9-bf74-e18c516385e3"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assumptions of Linear Regression\n",
    "\n",
    "* Linearity\n",
    "* Normality of Errors\n",
    "* Constant Variance of Errors (Homoscedasticity)\n",
    "* Independence of Errors\n",
    "* Lack of Multicollinearity\n",
    "        \n",
    "We can't always meet these assumptions, and often have to find ways to combat that reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking Normality of Residuals\n",
    "\n",
    "* Can plot a historgram and eyeball if it looks normal.\n",
    "    * This method is slightly prone to error.\n",
    "* Can plot a quantile-qualtile plot, more next slide.\n",
    "* Can use one of many statistcal tests:\n",
    "    * Jarque–Bera test\n",
    "    * Shapiro–Wilk test\n",
    "    * Kologorov-Sinfov test\n",
    "* In practice one would use many of these, both visual and statistical to determine normality of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### QQ Plots\n",
    "Compares the empirical quantiles from a model's rediduals to those that would occur in a true normal distribution\n",
    "<center><img src=\"images/qq.png\" width=\"400px\"></img></center>\n",
    "Watch this: https://www.youtube.com/watch?v=X9_ISJ0YpGw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analyzing Residuals\n",
    "\n",
    "### Many of the assumptions of linear regression can be checked for a model by looking at it's residuals.\n",
    "\n",
    "### Let's look at some residual plots thinking about the assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/res_a.png\" width=\"400px\"></img></center>\n",
    "<center>$\\hat{y}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notes: good residual plot, look normal, independent and constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/res_b.png\" width=\"400px\"></img></center>\n",
    "<center>$\\hat{y}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notes: descent residual plot, look fairly normal, but there are some possible outliers and possibly not independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/res_c.png\" width=\"400px\"></img></center>\n",
    "<center>$\\hat{y}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notes: residuals are curvilinear, this violates the linearity assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/res_d.png\" width=\"400px\"></img></center>\n",
    "<center>$\\hat{y}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notes: residuals are heteroscedastic, this violates the constant variance assumption, instead depends on x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/res_e.png\" width=\"400px\"></img></center>\n",
    "<center>$\\hat{y}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notes: indicates a linear relationship between the residuals and a variable not in the model; we probably want to try to find/measure that variable and add it into our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outliers\n",
    "\n",
    "* Outliers\n",
    "    * Types of outliers\n",
    "    * Detecting outliers\n",
    "        * Studentized Residuals\n",
    "        * Leverage\n",
    "    * Residual plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Type of Outliers\n",
    "\n",
    "<center><img src=\"images/types_of_outliers.png\" width=\"600px\"></img></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outliers\n",
    "### Detecting outliers visually\n",
    "\n",
    "We can make a **residual plot** to help identify outliers visually. In this case, we plot the residuals by the fitted/predicted value, $\\hat{y}$.\n",
    "\n",
    "Even better, we can **standardize** the residuals, dividing by the standard error. This allows us to see which points are outliers in the common way, perhaps by checking whether they're above or below 2 (roughly 95% of our data is covered by that region)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Standardized residuals\n",
    "\n",
    "<center><img src=\"images/standardized_residuals.png\" width=\"500px\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Studentizing\n",
    "\n",
    "Even better still, we can **\"studentize\"** the errors by dividing, not by the \"global\" standard error for our model, but by the standard error of our model at the particular value of y where the residual occurred.  Our confidence intervals change depending on how much data we have seen in a particular region.  If we've seen a lot of data, our intervals are tight; otherwise, they are wide.  So, it takes \"more\" for a data point to be considered an outlier if it is in a region in which we have little data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Studentizing Visually\n",
    "\n",
    "<img src=\"images/studentized_residual_plot.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leverage\n",
    "\n",
    "* A high-leverage point is an observation with an unusual X value.\n",
    "* It does not necessarily have a large effect on the regression model (it could lie right along the best fit line of a model fit without it).\n",
    "* Most common measure is the \"hat value\": $h_{ii}=(H)_{ii}$\n",
    "* The $i$th diagonal of the hat matrix: $$ H = X(X^TX)^{-1}X^T, $$ is the leverage of the particular data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Intuition\n",
    "\n",
    "Dragging a single point upwards and seeing how much the prediction line follows. If, for a fixed $x$, we perturb $y$ and $\\hat{y_i}$ moves a little, then it is low leverage; if it moves a lot, then it is high leverage. So you can think of it as $h_{ii} = \\frac{d\\hat{y_i}}{dy_i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use Leverage to Studentize our errors\n",
    "\n",
    "* The corresponding Studentized residual is then $$ t_i = \\frac{\\hat{\\epsilon_i}}{ \\hat{\\sigma}\\sqrt{1 - h_{ii}} } $$ where $\\hat{\\sigma}$ is an appropriate estimate of $\\sigma$ (basically square root of RSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now that we have either standardized (divided by \"global\" standard error) or studentized (divided by \"local\" standard error) residuals, we can use them to programmatically identify outlier points.  Roughly 95% of our data will fall within $\\pm2$ standardized/studentized errors.  We likely don't want to throw out 1 in 20 data points, though, so perhaps we'll cut anything off if it's outside the $\\pm3$ bounds.  Note, if we do find outliers we usually train two models, one with them and one without.  Also we might chase down the story behind the outlier data points, if we can (was data entered incorrectly? was there a tsunami that day? did the servers go down?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multicollinearity \n",
    "Measuring the same thing two different ways.\n",
    "\n",
    "If we had the grade of every class for a student, as well as their GPA, we have multicollinearity because GPA is a linear function of their grades.\n",
    "\n",
    "Could also just be married_is_True and married_is_False as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Perfect vs Partial\n",
    "* Perfect: unlikely to occur in practice\n",
    "  * Your model will often fail to run/converge (some libraries will still be ok, but don't count on it)\n",
    "  * Consider a case where $\\beta_1$ and $\\beta_2$ measure \"years since graduating Galvanize\" and \"years as a data scientist\", and of course these are the same ;)\n",
    "* Partial\n",
    "  * Uncertainty in the model coefficients becomes large\n",
    "  * Does not necessarily affect model accuracy or bias the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Identifying Multicollinearity\n",
    "\n",
    "* Correlation Matrix / Scatterplot Matrix / Bivariate Correlations\n",
    "    * Can only pick up pairwise effects\n",
    "* Variance Inflation Factors, VIF\n",
    "    * Regress each of the independent variables on all the other independent variables\n",
    "    * I.E. with a design matrix X of $p$ features, for each feature $i$, fit a linear model with the $i^{th}$ feature as the target and the remaining $p-1$ features as independent variables:\n",
    "        $$ X_i = X_{p \\setminus i}\\beta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why VIF?\n",
    "\n",
    "Question (2 mins): Why do we care about predicting one of the features with all the others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### VIF Definition\n",
    "$$ VIF_i = \\frac{1}{1 - R_i^2} $$\n",
    "\n",
    "* If any of these auxiliary $R^2$ values are near 1, there is high multicollinearity\n",
    "* In the best case:\n",
    "    * We can't predict our $i$th feature with the others, so $R_i^2$ is 0\n",
    "    * This means VIF is 1, and $x_j$ is linearly independent of the other independent variables\n",
    "* If $VIF > 10$, then multicollinearity is probably a problem\n",
    "    * 10 is a rule of thumb; you may be more or less conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixing Multicollinearity\n",
    "\n",
    "* What should I do if I have high multicollinearity?\n",
    "    * Try to gather more data\n",
    "    * Consider combining multiple intercorrelated variables into one\n",
    "    * Don't interpret coefficients, just use your model to predict\n",
    "    * Discard the offending variable(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another Hypothesis Test\n",
    "#### Are any of my features useful, a.k.a. should have a non-zero coefficient?\n",
    "\n",
    "1) Set up hypotheses:\n",
    "    $$ H_0: \\beta_{1...p} = 0 $$\n",
    "\n",
    "<center> $ H_A:$  at least one $\\beta_j$ is nonzero </center>\n",
    "\n",
    "Compare the difference in total squared error and the residual squared error with the residual squared error, scaled by features used (for DOF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2) Compute F-statistic\n",
    "\n",
    " $$ F = \\frac{\\frac{TSS - RSS}{p}}{\\frac{RSS}{n - p - 1}} ~ F_{p, n - p - 1} $$\n",
    " \n",
    "3) Compute p-value\n",
    " ```python\n",
    " p_val = 1 - scs.f.cdf(F_stat, p, n - p_full - 1)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Models\n",
    "\n",
    "Sometime you want to check whether a model that is nested within another is significantly worse than the full model.\n",
    "\n",
    "Reduced Model: $ Y = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p $\n",
    "\n",
    "Full Model:    $ Y = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p + \\beta_{p+1} x_{p+1} + ... + \\beta_{p+k} x_{p+k} $\n",
    "\n",
    "1) Set up hypotheses\n",
    "\n",
    "$$ H_0: \\beta_{1...k} = 0 $$\n",
    "\n",
    "<center> $H_A:$ at least one of the added betas, $\\beta_k$, is nonzero </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2) Compute F-statistic\n",
    " $$ F = \\frac{\\frac{(RSS_{red} - RSS_{full})}{(p_{full} - p_{red})}}{\\frac{RSS_{full}}{(n - p_{full} -1)}},\\; p_{full} = p + k $$\n",
    "\n",
    "3) Compute p-value\n",
    "\n",
    "  ```python\n",
    "  p_val = 1 - scs.f.cdf(F_stat, p_full - p_red, \n",
    "                        n - p_full - 1)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f46f2d18-c938-48fc-b93d-2a99b2ba9e0e"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Objectives\n",
    "By the end of the lesson you will be able to answer:\n",
    "* Why is it called **Linear** Regression?\n",
    "* How do we choose the \"best\" line?\n",
    "* How do we evaluate our model?\n",
    "* What hypothesis are we testing in Linear Regression?\n",
    "* How do we interpret statsmodel output?\n",
    "* What are the assumptions of Linear Regression?\n",
    "* How do we verify that the assumptions are met by our model?\n",
    "* How do we compare linear models to each other?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
