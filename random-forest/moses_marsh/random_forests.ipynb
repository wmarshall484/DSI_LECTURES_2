{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as scs\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Morning Objectives\n",
    "\n",
    " * Explain the relationship and difference between bagging and a random forest.\n",
    " * Explain why bagging/random forests are more accurate than a single decision tree.\n",
    " * Explain & construct a random forest (classification or regression).\n",
    "\n",
    "Afternoon Objectives\n",
    "\n",
    " * Get feature importances from a random forest.\n",
    " * Explain how OOB error is calculated and what it estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "Morning Agenda:\n",
    "\n",
    " * Discuss ensemble methods\n",
    " * Review bias/variance tradeoff\n",
    " * Review decision trees\n",
    " * Discuss bagging (bootstrap aggregation)\n",
    " * Discuss random forests\n",
    "\n",
    "Afternoon Agenda:\n",
    "\n",
    " * Discuss out-of-bag error\n",
    " * Discuss feature importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an Ensemble Method?\n",
    "\n",
    "In general, an **ensemble** method combines many weak models to form a strong model. We train multiple *different* models on the data. They could be trained on different subsets of the data, or trained in different ways, or even be completely different types of models.\n",
    "\n",
    "Once we've done that, we need to combine the models to form a single model.\n",
    "\n",
    "Class discussion: how would get a single prediction from an ensemble of **regression** models?\n",
    "\n",
    "Class discussion: how would get a single prediction from an ensemble of **classification** models?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: Intuition\n",
    "\n",
    "Suppose we have 5 *independent* hard binary classifers (they only give 0 or 1 probability). If each has a %70 probability of correctly classifying a data point, what is the probability that an *ensemble* of these models correctly classifies a point? The ensemble prediction is just the majority vote of the individual classifiers.\n",
    "\n",
    "Question: what does independent mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ensemble_probability(n, p):\n",
    "    '''Given a n independent classifiers each with\n",
    "    probability p of voting correctly, return the \n",
    "    probability that the majority of the classifiers \n",
    "    vote correctly'''\n",
    "    return (1 - scs.distributions.binom(n,p).cdf(n//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_ensemble_probability(5, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.arange(1, 55, 2)\n",
    "ensemble_accuracies = [find_ensemble_probability(n, 0.7) for n in ns]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ns, ensemble_accuracies, '.')\n",
    "ax.set_ylabel(\"Ensemble accuracy\")\n",
    "ax.set_xlabel(\"Number of independent 0.7-accuracy classifiers\")\n",
    "ax.set_title(\"Accuracy of an Ensemble of Independent Classifiers\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\binom{5}{5} 0.7^5 + \\binom{5}{4} 0.7^4 0.3 + \\binom{5}{3} 0.7^3 0.3^2 \\approx 0.83 $$\n",
    "\n",
    "With 55 such classifiers we can achieve 99.9% accuracy.\n",
    "\n",
    "\n",
    "Question: what's the limitation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Make Them Independent?\n",
    "\n",
    "If the learners are all the same, ensembles don't help.\n",
    "\n",
    "Train each learner on different subset of data.\n",
    "\n",
    "Question: Why is this better than a single good model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance\n",
    "\n",
    "Question: what is bias?\n",
    "\n",
    "Question: what is variance?\n",
    "\n",
    "Question: what is the bias of an unpruned decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Classification Trees\n",
    "\n",
    "A **classification tree** is a decision tree to predicts whether a data point is in one class or another. Each branch node is a decision, choosing left or right based on the value of a certain feature. Each leaf node gives the probability that a data point is in one class or another.\n",
    "\n",
    "Let's look at the tennis dataset from the other day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our data\n",
    "tennis_df = pd.read_table('data/tennis.txt', delim_whitespace=True)\n",
    "tennis_df.rename(columns={'playtennis': 'played'}, inplace=True)\n",
    "#tennis_df['played'] = tennis_df['played'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "tennis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably need to do `pip install graphviz` to generate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='A simple classification tree')\n",
    "\n",
    "dot.node('O', 'outlook?', shape='diamond')\n",
    "dot.node('1', \"no\", shape='rectangle')\n",
    "dot.node('H', 'humidity?', shape='diamond')\n",
    "dot.node('O2', 'outlook?', shape='diamond')\n",
    "dot.node('W', 'wind?', shape='diamond')\n",
    "dot.node('3', 'yes', shape='rectangle')\n",
    "dot.node('T', 'temperature?', shape='diamond')\n",
    "dot.node('4', 'yes', shape='rectangle')\n",
    "dot.node('5', \"no\", shape='rectangle')\n",
    "dot.node('2', \"no\", shape='rectangle')\n",
    "dot.node('W2', 'wind?', shape='diamond')\n",
    "dot.node('6', \"no\", shape='rectangle')\n",
    "dot.node('7', 'yes', shape='rectangle')\n",
    "\n",
    "dot.edge('O', '1', 'overcast')\n",
    "dot.edge('O', 'H', 'not overcast')\n",
    "dot.edge('H', 'O2', 'high')\n",
    "dot.edge('H', 'W', 'normal')\n",
    "dot.edge('W', '3', 'False')\n",
    "dot.edge('W', 'T', 'True')\n",
    "dot.edge('T', '4', 'mild')\n",
    "dot.edge('T', '5', 'cool')\n",
    "dot.edge('O2', '2', 'sunny')\n",
    "dot.edge('O2', 'W2', 'rainy')\n",
    "dot.edge('W2', '7', 'False')\n",
    "dot.edge('W2', '6', 'True')\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification tree is built by\n",
    "\n",
    "* Iteratively divide the nodes such that the information gain (using entropy/gini impurity) is maximized\n",
    "* Various stopping conditions like a depth limit\n",
    "* Prune trees by merging nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Review: Regression Trees\n",
    "\n",
    "A **regression tree** predicting a number rather than a class.  A leaf node outputs *the mean of its elements* instead of *the majority class of its elements*.\n",
    "\n",
    "To train a regression tree, we\n",
    "\n",
    "* Iteratively divide the nodes such that *variance* of the parent node $P$ minus the weighted variance of the child nodes $C_L$ and $C_R$ is maximized\n",
    "\n",
    "$$I_V = \\text{var}(P) -\\frac{|C_R|}{|P|}\\text{var}(C_L) - \\frac{|C_R|}{|P|}\\text{var}(C_R) $$\n",
    "\n",
    "\n",
    "$$I_V = \\frac{1}{|P|}\\left(\\sum_{i \\in P} (y_i - \\bar{y_P})^2\\right) - \\left(\\frac{|C_L|}{|P|}\\frac{1}{|C_L|}\\sum_{i \\in C_L} (y_i - \\bar{y_L})^2 + \\frac{|C_R|}{|P|}\\frac{1}{|C_R|}\\sum_{i\\in C_R} (y_i - \\bar{y_R})^2\\right)$$\n",
    "\n",
    "$$I_V = \\frac{1}{|P|}\\left[\\left(\\sum_{i \\in P} (y_i - \\bar{y_P})^2\\right) - \\left(\\sum_{i \\in C_L} (y_i - \\bar{y_L})^2 + \\sum_{i\\in C_R} (y_i - \\bar{y_R})^2\\right)\\right]$$\n",
    "\n",
    "* Use various stopping conditions like a depth limit, minimum leaf size, and\n",
    "* Prune trees by merging nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees: Example\n",
    "\n",
    " $x_1$ |   $x_2$ |  $y$\n",
    "-------|---------|--------\n",
    " 1     |    1    |   1\n",
    " 0     |    0    |   2\n",
    " 1     |    0    |   3\n",
    " 0     |    1    |   4\n",
    "\n",
    " Prior to the split we guess the mean, 2.5, for everything, giving total squared error:\n",
    " \n",
    " $$ E = (1-2.5)^2 + (2-2.5)^2 + (3-2.5)^2 + (4-2.5)^2  = 5$$\n",
    " After we split on $x_1$ we guess 2 for rows 1 & 3 and 3 for rows 2 & 4:\n",
    " \n",
    " $$ I = 5 - [(1-2)^2 + (3-2)^2 + (2-3)^2 + (4-3)^2] = 5 - 4  = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Summary\n",
    "\n",
    "What are the pros and cons?\n",
    "\n",
    "Pros\n",
    " * No feature scaling needed\n",
    " * Model nonlinear relationships\n",
    " * Can do both classification and regression\n",
    " * Robust\n",
    " * Highly interpretable\n",
    "\n",
    "Cons\n",
    " * Can be expensive to train\n",
    " * Need to be tuned so they don't totally overfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Bootstrapping\n",
    "\n",
    "What is a bootstrap sample?\n",
    "\n",
    "What have we learned that bootstrap samples are good for so far?\n",
    "\n",
    "Let's get the median of some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scs.uniform(0,10).rvs(100)\n",
    "np.median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the confidence interval of this estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_confidence_interval(data, function, alpha=0.05, n_bootstraps=1000):\n",
    "    '''return a the confidence interval for a function of data using bootstrapping'''\n",
    "    medians = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        bootstrap_sample = np.random.choice(data, len(data))\n",
    "        medians.append(function(bootstrap_sample))\n",
    "    return (np.percentile(medians, 100*(alpha/2.)),\n",
    "            np.percentile(medians, 100*(1-alpha/2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "ci = bootstrap_confidence_interval(data, np.median, alpha)\n",
    "\n",
    "print(\"The {}% confidence interval is from {} to {}\".format(1-alpha, *ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our procedure was\n",
    "  * Take 1000 bootstrap samples.\n",
    "  * Take the median of each sample.\n",
    "  * The 95% confidence inverval for the median is between the 25th and 975th largest samples.\n",
    "  \n",
    "To confirm this worked, let's do it a bunch of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = []\n",
    "for _ in range(100):\n",
    "    data = scs.uniform(0,10).rvs(100)\n",
    "    ci = bootstrap_confidence_interval(data, np.median)\n",
    "    hits.append(ci[0] < 5.0 and ci[1] > 5.0)\n",
    "print(np.mean(hits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the fraction of time the bootstrapped CI contained the true median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped aggregation\n",
    "\n",
    " * We are thinking about the population of all possible decision tree models on our data.\n",
    " * If I take $n$ samples *iid* from this distribution and average them the variance goes down by $\\sqrt n$\n",
    " * There is some correlation between models because they are all trained on bootstrap samples from the same draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Experiment\n",
    "\n",
    "You're each going to be a decision tree on some data based on a bootstrap sample, and then we'll all ensemble the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "\n",
    "# Split into test/train, using the same random state for everyone\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=462)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# each of you has a different bootstrap sample\n",
    "indices = np.arange(len(X_train))\n",
    "bootstrap_sample_indices = np.random.choice(indices, len(X_train))\n",
    "clf.fit(X_train[bootstrap_sample_indices], y_train[bootstrap_sample_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:.3f}\".format(np.mean(clf.predict(X_test) == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"My prediction: {}\".format(clf.predict(X_test)[0:20]))\n",
    "print(\"Actual result: {}\".format(y_test[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concept, creating each model from a bootstrap sample and aggregating the results, is called **bagging**. It can be used with any sort of model, but is generally done with decision trees.\n",
    "\n",
    "Question: why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping on Regression Trees\n",
    "\n",
    "Let's do another example. Consider some points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = 5000\n",
    "x = scs.uniform(0, 10).rvs(n_data)\n",
    "y = np.sin(x) + scs.norm(0, 0.5).rvs(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "ax.plot(x, y, '.', ms=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a decision tree to predict the points. We won't make it that deep because we want to visualize the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 7\n",
    "model0 = DecisionTreeRegressor(max_depth=max_depth)\n",
    "model0.fit(x.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pts = 1000\n",
    "xpts = np.linspace(0, 10, n_pts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "ax.plot(x, y, '.', ms=2)\n",
    "\n",
    "ax.plot(xpts, model0.predict(xpts.reshape(-1, 1)), 'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's what one decision tree looks like; each discontinuity is a node split. What if we creat a bunch of bootstrap samples and build an ensemble of trees from them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstraps = 5000\n",
    "yptses = np.zeros((n_bootstraps, n_pts))\n",
    "for i in range(n_bootstraps):\n",
    "    bootstrap = np.random.choice(np.arange(n_data), n_data, replace=True)\n",
    "    model = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    model.fit(x[bootstrap].reshape(-1, 1), y[bootstrap])\n",
    "    yptses[i] = model.predict(xpts.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are three of the bootstrapped trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "ax.plot(x, y, '.', ms=2)\n",
    "\n",
    "for i in range(3):\n",
    "    ax.plot(xpts, yptses[i])\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here in black is the average across all bootstrapped trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "ax.plot(x, y, '.', ms=2)\n",
    "\n",
    "ax.plot(xpts, yptses.mean(axis=0), 'k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "Bagging decision trees is pretty cool, but the trees still tend to look pretty similar. We want a way to make the trees more different (decorrelate them) without substantially increasing the bias of each tree.\n",
    "\n",
    "Random forests do this with **feature subsetting** (also called \"subspace sampling\"). For any node in any tree, instead of finding the best split among **all** features, we randomly select a few features, and find the best split among just those features. The number of features $m$ to consider at each split is a hyperparameter; typically $m = \\sqrt k$ is used.\n",
    "\n",
    "Again, the features to consider are chosen **at each split**, not each tree. **Everyone gets this wrong.**\n",
    "\n",
    "For example, suppose we're building a model with nine features. One of them is really predictive, another is pretty good, and the others are just ok.\n",
    "\n",
    "If we build an ensemble of bagged trees, probably each will use the good feature as the first split, and probably each will use the pretty-good feature at the next split. For the other splits the trees might differ, particularly farther down when only a few points are being considered, but the first branches will be pretty much the same.\n",
    "\n",
    "If we build a tree in a random forest, we'll only consider three (random) features for that first split. Only a fraction of the trees (around 30%) will consider the good feature on the first split, so they will use that. Some of the others will consider the pretty-good feature, so they will start there. The others will start at some other feature. Those trees will still consider the good and pretty-good features at some of the lower nodes, and will get to take advantage of them, but the overall structure of those trees will be completely different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Parameters\n",
    "\n",
    "Random Forest Parameters\n",
    "\n",
    " * Total number of trees\n",
    " * Number of features to use at each split\n",
    " * Individual decision tree Parameters\n",
    "    - e.g., tree depth, pruning, split criterion\n",
    "\n",
    "In general, RF are fairly robust to the choice of parameters and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of Random Forest\n",
    "\n",
    "Pros\n",
    "\n",
    " * Often give near state-of-the-art performance\n",
    " * Good out-of-the-box performance\n",
    " * No feature scaling needed\n",
    " * Model nonlinear relationships\n",
    "\n",
    "Cons\n",
    "\n",
    " * Can be expensive to train (though can be done in parallel)\n",
    " * Not interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Let's investigate the accuracy of a random forests compared with a single decision tree using the breast cancer dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "#data = pd.drop(data, )\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "X = X.drop(['worst concave points', 'mean concave points', 'worst perimeter', 'worst radius', 'worst area', 'mean concavity'], axis=1)\n",
    "# Split into test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, consider a decision tree, doing a grid search over hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Search                                     \n",
    "model = DecisionTreeClassifier()\n",
    "depth_parm = np.arange(1, 12, 1)\n",
    "num_samples_parm = np.arange(5,95,10)\n",
    "parameters = {'max_depth' : depth_parm,\n",
    "             'min_samples_leaf' : num_samples_parm}\n",
    "clf = GridSearchCV(model, parameters, cv=10)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and fit model                                                   \n",
    "rf = RandomForestClassifier(n_estimators=1000,\n",
    "                           max_features='auto',\n",
    "                           random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "                                     \n",
    "# Test Prediction\n",
    "pred = rf.predict(X_test)\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afternoon Lecture\n",
    "\n",
    "## Interpreting Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Morning Objectives\n",
    "\n",
    " * Explain & construct a random forest (classification or regression).\n",
    " * Explain the relationship and difference between random forest and bagging.\n",
    " * Explain why random forests are more accurate than a single decision tree.\n",
    "\n",
    "Afternoon Objectives\n",
    "\n",
    " * Get feature importances from a random forest.\n",
    " * Explain how OOB error is calculated and what is it an estimate of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "Morning Agenda\n",
    "\n",
    " * Discuss ensemble methods\n",
    " * Review bias/variance tradeoff\n",
    " * Review decision trees\n",
    " * Discuss bagging (bootstrap aggregation)\n",
    " * Discuss random forests\n",
    "\n",
    "Afternoon Agenda\n",
    "\n",
    " * Discuss out-of-bag error\n",
    " * Discuss feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Bagging and Random Forests\n",
    "\n",
    "What is bagging?\n",
    "\n",
    "Can bagging be used with other models?\n",
    "\n",
    "What's the difference between bagging and random forests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-Of-Bag Error\n",
    "\n",
    "The out-of-bag error is a way to measure the error of a bagged model (including random forests).\n",
    "\n",
    "Since the decision trees are constructed from a bootstrapped sample, each tree will (probably) not see all of the data, so each data point will (probably) not be seen by many of the trees.\n",
    "\n",
    "Let's imagine a data set with 10 points, and that we're making a random forest with 20 trees. We'll then construct 20 bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = np.arange(10)\n",
    "\n",
    "n_data = len(fake_data)\n",
    "n_trees = 20\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "bootstrap_samples = np.random.choice(np.arange(n_data),\n",
    "                                     [n_trees, n_data],\n",
    "                                     replace=True)\n",
    "# sort along rows to make it a bit easier to read\n",
    "bootstrap_samples.sort(axis=1)\n",
    "bootstrap_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would then construct 20 trees, each using the data in one of the rows.\n",
    "\n",
    "Notice the first tree (and several others) isn't constructed using point 0 at all. So we could test that point of an ensemble of just those trees a get a independent measure of the effectiveness of the model. Simililarly, we could test other points on other trees.\n",
    "\n",
    "Question: which trees would we use to test point 1?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_samples[(bootstrap_samples != 1).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, how many trees can we use to test each point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = []\n",
    "for i in range(10):\n",
    "    bsize.append(sum((bootstrap_samples != i).all(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bsize)/n_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out this number is $\\frac{1}{e}$; you can [read about the math](https://stats.stackexchange.com/questions/88980/why-on-average-does-each-bootstrap-sample-contain-roughly-two-thirds-of-observat) and, relatedly, [derangements](https://en.wikipedia.org/wiki/Derangement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we use cross validation anyway because we're comparing with other models and we want to use the same validation pipeline for everything.\n",
    "\n",
    "\n",
    "\n",
    "## Feature Importances\n",
    "\n",
    "One of the challenges of random forests is the lack of interpretability. Feature importances are a measure of which features aften actually effect the predictions.\n",
    "\n",
    "This can be a critical business question. For example, with churn analysis, it's generally more important to understand *why* customers are churning than to predict which customers are going to churn.\n",
    "\n",
    "How should we measure it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances: Average Decrease in Impurity\n",
    "\n",
    "How much does each feature decrease the impurity?\n",
    "\n",
    " * For each tree, each split is made in order to reduce the total impurity of the tree (Gini/entropy/MSE). \n",
    " * \"Total information gain\" for a single tree is the sum of the information gain at each split, and a feature's importance for a single tree is the total information gain of splits involving that feature divided by the total information gain of the tree.\n",
    " * This is called \"Gini importance\" and it is what `sklearn` implements. \n",
    " * The importance of a feature in a forest is the average of the Gini importances for that feature across all trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "#data = pd.drop(data, )\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "X = X.drop(['worst concave points', 'mean concave points', 'worst perimeter', 'worst radius', 'worst area', 'mean concavity'], axis=1)\n",
    "# Split into test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000,\n",
    "                           max_features='auto',\n",
    "                           random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance\n",
    "feat_scores = pd.DataFrame({'Average Gini importance' : rf.feature_importances_},\n",
    "                           index=X.columns)\n",
    "feat_scores = feat_scores.sort_values(by='Average Gini importance')\n",
    "feat_scores.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances: Average Decrease in Accuracy when a feature's values are shuffled\n",
    "\n",
    "(Described [here](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#varimp))\n",
    "\n",
    "How much does randomly shuffling the values of a feature affect accuracy?\n",
    "\n",
    "To compute the importance of the $j^{th}$ feature:\n",
    "\n",
    " * When the $b^{th}$ tree is grown, use it to predict the OOB samples and record accuracy.\n",
    " * Scramble the values of the $j^{th}$ feature in the OOB samples and do the prediction again.  Compute the new (lower) accuracy.\n",
    " * Average the decrease in accuracy across all trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "#data = pd.drop(data, )\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "X = X.drop(['worst concave points', 'mean concave points', 'worst perimeter', 'worst radius', 'worst area', 'mean concavity'], axis=1)\n",
    "\n",
    "feature_names = X.columns\n",
    "X = X.values\n",
    "y = y.values\n",
    "# Split into test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 250\n",
    "index_set = set(range(len(X)))\n",
    "bootstrapped_indices = [np.random.choice(np.arange(len(X)), size=len(X)) for _ in range(n_trees)]\n",
    "oob_indices = [list(index_set - set(b)) for b in bootstrapped_indices]\n",
    "estimators = [DecisionTreeClassifier().fit(X[b],y[b]) for b in bootstrapped_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_scores = np.array([est.score(X[oob], y[oob]) for oob, est in zip(oob_indices, estimators)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_column(X, i):\n",
    "    X_new = X.copy()\n",
    "    np.random.shuffle(X_new[:,i])\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance = np.zeros(X.shape[1])\n",
    "for i in range(X.shape[1]):\n",
    "    X_shuffled = shuffle_column(X, i)\n",
    "    new_oob_scores = np.array([est.score(X_shuffled[oob], y[oob]) for oob, est in zip(oob_indices, estimators)])\n",
    "    feat_importance[i] = (oob_scores - new_oob_scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_series = pd.Series(data=feat_importance, index=feature_names)\n",
    "importance_series.sort_values().plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
