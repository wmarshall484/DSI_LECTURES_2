{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "%matplotlib inline\n",
    "\n",
    "# Load Boston data\n",
    "data = load_boston()\n",
    "\n",
    "# Split into test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n",
    "# Parameter Search                                                    \n",
    "model = DecisionTreeRegressor()\n",
    "depth_parm = np.linspace(1,12,12)\n",
    "num_samples_parm = np.linspace(5,100,20)\n",
    "parameters = {'max_depth' : depth_parm,\n",
    "             'min_samples_leaf' : num_samples_parm}\n",
    "regressor = GridSearchCV(model, parameters, scoring = 'mean_squared_error', cv=10)\n",
    "regressor.fit(X_train,y_train)\n",
    "                                      \n",
    "# Test Prediction\n",
    "pred = regressor.predict(X_test)\n",
    "mse = np.mean((y_test - pred)**2)\n",
    "print mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Load Boston data\n",
    "data = load_boston()\n",
    "\n",
    "# Split into test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, \n",
    "                                                    data.target, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n",
    "# Train and fit model                                                   \n",
    "rf = RandomForestRegressor(n_estimators=1000,\n",
    "                                  max_features='auto',\n",
    "                                  random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "                                     \n",
    "# Test Prediction\n",
    "pred = rf.predict(X_test)\n",
    "mse = np.mean((y_test - pred)**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37% reduction in MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Interpretation\n",
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraction of Samples Affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plot the feature importance\n",
    "feat_scores = pd.DataFrame({'Fraction of Samples Affected' : rf.feature_importances_},\n",
    "                           index=data.feature_names)\n",
    "feat_scores = feat_scores.sort_values(by='Fraction of Samples Affected')\n",
    "feat_scores.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Decrease Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "boston = load_boston()   \n",
    "names = boston.feature_names\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    " \n",
    "# crossvalidate the scores on a number of \n",
    "# different random splits of the data\n",
    "for train_idx, test_idx in ShuffleSplit(len(X), 100, .3):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "    r = rf.fit(X_train, Y_train)\n",
    "    acc = r2_score(Y_test, rf.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(Y_test, rf.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "\n",
    "score_series = pd.DataFrame(scores).mean()\n",
    "scores = pd.DataFrame({'Mean Decrease Accuracy' : score_series})\n",
    "scores.sort_values(by='Mean Decrease Accuracy').plot(kind='barh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
