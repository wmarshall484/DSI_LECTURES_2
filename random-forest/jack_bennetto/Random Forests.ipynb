{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Random Forests\n",
    "### Jack Bennetto\n",
    "### July 17, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.misc import comb\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Morning Objectives\n",
    "\n",
    " * Explain & construct a random forest (classification or regression).\n",
    " * Explain the relationship and difference between random forest and bagging.\n",
    " * Explain why random forests are more accurate than a single decision tree.\n",
    "\n",
    "Afternoon Objectives\n",
    "\n",
    " * Get feature importances from a random forest.\n",
    " * Explain how OOB error is calculated and what is it an estimate of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "Morning Agenda:\n",
    "\n",
    " * Discuss ensemble methods\n",
    " * Review bias/variance tradeoff\n",
    " * Review decision trees\n",
    " * Discuss bagging (bootstrap aggregation)\n",
    " * Discuss random forests\n",
    "\n",
    "Afternoon Agenda:\n",
    "\n",
    " * Discuss out-of-bag error\n",
    " * Discuss feature importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an Ensemble Method?\n",
    "\n",
    "In general, an **ensemble** method combines many weak models to form a strong model.\n",
    "\n",
    "Train multiple different models on the data. The overall prediction is\n",
    "\n",
    " * the average prediction, for a regressor, or\n",
    " * the plurality choice, for a classifier (the fraction of models is probability).\n",
    "\n",
    "Why is probability is important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: Intuition\n",
    "\n",
    "Suppose we have 5 *independent* binary classifers that are each 70% accurate. What's the overall accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ensemble_accuracy(n, p):\n",
    "    '''Given a n independent classifiers each of p accuracy,\n",
    "    return the emsumble accuracy'''\n",
    "    ensemble_accuracy = 0\n",
    "    for k in range((n + 1) / 2, n+1):\n",
    "        ensemble_accuracy += comb(n, k) * p**k * (1-p)**(n-k)\n",
    "    return ensemble_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_ensemble_accuracy(5, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ns = np.arange(1, 55, 2)\n",
    "vfea = np.vectorize(find_ensemble_accuracy, excluded=['p'])\n",
    "ensemble_accuracies = vfea(ns, p=0.7)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ns, ensemble_accuracies, '.')\n",
    "ax.set_ylabel(\"Ensemble accuracy\")\n",
    "ax.set_xlabel(\"Number of independent 0.7-accuracy classifiers\")\n",
    "ax.set_title(\"Accuracy of an Ensemble of Independent Classifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\binom{5}{5} 0.7^5 + \\binom{5}{4} 0.7^4 0.3 + \\binom{5}{3} 0.7^3 0.3^2 \\approx 0.83 $$\n",
    "\n",
    "With 55 such classifiers we can achieve 99.9% accuracy.\n",
    "\n",
    "\n",
    "Ok, so that's all great, but what's the limitation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Make Them Independent?\n",
    "\n",
    "If the learners are all the same, ensembles don't help.\n",
    "\n",
    "Train each learner on different subset of data.\n",
    "\n",
    " * Why is this better than a single good model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance\n",
    "\n",
    "**Bias:** Error from failure to match training set\n",
    "\n",
    "**Variance:** Error from sampling training set\n",
    "\n",
    "What is the bias of an unpruned decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Classification Trees\n",
    "\n",
    "A **classification tree** is a decision tree to predicts whether a data point is in one class or another. Each branch node is a decision, choosing left or right based on the value of a certain feature. Each leaf node gives the probability that a data point is in one class or another.\n",
    "\n",
    "Let's look at the tennis dataset from the other day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in our data\n",
    "tennis_df = pd.read_table('data/tennis.txt', delim_whitespace=True)\n",
    "tennis_df.rename(columns={'playtennis': 'played'}, inplace=True)\n",
    "#tennis_df['played'] = tennis_df['played'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "tennis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='A simple classification tree')\n",
    "\n",
    "dot.node('O', 'outlook?', shape='diamond')\n",
    "dot.node('1', \"no\", shape='rectangle')\n",
    "dot.node('H', 'humidity?', shape='diamond')\n",
    "dot.node('O2', 'outlook?', shape='diamond')\n",
    "dot.node('W', 'wind?', shape='diamond')\n",
    "dot.node('3', 'yes', shape='rectangle')\n",
    "dot.node('T', 'temperature?', shape='diamond')\n",
    "dot.node('4', 'yes', shape='rectangle')\n",
    "dot.node('5', \"no\", shape='rectangle')\n",
    "dot.node('2', \"no\", shape='rectangle')\n",
    "dot.node('W2', 'wind?', shape='diamond')\n",
    "dot.node('6', \"no\", shape='rectangle')\n",
    "dot.node('7', 'yes', shape='rectangle')\n",
    "\n",
    "dot.edge('O', '1', 'overcast')\n",
    "dot.edge('O', 'H', 'not overcast')\n",
    "dot.edge('H', 'O2', 'high')\n",
    "dot.edge('H', 'W', 'normal')\n",
    "dot.edge('W', '3', 'False')\n",
    "dot.edge('W', 'T', 'True')\n",
    "dot.edge('T', '4', 'mild')\n",
    "dot.edge('T', '5', 'cool')\n",
    "dot.edge('O2', '2', 'sunny')\n",
    "dot.edge('O2', 'W2', 'rainy')\n",
    "dot.edge('W2', '7', 'False')\n",
    "dot.edge('W2', '6', 'True')\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification tree is built by\n",
    "\n",
    "* Iteratively divide the nodes such that (entropy/gini impurity) is minimized\n",
    "* Various stopping conditions like a depth limit\n",
    "* Prune trees by merging nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Regression Trees\n",
    "\n",
    "A **regression tree** predicting a number rather than the probability that something is in one class or another. Prediction works the same as with classification trees, but the leaf nodes give a number rather than probabilities of a class.\n",
    "\n",
    "To train a regression tree, we\n",
    "\n",
    "* Iteratively divide the nodes such that *total squared error* is minimized,\n",
    "\n",
    "$$\\sum_{i \\in L} (y_i - m_L)^2 + \\sum_{i\\in R} (y_i - m_R)^2$$\n",
    "\n",
    "* Use various stopping conditions like a depth limit, minimum leaf size, and\n",
    "* Prune trees by merging nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees: Example\n",
    "\n",
    " $x_1$ |   $x_2$ |  $y$\n",
    "-------|---------|--------\n",
    " 1     |    1    |   1\n",
    " 0     |    0    |   2\n",
    " 1     |    0    |   3\n",
    " 0     |    1    |   4\n",
    "\n",
    " Prior to the split we guess the mean, 2.5, for everything, giving total squared error:\n",
    " \n",
    " $$ E = (1-2.5)^2 + (2-2.5)^2 + (3-2.5)^2 + (4-2.5)^2  = 5$$\n",
    " After we split on $x_1$ we guess 2 for rows 1 & 3 and 3 for rows 2 & 4:\n",
    " \n",
    " $$ E = (1-2)^2 + (3-2)^2 + (2-3)^2 + (4-3)^2 = 4 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Summary\n",
    "\n",
    "What are the pros and cons?\n",
    "\n",
    "Pros\n",
    " * No feature scaling needed\n",
    " * Model nonlinear relationships\n",
    " * Can do both classification and regression\n",
    " * Robust\n",
    " * Highly interpretable\n",
    "\n",
    "Cons\n",
    " * Can be expensive to train\n",
    " * Often poor predictors because of high variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Bootstrapping\n",
    "\n",
    "What is a bootstrap sample?\n",
    "\n",
    "What have we learned that bootstrap samples are good for so far?\n",
    "\n",
    "Let's get the median of some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = scs.uniform(0,10).rvs(100)\n",
    "np.median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the confidence interval of this estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "medians = []\n",
    "for _ in range(10000):\n",
    "    bootstrap_sample = np.random.choice(data, len(data))\n",
    "    medians.append(np.median(bootstrap_sample))\n",
    "print(\"The {}% confidence interval is from {} to {}\".format(1-alpha,\n",
    "                                                            np.percentile(medians, 100*(alpha/2.)),\n",
    "                                                            np.percentile(medians, 100*(1-alpha/2.))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our procedure was\n",
    "  * Take 10000 bootstrap samples.\n",
    "  * Take the median of each sample.\n",
    "  * The 95% confidence inverval for the median is between the 250th and 9750th largest samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging (bootstrap aggregation)\n",
    "\n",
    "We could repeatedly sample from the population, building decision tree\n",
    "models and averaging the results.  But we only have one sample. Instead, we simulate multiple draws from the data by using multiple bootstrap samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a bit more detail:\n",
    "\n",
    " * Take a bunch of bootstrap samples - say n\n",
    " * Train a high variance, low bias model on each of them\n",
    " * Average the results - this can reduce your variance by up to $\\sqrt n$\n",
    "\n",
    "\n",
    "Question: Why is the reduction in variance less than $\\sqrt n$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " * We are thinking about the population of all possible decision tree models on our data.\n",
    " * If I take $n$ samples *iid* from this distribution and average them the variance goes down by $\\sqrt n$\n",
    " * There is some correlation between models because they are all trained on bootstrap samples from the same draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Experiment\n",
    "\n",
    "You're each going to be a decision tree on some data based on a bootstrap sample, and then we'll all together be a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "\n",
    "# Split into test/train, using the same random state for everyone\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=462)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# each of you has a different bootstrap sample\n",
    "bootstrap_sample = np.random.choice(range(len(X_train)), len(X_train))\n",
    "clf.fit(X_train[np.where(bootstrap_sample)], y_train[np.where(bootstrap_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:.3f}\".format(np.mean(clf.predict(X_test) == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"My prediction: {}\".format(clf.predict(X_test)[0:20]))\n",
    "print(\"Actual result: {}\".format(y_test[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "Random Forests improve on Bagging by de-correlating the trees using a technique called Subspace Sampling.\n",
    "\n",
    " * At each decision tree split only $m$ (often $m = \\sqrt k$) features are considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Parameters\n",
    "\n",
    "Random Forest Parameters\n",
    "\n",
    " * Total number of trees\n",
    " * Number of features to use at each split\n",
    " * Individual decision tree Parameters\n",
    "    - e.g., tree depth, pruning, split criterion\n",
    "\n",
    "In general, RF are fairly robust to the choice of parameters and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of Random Forest\n",
    "\n",
    "Pros\n",
    "\n",
    " * Often give near state-of-the-art performance\n",
    " * Good out-of-the-box performance\n",
    " * No feature scaling needed\n",
    " * Model nonlinear relationships\n",
    "\n",
    "Cons\n",
    "\n",
    " * Can be expensive to train (though can be done in parallel)\n",
    " * Not interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Let's investigate the accuracy of a random forests compared with a single decision tree using the boston dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Boston data\n",
    "data = load_breast_cancer()\n",
    "#data = pd.drop(data, )\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "X = X.drop(['worst concave points', 'mean concave points', 'worst perimeter', 'worst radius', 'worst area', 'mean concavity'], axis=1)\n",
    "# Split into test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, consider a decision tree, doing a grid search over hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter Search                                     \n",
    "model = DecisionTreeClassifier()\n",
    "depth_parm = np.arange(1, 12, 1)\n",
    "num_samples_parm = np.arange(5,95,10)\n",
    "parameters = {'max_depth' : depth_parm,\n",
    "             'min_samples_leaf' : num_samples_parm}\n",
    "clf = GridSearchCV(model, parameters, cv=10)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train and fit model                                                   \n",
    "rf = RandomForestClassifier(n_estimators=1000,\n",
    "                           max_features='auto',\n",
    "                           random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "                                     \n",
    "# Test Prediction\n",
    "pred = rf.predict(X_test)\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afternoon Lecture\n",
    "\n",
    "## Interpreting Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Morning Objectives\n",
    "\n",
    " * Explain & construct a random forest (classification or regression).\n",
    " * Explain the relationship and difference between random forest and bagging.\n",
    " * Explain why random forests are more accurate than a single decision tree.\n",
    "\n",
    "Afternoon Objectives\n",
    "\n",
    " * Get feature importances from a random forest.\n",
    " * Explain how OOB error is calculated and what is it an estimate of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "Morning Agenda\n",
    "\n",
    " * Discuss ensemble methods\n",
    " * Review bias/variance tradeoff\n",
    " * Review decision trees\n",
    " * Discuss bagging (bootstrap aggregation)\n",
    " * Discuss random forests\n",
    "\n",
    "Afternoon Agenda\n",
    "\n",
    " * Discuss out-of-bag error\n",
    " * Discuss feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Bagging and Random Forests\n",
    "\n",
    "What is bagging?\n",
    "\n",
    "Can bagging be used with other models?\n",
    "\n",
    "What's the difference between bagging and random forests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1/np.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-Of-Bag Error\n",
    "\n",
    "Measuring error of a bagged model.\n",
    "\n",
    "* Out-of-bag (OOB) error is a method of estimating the error of ensemble methods that use Bagging.  \n",
    "* About 37% of the estimators will not have been trained on each data point.\n",
    "* Test each data point only on the estimators that didn't see that data point during training.  \n",
    "* Often use cross validation anyway because we're comparing with other models and want to measure the accuracy the same way.\n",
    "\n",
    "---\n",
    "\n",
    "## Feature Importances\n",
    "\n",
    "One of the challenges of random forests is the lack of interpretability. Feature importances are a measure of which features aften actually effect the predictions.\n",
    "\n",
    "This can be a critical business question. For example, with churn analysis, it's generally more important to understand *why* customers are churning than to predict which customers are going to churn.\n",
    "\n",
    "How should we measure it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances: Mean Decrease Impurity\n",
    "\n",
    "How much does each feature decrease the impurity?\n",
    "\n",
    "To compute the importance of the $j^{th}$ feature:\n",
    "\n",
    " * For each tree, each split is made in order to reduce the total impurity of the tree (Gini/entropy/MSE); we can record the magnitude of the reduction.\n",
    " * Then the importance of a feature is the average decrease in impurity across trees in the forest, as a result of splits defined by that feature.  \n",
    " * This is implemented in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances: Mean Decrease Accuracy\n",
    "\n",
    "How much does randomly mixing values of a feature affect accuracy?\n",
    "\n",
    "To compute the importance of the $j^{th}$ feature:\n",
    "\n",
    " * When the $b^{th}$ tree is grown, use it to predict the OOB samples and record accuracy.\n",
    " * Scramble the values of the $j^{th}$ feature in the OOB samples and do the prediction again.  Compute the new (lower) accuracy.\n",
    " * Average the decrease in accuracy across all trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances: ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the feature importance\n",
    "feat_scores = pd.DataFrame({'Fraction of Samples Affected' : rf.feature_importances_},\n",
    "                           index=X.columns)\n",
    "feat_scores = feat_scores.sort_values(by='Fraction of Samples Affected')\n",
    "feat_scores.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Decrease Accuracy\n",
    "\n",
    "A different approach to calculating feature importances shuufles the values of a feature, and measures the decrease in accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    "\n",
    "\n",
    "names = data.feature_names\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    " \n",
    "# crossvalidate the scores on a number of \n",
    "# different random splits of the data\n",
    "splitter = ShuffleSplit(100, test_size=.3)\n",
    "\n",
    "for train_idx, test_idx in splitter.split(X, y):\n",
    "    X_train, X_test = X.values[train_idx], X.values[test_idx]\n",
    "    y_train, y_test = y.values[train_idx], y.values[test_idx]\n",
    "    rf.fit(X_train, y_train)\n",
    "    acc = r2_score(y_test, rf.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(y_test, rf.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "\n",
    "score_series = pd.DataFrame(scores).mean()\n",
    "scores = pd.DataFrame({'Mean Decrease Accuracy' : score_series})\n",
    "scores.sort_values(by='Mean Decrease Accuracy').plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
