> 4 out of 5 dentists recommend this toothpaste.

The majority opinion of a group of independent experts is more authoritative, and more often correct, than any one individual. This is the intuition behind ensemble learning. We can (and will) demonstrate this statistically.

In this talk, data scientist and machine learning instructor Elliot Cohen will demonstrate (and demystify) the power of multi-model predictions. In particular, he will introduce boosting, bagging and random forests as robust techniques applicable to a wide range of classification and regression problems. Part theory, part math, part code, this talk will give budding data scientists the foundation necessary to add ensemble learning to their repertoire. Already using boosting in production? Come learn the _why_ behind the _how_, and share your insights with the community!
